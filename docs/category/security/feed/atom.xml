<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Simplicity is a form of art... - Security</title><link href="https://blog.siphos.be/" rel="alternate"></link><link href="https://blog.siphos.be/category/security/feed/atom.xml" rel="self"></link><id>https://blog.siphos.be/</id><updated>2018-03-03T13:20:00+01:00</updated><subtitle></subtitle><entry><title>Automating compliance checks</title><link href="https://blog.siphos.be/2018/03/automating-compliance-checks/" rel="alternate"></link><published>2018-03-03T13:20:00+01:00</published><updated>2018-03-03T13:20:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2018-03-03:/2018/03/automating-compliance-checks/</id><summary type="html">&lt;p&gt;With the configuration baseline for a technical service being described fully (see the &lt;a href="https://blog.siphos.be/2018/01/documenting-configuration-changes/"&gt;first&lt;/a&gt;, &lt;a href="https://blog.siphos.be/2018/01/structuring-a-configuration-baseline/"&gt;second&lt;/a&gt; and &lt;a href="https://blog.siphos.be/2018/01/documenting-a-rule/"&gt;third&lt;/a&gt; post in this series), it is time to consider the validation of the settings in an automated manner. The preferred method for this is to use &lt;em&gt;Open Vulnerability and Assessment Language (OVAL)&lt;/em&gt;, which is nowadays managed by the &lt;a href="https://oval.cisecurity.org/"&gt;Center for Internet Security&lt;/a&gt;, abbreviated as CISecurity. Previously, OVAL was maintained and managed by Mitre under NIST supervision, and Google searches will often still point to the old sites. However, documentation is now maintained on CISecurity's &lt;a href="https://github.com/OVALProject/Language/tree/5.11.2/docs"&gt;github repositories&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But I digress...&lt;/p&gt;
</summary><content type="html">&lt;p&gt;With the configuration baseline for a technical service being described fully (see the &lt;a href="https://blog.siphos.be/2018/01/documenting-configuration-changes/"&gt;first&lt;/a&gt;, &lt;a href="https://blog.siphos.be/2018/01/structuring-a-configuration-baseline/"&gt;second&lt;/a&gt; and &lt;a href="https://blog.siphos.be/2018/01/documenting-a-rule/"&gt;third&lt;/a&gt; post in this series), it is time to consider the validation of the settings in an automated manner. The preferred method for this is to use &lt;em&gt;Open Vulnerability and Assessment Language (OVAL)&lt;/em&gt;, which is nowadays managed by the &lt;a href="https://oval.cisecurity.org/"&gt;Center for Internet Security&lt;/a&gt;, abbreviated as CISecurity. Previously, OVAL was maintained and managed by Mitre under NIST supervision, and Google searches will often still point to the old sites. However, documentation is now maintained on CISecurity's &lt;a href="https://github.com/OVALProject/Language/tree/5.11.2/docs"&gt;github repositories&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But I digress...&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Read-only compliance validation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of the main ideas with OVAL is to have a language (XML-based) that represents state information (what something should be) which can be verified in a read-only fashion. Even more, from an operational perspective, it is very important that compliance checks &lt;em&gt;do not alter&lt;/em&gt; anything, but only report.&lt;/p&gt;
&lt;p&gt;Within its design, OVAL engineering has considered how to properly manage huge sets of assessment rules, and how to document this in an unambiguous manner. In the previous blog posts, ambiguity was resolved through writing style, and not much through actual, enforced definitions.&lt;/p&gt;
&lt;p&gt;OVAL enforces this. You can't write a generic or ambiguous rule in OVAL. It is very specific, but that also means that it is daunting to implement the first few times. I've written many OVAL sets, and I still struggle with it (although that's because I don't do it enough in a short time-frame, and need to reread my own documentation regularly).&lt;/p&gt;
&lt;p&gt;The capability to perform read-only validation with OVAL leads to a number of possible use cases. In the &lt;a href="http://oval.mitre.org/language/version5.10/OVAL_Language_Specification_09-14-2011.pdf"&gt;5.10 specification&lt;/a&gt; a number of use cases are provided. Basically, it boils down to vulnerability discovery (is a system vulnerable or not), patch management (is the system patched accordingly or not), configuration management (are the settings according to the rules or not), inventory management (detect what is installed on the system or what the systems' assets are), malware and threat indicator (detect if a system has been compromised or particular malware is active), policy enforcement (verify if a client system adheres to particular rules before it is granted access to a network), change tracking (regularly validating the state of a system and keeping track of changes), and security information management (centralizing results of an entire organization or environment and doing standard analytics on it).&lt;/p&gt;
&lt;p&gt;In this blog post series, I'm focusing on configuration management.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OVAL structure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Although the OVAL standard (just like the XCCDF standard actually) entails a number of major components, I'm going to focus on the OVAL definitions. Be aware though that the results of an OVAL scan are also standardized format, as are results of XCCDF scans for instance.&lt;/p&gt;
&lt;p&gt;OVAL definitions have 4 to 5 blocks in them:
- the &lt;strong&gt;definition&lt;/strong&gt; itself, which describes what is being validated and how. It refers to one or more tests that are to be executed or validated for the definition result to be calculated
- the &lt;strong&gt;test&lt;/strong&gt; or tests, which are referred to by the definition. In each test, there is at least a reference to an object (what is being tested) and optionally to a state (what should the object look like)
- the &lt;strong&gt;object&lt;/strong&gt;, which is a unique representation of a resource or resources on the system (a file, a process, a mount point, a kernel parameter, etc.). Object definitions can refer to multiple resources, depending on the definition.
- the &lt;strong&gt;state&lt;/strong&gt;, which is a sort-of value mapping or validation that needs to be applied to an object to see if it is configured correctly
- the &lt;strong&gt;variable&lt;/strong&gt;, an optional definition which is what it sounds like, a variable that substitutes an abstract definition with an actual definition,  allowing to write more reusable tests.&lt;/p&gt;
&lt;p&gt;Let's get an example going, but without the XML structure, so in human language. We want to define that the Kerberos definition on a Linux system should allow forwardable tickets by default. This is accomplished by ensuring that, inside the &lt;code&gt;/etc/krb5.conf&lt;/code&gt; file (which is an INI-style configuration file), the value of the &lt;code&gt;forwardable&lt;/code&gt; key inside the &lt;code&gt;[libdefaults]&lt;/code&gt; section is set to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In OVAL, the definition itself will document the above in human readable text, assign it a unique ID (like &lt;code&gt;oval:com.example.oval:def:1&lt;/code&gt;) and mark it as being a definition for configuration validation (&lt;code&gt;compliance&lt;/code&gt;). Then, it defines the criteria that need to be checked in order to properly validate if the rule is applicable or not. These criteria include validation if the OVAL statement is actually being run on a Linux system (as it makes no sense to run it against a Cisco router) which is Kerberos enabled, and then the criteria of the file check itself. Each criteria links to a test.&lt;/p&gt;
&lt;p&gt;The test of the file itself links to an object and a state. There are a number of ways how we can check for this specific case. One is that the object is the &lt;code&gt;forwardable&lt;/code&gt; key in the &lt;code&gt;[libdefaults]&lt;/code&gt; section of the &lt;code&gt;/etc/krb5.conf&lt;/code&gt; file, and the state is the value &lt;code&gt;true&lt;/code&gt;. In this case, the state will point to those two entries (through their unique IDs) and define that the object must exist, and all matches must have a matching state. The "all matches" here is not that important, because there will generally only be one such definition in the &lt;code&gt;/etc/krb5.conf&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;Note however that a different approach to the test can be declared as well. We could state that the object is the &lt;code&gt;[libdefaults]&lt;/code&gt; section inside the &lt;code&gt;/etc/krb5.conf&lt;/code&gt; file, and the state is the value &lt;code&gt;true&lt;/code&gt; for the &lt;code&gt;forwardable&lt;/code&gt; key. In this case, the test declares that multiple objects must exist, and (at least) one must match the state.&lt;/p&gt;
&lt;p&gt;As you can see, the OVAL language tries to map definitions to unambiguous definitions. So, how does this look like in OVAL XML?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The OVAL XML structure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://blog.siphos.be/static/2018/oval.xml"&gt;full example&lt;/a&gt; contains a few more entries than those we declare next, in order to be complete. The most important definitions though are documented below.&lt;/p&gt;
&lt;p&gt;Let's start with the definition. As stated, it will refer to tests that need to match for the definition to be valid.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;definitions&amp;gt;
  &amp;lt;definition id=&amp;quot;oval:com.example.oval:def:1&amp;quot; version=&amp;quot;1&amp;quot; class=&amp;quot;compliance&amp;quot;&amp;gt;
    &amp;lt;metadata&amp;gt;
      &amp;lt;title&amp;gt;libdefaults.forwardable in /etc/krb5.conf must be set to true&amp;lt;/title&amp;gt;
      &amp;lt;affected family=&amp;quot;unix&amp;quot;&amp;gt;
        &amp;lt;platform&amp;gt;Red Hat Enterprise Linux 7&amp;lt;/platform&amp;gt;
      &amp;lt;/affected&amp;gt;
      &amp;lt;description&amp;gt;
        By default, tickets obtained from the Kerberos environment must be forwardable.
      &amp;lt;/description&amp;gt;
    &amp;lt;/metadata&amp;gt;
    &amp;lt;criteria operator=&amp;quot;AND&amp;quot;&amp;gt;
      &amp;lt;criterion test_ref=&amp;quot;oval:com.example.oval:tst:1&amp;quot; comment=&amp;quot;Red Hat Enterprise Linux is installed&amp;quot;/&amp;gt;
      &amp;lt;criterion test_ref=&amp;quot;oval:com.example.oval:tst:2&amp;quot; comment=&amp;quot;/etc/krb5.conf&amp;#39;s libdefaults.forwardable is set to true&amp;quot;/&amp;gt;
    &amp;lt;/criteria&amp;gt;
  &amp;lt;/definition&amp;gt;
&amp;lt;/definitions&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first thing to keep in mind is the (weird) identification structure. Just like with XCCDF, it is not sufficient to have your own id convention. You need to start an id with &lt;code&gt;oval:&lt;/code&gt; followed by the reverse domain definition (here &lt;code&gt;com.example.oval&lt;/code&gt;), followed by the type (&lt;code&gt;def&lt;/code&gt; for definition) and a sequence number.&lt;/p&gt;
&lt;p&gt;Also, take a look at the criteria. Here, two tests need to be compliant (hence the &lt;code&gt;AND&lt;/code&gt; operator). However, more complex operations can be done as well. It is even allowed to nest multiple criteria, and refer to previous definitions, like so (taken from the &lt;a href="https://raw.githubusercontent.com/GovReady/ubuntu-scap/master/ssg-rhel6-oval.xml"&gt;ssg-rhel6-oval.xml file&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;criteria comment=&amp;quot;package hal removed or service haldaemon is not configured to start&amp;quot; operator=&amp;quot;OR&amp;quot;&amp;gt;
  &amp;lt;extend_definition comment=&amp;quot;hal removed&amp;quot; definition_ref=&amp;quot;oval:ssg:def:211&amp;quot;/&amp;gt;
  &amp;lt;criteria operator=&amp;quot;AND&amp;quot; comment=&amp;quot;service haldaemon is not configured to start&amp;quot;&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 0&amp;quot; test_ref=&amp;quot;oval:ssg:tst:212&amp;quot;/&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 1&amp;quot; test_ref=&amp;quot;oval:ssg:tst:213&amp;quot;/&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 2&amp;quot; test_ref=&amp;quot;oval:ssg:tst:214&amp;quot;/&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 3&amp;quot; test_ref=&amp;quot;oval:ssg:tst:215&amp;quot;/&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 4&amp;quot; test_ref=&amp;quot;oval:ssg:tst:216&amp;quot;/&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 5&amp;quot; test_ref=&amp;quot;oval:ssg:tst:217&amp;quot;/&amp;gt;
    &amp;lt;criterion comment=&amp;quot;haldaemon runlevel 6&amp;quot; test_ref=&amp;quot;oval:ssg:tst:218&amp;quot;/&amp;gt;
  &amp;lt;/criteria&amp;gt;
&amp;lt;/criteria&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next, let's look at the tests.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;tests&amp;gt;
  &amp;lt;unix:file_test id=&amp;quot;oval:com.example.oval:tst:1&amp;quot; version=&amp;quot;1&amp;quot; check_existence=&amp;quot;all_exist&amp;quot; check=&amp;quot;all&amp;quot; comment=&amp;quot;/etc/redhat-release exists&amp;quot;&amp;gt;
    &amp;lt;unix:object object_ref=&amp;quot;oval:com.example.oval:obj:1&amp;quot; /&amp;gt;
  &amp;lt;/unix:file_test&amp;gt;
  &amp;lt;ind:textfilecontent54_test id=&amp;quot;oval:com.example.oval:tst:2&amp;quot; check=&amp;quot;all&amp;quot; check_existence=&amp;quot;all_exist&amp;quot; version=&amp;quot;1&amp;quot; comment=&amp;quot;The value of forwardable in /etc/krb5.conf&amp;quot;&amp;gt;
    &amp;lt;ind:object object_ref=&amp;quot;oval:com.example.oval:obj:2&amp;quot; /&amp;gt;
    &amp;lt;ind:state state_ref=&amp;quot;oval:com.example.oval:ste:2&amp;quot; /&amp;gt;
  &amp;lt;/ind:textfilecontent54_test&amp;gt;
&amp;lt;/tests&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There are two tests defined here. The first test just checks if &lt;code&gt;/etc/redhat-release&lt;/code&gt; exists. If not, then the test will fail and the definition itself will result to false (as in, not compliant). This isn't actually a proper definition, because you want the test to not run when it is on a different platform, but for the sake of example and simplicity, let's keep it as is.&lt;/p&gt;
&lt;p&gt;The second test will check for the value of the &lt;code&gt;forwardable&lt;/code&gt; key in &lt;code&gt;/etc/krb5.conf&lt;/code&gt;. For it, it refers to an object and a state. The test states that all objects must exist (&lt;code&gt;check_existence="all_exist"&lt;/code&gt;) and that all objects must match the state (&lt;code&gt;check="all"&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The object definition looks like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;objects&amp;gt;
  &amp;lt;unix:file_object id=&amp;quot;oval:com.example.oval:obj:1&amp;quot; comment=&amp;quot;The /etc/redhat-release file&amp;quot; version=&amp;quot;1&amp;quot;&amp;gt;
    &amp;lt;unix:filepath&amp;gt;/etc/redhat-release&amp;lt;/unix:filepath&amp;gt;
  &amp;lt;/unix:file_object&amp;gt;
  &amp;lt;ind:textfilecontent54_object id=&amp;quot;oval:com.example.oval:obj:2&amp;quot; comment=&amp;quot;The forwardable key&amp;quot; version=&amp;quot;1&amp;quot;&amp;gt;
    &amp;lt;ind:filepath&amp;gt;/etc/krb5.conf&amp;lt;/ind:filepath&amp;gt;
    &amp;lt;ind:pattern operation=&amp;quot;pattern match&amp;quot;&amp;gt;^\s*forwardable\s*=\s*((true|false))\w*&amp;lt;/ind:pattern&amp;gt;
    &amp;lt;ind:instance datatype=&amp;quot;int&amp;quot; operation=&amp;quot;equals&amp;quot;&amp;gt;1&amp;lt;/ind:instance&amp;gt;
  &amp;lt;/ind:textfilecontent54_object&amp;gt;
&amp;lt;/objects&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first object is a simple file reference. The second is a text file content object. More specifically, it matches the line inside &lt;code&gt;/etc/krb5.conf&lt;/code&gt; which has &lt;code&gt;forwardable = true&lt;/code&gt; or &lt;code&gt;forwardable = false&lt;/code&gt; in it. An expression is made on it, so that we can refer to the subexpression as part of the test.&lt;/p&gt;
&lt;p&gt;This test looks like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;states&amp;gt;
  &amp;lt;ind:textfilecontent54_state id=&amp;quot;oval:com.example.oval:ste:2&amp;quot; version=&amp;quot;1&amp;quot;&amp;gt;
    &amp;lt;ind:subexpression datatype=&amp;quot;string&amp;quot;&amp;gt;true&amp;lt;/ind:subexpression&amp;gt;
  &amp;lt;/ind:textfilecontent54_state&amp;gt;
&amp;lt;/states&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This test refers to a subexpression, and wants it to be &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Testing the checks with Open-SCAP&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Open-SCAP tool is able to test OVAL statements directly. For instance, with the above definition in a file called &lt;code&gt;oval.xml&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap oval eval --results oval-results.xml oval.xml
Definition oval:com.example.oval:def:1: true
Evaluation done.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The output of the command shows that the definition was evaluated successfully. If you want more information, open up the &lt;code&gt;oval-results.xml&lt;/code&gt; file which contains all the details about the test. This results file is also very useful while developing OVAL as it shows the entire result of objects, tests and so forth.&lt;/p&gt;
&lt;p&gt;For instance, the &lt;code&gt;/etc/redhat-release&lt;/code&gt; file was only checked to see if it exists, but the results file shows what other parameters can be verified with it as well:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;unix-sys:file_item id=&amp;quot;1233781&amp;quot; status=&amp;quot;exists&amp;quot;&amp;gt;
  &amp;lt;unix-sys:filepath&amp;gt;/etc/redhat-release&amp;lt;/unix-sys:filepath&amp;gt;
  &amp;lt;unix-sys:path&amp;gt;/etc&amp;lt;/unix-sys:path&amp;gt;
  &amp;lt;unix-sys:filename&amp;gt;redhat-release&amp;lt;/unix-sys:filename&amp;gt;
  &amp;lt;unix-sys:type&amp;gt;regular&amp;lt;/unix-sys:type&amp;gt;
  &amp;lt;unix-sys:group_id datatype=&amp;quot;int&amp;quot;&amp;gt;0&amp;lt;/unix-sys:group_id&amp;gt;
  &amp;lt;unix-sys:user_id datatype=&amp;quot;int&amp;quot;&amp;gt;0&amp;lt;/unix-sys:user_id&amp;gt;
  &amp;lt;unix-sys:a_time datatype=&amp;quot;int&amp;quot;&amp;gt;1515186666&amp;lt;/unix-sys:a_time&amp;gt;
  &amp;lt;unix-sys:c_time datatype=&amp;quot;int&amp;quot;&amp;gt;1514927465&amp;lt;/unix-sys:c_time&amp;gt;
  &amp;lt;unix-sys:m_time datatype=&amp;quot;int&amp;quot;&amp;gt;1498674992&amp;lt;/unix-sys:m_time&amp;gt;
  &amp;lt;unix-sys:size datatype=&amp;quot;int&amp;quot;&amp;gt;52&amp;lt;/unix-sys:size&amp;gt;
  &amp;lt;unix-sys:suid datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:suid&amp;gt;
  &amp;lt;unix-sys:sgid datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:sgid&amp;gt;
  &amp;lt;unix-sys:sticky datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:sticky&amp;gt;
  &amp;lt;unix-sys:uread datatype=&amp;quot;boolean&amp;quot;&amp;gt;true&amp;lt;/unix-sys:uread&amp;gt;
  &amp;lt;unix-sys:uwrite datatype=&amp;quot;boolean&amp;quot;&amp;gt;true&amp;lt;/unix-sys:uwrite&amp;gt;
  &amp;lt;unix-sys:uexec datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:uexec&amp;gt;
  &amp;lt;unix-sys:gread datatype=&amp;quot;boolean&amp;quot;&amp;gt;true&amp;lt;/unix-sys:gread&amp;gt;
  &amp;lt;unix-sys:gwrite datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:gwrite&amp;gt;
  &amp;lt;unix-sys:gexec datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:gexec&amp;gt;
  &amp;lt;unix-sys:oread datatype=&amp;quot;boolean&amp;quot;&amp;gt;true&amp;lt;/unix-sys:oread&amp;gt;
  &amp;lt;unix-sys:owrite datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:owrite&amp;gt;
  &amp;lt;unix-sys:oexec datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:oexec&amp;gt;
  &amp;lt;unix-sys:has_extended_acl datatype=&amp;quot;boolean&amp;quot;&amp;gt;false&amp;lt;/unix-sys:has_extended_acl&amp;gt;
&amp;lt;/unix-sys:file_item&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, this is just on OVAL level. The final step is to link it in the XCCDF file.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Referring to OVAL in XCCDF&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The XCCDF Rule entry allows for a &lt;code&gt;check&lt;/code&gt; element, which refers to an automated check for compliance.&lt;/p&gt;
&lt;p&gt;For instance, the above rule could be referred to like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;Rule id=&amp;quot;xccdf_com.example_rule_krb5-forwardable-true&amp;quot;&amp;gt;
  &amp;lt;title&amp;gt;Enable forwardable tickets on RHEL systems&amp;lt;/title&amp;gt;
  ...
  &amp;lt;check system=&amp;quot;http://oval.mitre.org/XMLSchema/oval-definitions-5&amp;quot;&amp;gt;
    &amp;lt;check-content-ref href=&amp;quot;oval.xml&amp;quot; name=&amp;quot;oval:com.example.oval:def:1&amp;quot; /&amp;gt;
  &amp;lt;/check&amp;gt;
&amp;lt;/Rule&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With this set in the Rule, Open-SCAP can validate it while checking the configuration baseline:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf eval --oval-results --results xccdf-results.xml xccdf.xml
...
Title   Enable forwardable kerberos tickets in krb5.conf libdefaults
Rule    xccdf_com.example_rule_krb5-forwardable-tickets
Ident   RHEL7-01007
Result  pass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A huge advantage here is that, alongside the detailed results of the run, there is also better human readable output as it shows the title of the Rule being checked.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The detailed capabilities of OVAL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the above example I've used two examples: a file validation (against &lt;code&gt;/etc/redhat-release&lt;/code&gt;) and a file content one (against &lt;code&gt;/etc/krb5.conf&lt;/code&gt;). However, OVAL has many more checks and support for it, and also has constraints that you need to be aware of.&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://github.com/OVALProject/Language/tree/master/docs"&gt;OVAL Project&lt;/a&gt; github account, the Language repository keeps track of the current documentation. By browsing through it, you'll notice that the OVAL capabilities are structured based on the target technology that you can check. Right now, this is AIX, Android, Apple iOS, Cisco ASA, Cisco CatOS, VMWare ESX, FreeBSD, HP-UX, Cisco iOS and iOS-XE, Juniper JunOS, Linux, MacOS, NETCONF, Cisco PIX, Microsoft SharePoint, Unix (generic), Microsoft Windows, and independent.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/OVALProject/Language/blob/master/docs/independent-definitions-schema.md"&gt;independent&lt;/a&gt; one contains tests and support for resources that are often reusable toward different platforms (as long as your OVAL and XCCDF supporting tools can run it on those platforms). A few notable supporting tests are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;filehash58_test&lt;/code&gt; which can check for a number of common hashes (such as SHA-512 and MD5). This is useful when you want to make sure that a particular (binary or otherwise) file is available on the system. In enterprises, this could be useful for license files, or specific library files.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;textfilecontent54_test&lt;/code&gt; which can check the content of a file, with support for regular expressions.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;xmlfilecontent_test&lt;/code&gt; which is a specialized test toward XML files&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keep in mind though that, as we have seen above, INI files specifically have no specialization available. It would be nice if CISecurity would develop support for common textual data formats, such as CSV (although that one is easily interpretable with the existing ones), JSON, YAML and INI.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/OVALProject/Language/blob/master/docs/unix-definitions-schema.md"&gt;unix&lt;/a&gt; one contains tests specific to Unix and Unix-like operating systems (so yes, it is also useful for Linux), and together with the &lt;a href="https://github.com/OVALProject/Language/blob/master/docs/linux-definitions-schema.md"&gt;linux&lt;/a&gt; one a wide range of configurations can be checked. This includes support for generic extended attributes (&lt;code&gt;fileextendedattribute_test&lt;/code&gt;) as well as SELinux specific rules (&lt;code&gt;selinuxboolean_test&lt;/code&gt; and &lt;code&gt;selinuxsecuritycontext_test&lt;/code&gt;), network interface settings (&lt;code&gt;interface_test&lt;/code&gt;), runtime processes (&lt;code&gt;process58_test&lt;/code&gt;), kernel parameters (&lt;code&gt;sysctl_test&lt;/code&gt;), installed software tests (such as &lt;code&gt;rpminfo_test&lt;/code&gt; for RHEL and other RPM enabled operating systems) and more.&lt;/p&gt;</content><category term="Security"></category><category term="xccdf"></category><category term="oval"></category><category term="scap"></category><category term="baseline"></category></entry><entry><title>Documenting a rule</title><link href="https://blog.siphos.be/2018/01/documenting-a-rule/" rel="alternate"></link><published>2018-01-24T20:40:00+01:00</published><updated>2018-01-24T20:40:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2018-01-24:/2018/01/documenting-a-rule/</id><summary type="html">&lt;p&gt;In the &lt;a href="https://blog.siphos.be/2018/01/documenting-configuration-changes/"&gt;first post&lt;/a&gt; I talked about why configuration documentation is important. In the &lt;a href="https://blog.siphos.be/2018/01/structuring-a-configuration-baseline/"&gt;second post&lt;/a&gt; I looked into a good structure for configuration documentation of a technological service, and ended with an XCCDF template in which this documentation can be structured.&lt;/p&gt;
&lt;p&gt;The next step is to document the rules themselves, i.e. the actual content of a configuration baseline.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;In the &lt;a href="https://blog.siphos.be/2018/01/documenting-configuration-changes/"&gt;first post&lt;/a&gt; I talked about why configuration documentation is important. In the &lt;a href="https://blog.siphos.be/2018/01/structuring-a-configuration-baseline/"&gt;second post&lt;/a&gt; I looked into a good structure for configuration documentation of a technological service, and ended with an XCCDF template in which this documentation can be structured.&lt;/p&gt;
&lt;p&gt;The next step is to document the rules themselves, i.e. the actual content of a configuration baseline.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Fine-grained rules&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While from a high-level point of view, configuration items could be documented in a coarse-grained manner, a proper configuration baseline documents rules very fine-grained. Let's first consider a bad example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;All application code files are root-owned, with read-write privileges for owner and group, and executable where it makes sense.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While such a rule could be interpreted correctly, it also leaves room for misinterpretation and ambiguity. Furthermore, it is not explicit. What are application code files? Where are they stored? What about group ownership? The executable permission, when does that make sense? Does the rule also imply that there is no privilege for world-wide access, or does it just ignore that?&lt;/p&gt;
&lt;p&gt;A better example (or set of examples) would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/opt/postgresql&lt;/code&gt; is recursively user-owned by root&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/opt/postgresql&lt;/code&gt; is recursively group-owned by root&lt;/li&gt;
&lt;li&gt;No files under &lt;code&gt;/opt/postgresql&lt;/code&gt; are executable except when specified further&lt;/li&gt;
&lt;li&gt;All files in &lt;code&gt;/opt/postgresql/bin&lt;/code&gt; are executable&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/opt/postgresql&lt;/code&gt; has &lt;code&gt;system_u:object_r:usr_t:s0&lt;/code&gt; as SELinux context&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/opt/postgresql/bin/postgres&lt;/code&gt; has &lt;code&gt;system_u:object_r:postgresql_exec_t:s0&lt;/code&gt; as SELinux context&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And even that list is still not complete, but you get the gist. The focus here is to have fine-grained rules which are explicit and not ambiguous.&lt;/p&gt;
&lt;p&gt;Of course, the above configuration rule is still a "simple" permission set. Configuration baselines go further than that of course. They can act on file content ("no PAM configuration files can refer to pam_rootok.so except for runuser and su"), run-time processes ("The processes with /usr/sbin/sshd as command and with -D as option must run within the sshd_t SELinux domain"), database query results, etc.&lt;/p&gt;
&lt;p&gt;This granularity is especially useful later on when you want to automate compliance checks, because the more fine-grained a description is, the easier it is to develop and maintain checks on it. But before we look into remediation, let's document the rule a bit further.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Metadata on the rules&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's consider the following configuration rule:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;/opt/postgresql/bin/postgres&lt;/code&gt; has &lt;code&gt;system_u:object_r:postgresql_exec_t:s0&lt;/code&gt; as SELinux context&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the configuration baseline, we don't just want to state that this is the rule, and be finished. We need to describe the rule in more detail, as was described in the &lt;a href="https://blog.siphos.be/2018/01/structuring-a-configuration-baseline/"&gt;previous post&lt;/a&gt;. More specifically, we definitely want to
- know the rule's severity is, or how "bad" it would be if we detect a deviation from the rule
- have an indication if the rule is security-sensitive or more oriented to manageability
- a more elaborate description of the rule than just the title
- an indication why this rule is in place (what does it solve, fix or simplify)
- information on how to remediate if a deviation is found
- know if the rule is applicable to our environment or not&lt;/p&gt;
&lt;p&gt;The severity in the &lt;em&gt;Security Content Automation Protocol (SCAP)&lt;/em&gt; standard, which defines the XCCDF standard as well as OVAL and a few others like CVSS, uses the following possible values for severity: unknown, info, low, medium, high.&lt;/p&gt;
&lt;p&gt;To indicate if a rule is security-oriented or not, XCCDF's role attribute is best used. With the role attribute, you state if a rule is to be included in the final scoring (a weighted value given to the compliance of a system) or not. If it is, then it is security sensitive.&lt;/p&gt;
&lt;p&gt;The indication of a rule applicability in the environment might seem strange. If you document the configuration baseline, shouldn't it include only those settings you want? Well, yes and no. Personally, I like to include recommendations that we &lt;em&gt;do not follow&lt;/em&gt; in the baseline as well.&lt;/p&gt;
&lt;p&gt;Suppose for instance that an audit comes along and says you need to enable data encryption on the database. Let's put aside that an auditor should focus mainly/solely on the risks, and let the solutions be managed by the team (but be involved in accepting solutions of course), the team might do an assessment and find that data encryption on the database level (i.e. the database files are encrypted so non-DBA users with operating system interactive rights cannot read the data) is actually not going to remediate any risk, yet introduce more complexity.&lt;/p&gt;
&lt;p&gt;In that situation, and assuming that the auditor agrees with a different control, you might want to add a rule to the configuration baseline about this. Either you document the wanted state (database files do not need to be encrypted), or you document the suggestion (database files should be encrypted) but explicitly state that you do not require or implement it, and document the reasoning for it. The rule is then augmented with references to the audit recommendation for historical reasons and to facilitate future discussions.&lt;/p&gt;
&lt;p&gt;And yes, I know the rule "database files should be encrypted" is still ambiguous. The actual rule should be more specific to the technology).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Documenting a rule in XCCDF&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In XCCDF, a rule is defined through the &lt;code&gt;Rule&lt;/code&gt; XML entity, and is placed within a &lt;code&gt;Group&lt;/code&gt;. The Group entities are used to structure the document, while the &lt;code&gt;Rule&lt;/code&gt; entities document specific configuration directives.&lt;/p&gt;
&lt;p&gt;The postgres related rule of above could be written as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;lt;Rule id=&amp;quot;xccdf_com.example_rule_pgsql-selinux-context&amp;quot;
      role=&amp;quot;full&amp;quot;
      selected=&amp;quot;1&amp;quot;
      weight=&amp;quot;5.1&amp;quot;
      severity=&amp;quot;high&amp;quot;
      cluster-id=&amp;quot;network&amp;quot;&amp;gt;
  &amp;lt;title&amp;gt;
    /opt/postgresql/bin/postgres has system_u:object_r:postgresql_exec_t:s0 as SELinux context
  &amp;lt;/title&amp;gt;
  &amp;lt;description&amp;gt;
    &amp;lt;xhtml:p&amp;gt;
      The postgres binary is the main binary of the PostgreSQL database daemon. Once started, it launches the necessary workers. To ensure that PostgreSQL runs in the proper SELinux domain (postgresql_t) its binary must be labeled with postgresql_exec_t.
    &amp;lt;/xhtml:p&amp;gt;
    &amp;lt;xhtml:p&amp;gt;
      The current state of the label can be obtained using stat, or even more simple, the -Z option to ls:
    &amp;lt;/xhtml:p&amp;gt;
    &amp;lt;xhtml:pre&amp;gt;~$ ls -Z /opt/postgresql/bin/postgres
-rwxr-xr-x. root root system_u:object_r:postgresql_exec_t:s0 /opt/postgresql/bin/postgres
    &amp;lt;/xhtml:pre&amp;gt;
  &amp;lt;/description&amp;gt;
  &amp;lt;rationale&amp;gt;
    &amp;lt;xhtml:p&amp;gt;
      The domain in which a process runs defines the SELinux controls that are active on the process. Services such as PostgreSQL have an established policy set that controls what a database service can and cannot do on the system.
    &amp;lt;/xhtml:p&amp;gt;
    &amp;lt;xhtml:p&amp;gt;
      If the PostgreSQL daemon does not run in the postgresql_t domain, then SELinux might either block regular activities of the database (service availability impact), block behavior that impacts its effectiveness (integrity issue) or allow behavior that shouldn&amp;#39;t be allowed. The latter can have significant consequences once a vulnerability is exploited.
    &amp;lt;/xhtml:p&amp;gt;
  &amp;lt;/rationale&amp;gt;
  &amp;lt;fixtext&amp;gt;
    Restore the context of the file using restorecon or chcon.
  &amp;lt;/fixtext&amp;gt;
  &amp;lt;fix strategy=&amp;quot;restrict&amp;quot; system=&amp;quot;urn:xccdf:fix:script:sh&amp;quot;&amp;gt;restorecon /opt/postgresql/bin/postgres
  &amp;lt;/fix&amp;gt;
  &amp;lt;ident system=&amp;quot;http://example.com/configbaseline&amp;quot;&amp;gt;pgsql-01032&amp;lt;/ident&amp;gt;
&amp;lt;/Rule&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Although this is lots of XML, it is easy to see what each element declares. The &lt;a href="https://csrc.nist.gov/CSRC/media/Publications/nistir/7275/rev-4/final/documents/nistir-7275r4_updated-march-2012_clean.pdf"&gt;NIST IR 7275 document&lt;/a&gt; is a very good resource to continuously consult in order to find the right elements and their interpretation.&lt;/p&gt;
&lt;p&gt;There is one element added that is "specific" to the content of this blog post series and not the XCCDF standard, namely the identification. As mentioned in an earlier post, organizations might have their own taxonomy for technical service identification, and requirements on how to number or identify rules. In the above example, the rule is identified as &lt;code&gt;pgsql-01032&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There is another attribute in use above that might need more clarification: the weight of the rule.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abusing CVSS for configuration weight scoring&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the above example, a weight is given to the rule scoring (weight of 5.1). This number is obtained through a &lt;a href="https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:N/UI:N/S:C/C:L/I:L/A:N/E:U/RL:O/CR:H/IR:H/AR:H/MAV:N/MAC:H/MPR:N/MUI:N/MS:U/MC:L/MI:N/MA:L"&gt;CVSS calculator&lt;/a&gt;, which is generally used to identify the risk of a security issue or vulnerability. CVSS stands for &lt;em&gt;Common Vulnerability Scoring System&lt;/em&gt; and is a popular way to weight security risks (which are then associated with vulnerability reports, &lt;em&gt;Common Vulnerabilities and Exposures (CVE)&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Misconfigurations can also be slightly interpreted as a security risk, although it requires some mental bridges. Rather than scoring the rule, you score the risk that it mitigates, and consider the worst thing that could happen if that rule is not implemented correctly. Now, worst-case thinking is subjective, so there will always be discussion on the weight of a rule. It is therefore important to have a consensus in the team (if the configuration baseline is team-owned) if this weight is actively used. Of course, an organization might choose to ignore the weight, or use a different scoring mechanism.&lt;/p&gt;
&lt;p&gt;In the above situation, I scored what would happen if a vulnerability in PostgreSQL was successfully exploited, and SELinux couldn't mitigate the risk as the label of the file was wrong. The result of a wrong label &lt;em&gt;could be&lt;/em&gt; that the PostgreSQL service runs in a higher privileged domain, or even in an unconfined domain (no SELinux restrictions active), so there is a heightened risk of confidentiality loss (beyond the database) and even integrity risk.&lt;/p&gt;
&lt;p&gt;However, the confidentiality risk is scored as low, and integrity even in between (base risk is low, but due to other constraints put in place integrity impact is reduced further) because PostgreSQL runs as a non-administrative user on the system, and perhaps because the organization uses dedicated systems for database hosting (so other services are not easily impacted).&lt;/p&gt;
&lt;p&gt;As mentioned, this is somewhat abusing the CVSS methodology, but is imo much more effective than trying to figure out your own scoring methodology. With CVSS, you start with scoring the risk regardless of context (CVSS Base), then adjust based on recent state or knowledge (CVSS Temporal), and finally adjust further with knowledge of the other settings or mitigating controls in place (CVSS Environmental).&lt;/p&gt;
&lt;p&gt;Personally, I prefer to only use the CVSS Base scoring for configuration baselines, because the other two are highly depending on time (which is, for documentation, challenging) and the other controls (which is more of a concern for service technical documentation). So in my preferred situation, the rule would be scored as 5.4 rather than 5.1. But that's just me.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Isn't this CCE?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;People who use SCAP a bit more might already be thinking if I'm not reinventing the wheel here. After all, SCAP also has a standard called &lt;em&gt;Common Configuration Enumeration (CCE)&lt;/em&gt; which seems to be exactly what I'm doing here: enumerating the configuration of a technical service. And indeed, if you look at the &lt;a href="https://nvd.nist.gov/config/cce/index"&gt;CCE list&lt;/a&gt; you'll find a number of Excel sheets (sigh) that define common configurations.&lt;/p&gt;
&lt;p&gt;For instance, for Red Hat Enterprise Linux v5, there is an enumeration identified as CCE-4361-2, which states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;File permissions for /etc/pki/tls/ldap should be set correctly&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The CCE description then goes on stating that this is a permission setting (CCE Parameter), which can be rectified with &lt;code&gt;chmod&lt;/code&gt; (CCE Technical Mechanism), and refers to a source for the setting.&lt;/p&gt;
&lt;p&gt;However, CCE has a number of downsides.&lt;/p&gt;
&lt;p&gt;First of all, it isn't being maintained anymore. And although XCCDF itself is also a quite old standard, it is still being looked into (a draft new version is being prepared) and is actively used as a standard. Red Hat is investing time and resources into secure configurations and compliancy aligned with SCAP, and other vendors publish SCAP-specific resources as well. CCE however would be a list, and thus requires continuous management. That RHELv5 is the most recent RHEL CCE list is a bad thing.&lt;/p&gt;
&lt;p&gt;Second, CCE's structure is for me insufficient to use in configuration baselines. XCCDF has a much more mature and elaborate set of settings for this. What CCE does is actually what I use in the above example as the organization-specific identifier.&lt;/p&gt;
&lt;p&gt;Finally, there aren't many tools that actively use CCE, unlike CVSS, XCCDF, OVAL, CVSS and other standards under the SCAP umbrella, which are all still actively used and developed upon by tools such as Open-SCAP.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Profiling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before finishing this post, I want to talk about profiling.&lt;/p&gt;
&lt;p&gt;Within an XCCDF benchmark, several profiles can be defined. In the XCCDF template I defined a single profile that covers all rules, but this can be fine-tuned to the needs of the organization. In XCCDF profiles, you can select individual rules (which ones are active for a profile and which ones aren't) and even fine-tune values for rules. This is called tailoring in XCCDF.&lt;/p&gt;
&lt;p&gt;A first use case for profiles is to group different rules based on the selected setup. In case of Nginx for instance, one can consider Nginx being used as either a reverse proxy, a static website hosting or a dynamic web application hosting. In all three cases, some rules will be the same, but several rules will be different. Within XCCDF, you can document all rules, and then use profiles to group the rules related to a particular service use.&lt;/p&gt;
&lt;p&gt;XCCDF allows for profile inheritance. This means that you can define a base Profile (all the rules that need to be applied, regardless of the service use) and then extend the profiles with individual rule selections.&lt;/p&gt;
&lt;p&gt;With profiles, you can also fine-tune values. For instance, you could have a password policy in place that states that passwords on internal machines have to be at least 10 characters long, but on DMZ systems they need to be at least 15 characters long. Instead of defining two rules, the rule could refer to a particular variable (Value in XCCDF) which is then selected based on the Profile. The value for a password length is then by default 10, but the Profile for DMZ systems selects the other value (15).&lt;/p&gt;
&lt;p&gt;Now, value-based tailoring is imo already a more advanced use of XCCDF, and is best looked into when you also start using OVAL or other automated checks. The tailoring information is then passed on to the automated compliance check so that the right value is validated.&lt;/p&gt;
&lt;p&gt;Value-based tailoring also makes rules either more complex to write, or ambiguous to interpret without full profile awareness. Considering the password length requirement, the rule could become:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The /etc/pam.d/password-auth file must refer to pam_passwdqc.so for the password service with a minimal password length of 10 (default) or 15 (DMZ) for the N4 password category&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At least the rule is specific. Another approach would be to document it as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The /etc/pam.d/password-auth file must refer to pam_passwdqc.so with the proper organizational password controls&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The documentation of the rule might document the proper controls further, but the rule is much less specific. Later checks might report that a system fails this check, referring to the title, which is insufficient for engineers or administrators to resolve.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Generating the guide&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To close off this post, let's finish with how to generate the guide based on an XCCDF document. Personally, I use two approaches for this.&lt;/p&gt;
&lt;p&gt;The first one is to rely on Open-SCAP. With Open-SCAP, you can generate guides easily:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf generate guide xccdf.xml &amp;gt; ConfigBaseline.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The second one, which I use more often, is a custom XSL style sheet, which also introduces the knowledge and interpretations of what this blog post series brings up (including the organizational identification). The end result is similar (the same content) but uses a structure/organization that is more in line with expectations.&lt;/p&gt;
&lt;p&gt;For instance, in my company, the information security officers want to have a tabular overview of all the rules in a configuration baseline. So the XSL style sheet generates such a tabular overview, and uses in-documenting linking to the more elaborate descriptions of all the rules.&lt;/p&gt;
&lt;p&gt;An &lt;a href="https://blog.siphos.be/static/2018/xccdf.xsl"&gt;older version&lt;/a&gt; is online for those interested. It uses JavaScript as well (in case you are security sensitive you might want to look into it) to allow collapsing rule documentation for faster online viewing.&lt;/p&gt;
&lt;p&gt;The custom XSL has an additional advantage, namely that there is no dependency on Open-SCAP to generate the guides (even though it is perfectly possible to copy the XSL and continue). I can successfully generate the guide using &lt;a href="https://www.microsoft.com/en-us/download/details.aspx?id=21714"&gt;Microsoft's msxml&lt;/a&gt; utility, using xsltproc, etc depending on the platform I'm on.&lt;/p&gt;</content><category term="Security"></category><category term="xccdf"></category><category term="scap"></category><category term="baseline"></category></entry><entry><title>Structuring a configuration baseline</title><link href="https://blog.siphos.be/2018/01/structuring-a-configuration-baseline/" rel="alternate"></link><published>2018-01-17T09:10:00+01:00</published><updated>2018-01-17T09:10:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2018-01-17:/2018/01/structuring-a-configuration-baseline/</id><summary type="html">&lt;p&gt;A good configuration baseline has a readable structure that allows all stakeholders to quickly see if the baseline is complete, as well as find a particular setting regardless of the technology. In this blog post, I'll cover a possible structure of the baseline which attempts to be sufficiently complete and technology agnostic.&lt;/p&gt;
&lt;p&gt;If you haven't read the blog post on &lt;a href="https://blog.siphos.be/2018/01/documenting-configuration-changes/"&gt;documenting configuration changes&lt;/a&gt;, it might be a good idea to do so as it declares the scope of configuration baselines and why I think XCCDF is a good match for this.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;A good configuration baseline has a readable structure that allows all stakeholders to quickly see if the baseline is complete, as well as find a particular setting regardless of the technology. In this blog post, I'll cover a possible structure of the baseline which attempts to be sufficiently complete and technology agnostic.&lt;/p&gt;
&lt;p&gt;If you haven't read the blog post on &lt;a href="https://blog.siphos.be/2018/01/documenting-configuration-changes/"&gt;documenting configuration changes&lt;/a&gt;, it might be a good idea to do so as it declares the scope of configuration baselines and why I think XCCDF is a good match for this.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Chaptered documentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As mentioned previously, a configuration baseline describes the configuration of a particular technological service (rather than a business service which is an integrated set of technologies and applications). To document and maintain the configuration state of the technology, I suggest the following eight chapters (to begin with):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Architecture&lt;/li&gt;
&lt;li&gt;Operating system and services&lt;/li&gt;
&lt;li&gt;Software deployment and file system&lt;/li&gt;
&lt;li&gt;Technical service settings&lt;/li&gt;
&lt;li&gt;Authentication, authorization, access control and auditing&lt;/li&gt;
&lt;li&gt;Service specific settings&lt;/li&gt;
&lt;li&gt;Cryptographic services&lt;/li&gt;
&lt;li&gt;Data and information handling&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Within each chapter, sections can be declared depending on how the technology works. For instance, for database technologies one can have a distinction between system-wide settings, instance-specific settings and even database-specific settings. Or, if the organization has specific standards on user definitions, a chapter on "User settings" can be used. The above is just a suggestion in an attempt to cover most aspects of a configuration baseline.&lt;/p&gt;
&lt;p&gt;With the sections of the chapter, rules are then defined which specify the actual configuration setting (or valid range) applicable to the technology. But the rule goes further than just a single-line configuration setting description.&lt;/p&gt;
&lt;p&gt;Each rule should have a &lt;em&gt;unique identifier&lt;/em&gt; so that other documents can reliably link to the rules in the document. Although XCCDF has a convention for this, I feel that the XCCDF way here is more useful for technical referencing while the organization is better off with a more human addressable approach. So while a rule in XCCDF has the identifier &lt;code&gt;xccdf_com.example.postgresql_rule_selinux-enforcing&lt;/code&gt; the human addressable identifier would be &lt;code&gt;postgresql_selinux-enforcing&lt;/code&gt; or even &lt;code&gt;postgresql-00001&lt;/code&gt;. In the company that I work for, we already have a taxonomy for services and a decision to use numerical identifiers on the configuration baseline rules.&lt;/p&gt;
&lt;p&gt;Each rule should be properly described, documenting what the rule is for. In case of a ranged value, it should also document how this range can be properly applied. For instance, if the number of worker threads is based on the number of cores available in the system, document the formula.&lt;/p&gt;
&lt;p&gt;Each rule should also document the risk that it wants to mitigate (be it a security risk, or a manageability aspect of the service, or a performance related tuning parameter). This aspect of the baseline is important whenever an implementation wants an exception to the rule (not follow it) or a deviation (different value). Personally, to make sure that the baseline is manageable, I don't expect engineers to immediately fill in the risk in great detail, but rather holistically. The actual risk determination is then only done when an implementation wants an exception or deviation, and then includes a list of potential mitigating actions to take. This way, a 300+ rule document does not require all 300+ rules to have a risk determination, especially if only a dozen or so rules have exceptions or deviations in the organization.&lt;/p&gt;
&lt;p&gt;Each rule should have sources linked to it. These sources help the reader understand what the rule is based on, such as a publicly available secure configuration baseline, an audit recommendation, a specific incident, etc. If the rule is also controversial, it might benefit from links to meeting minutes.&lt;/p&gt;
&lt;p&gt;Each rule might have consequences listed as well. These are known changes or behavior aspects that follow the implementation of the rule. For instance, a rule might state that TLS mutual authentication is mandatory, and the consequence is that all interacting clients must have a properly defined certificate (so proper PKI requirements) as well as client registration in the application.&lt;/p&gt;
&lt;p&gt;Finally, and importantly as well, each rule identifies the scope at which exceptions or deviations can be granted. For smaller groups and organizations, this might not matter that much, but for larger organizations, some configuration baseline rules can be "approved" by a small team or by the application owner, while others need formal advise of a security officer and approval on a decision body.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Finding a balanced approval hierarchy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The exception management for configuration baselines should not be underestimated. It is not viable to have all settings handled by top management decision bodies, but some configuration changes might result in such a huge impact that a formal decision needs to be taken somewhere, with proper accountability assigned (yes, this is the architect in me speaking).&lt;/p&gt;
&lt;p&gt;Rather than attempting to create a match for all rules, I again like to keep the decision here in the middle, just like I do with the risk determination. The maintainer of the configuration baseline can leave the "scope" of a rule open, and have an intermediate decision body as the main decision body. Whenever an exception or deviation is asked, the risk determination is made and filled in, and with this documented rule now complete a waiver is asked on the decision body. Together with the waiver request, the maintainer also asks this decision body if the rule in the future also needs to be granted on that decision body or elsewhere.&lt;/p&gt;
&lt;p&gt;The scope is most likely tied to the impact of the rule towards other services. A performance specific rule that only affects the application hosted on the technology can be easily scoped as being application-only. This means that the application or service owner can decide to deviate from the baseline. A waiver for a rule that influences system behavior might need to be granted by the system administrator (or team) as well as application or service owners that use this system. Following this logic, I generally use the following scope terminology:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tbd (to be determined), meaning that there is no assessment done yet&lt;/li&gt;
&lt;li&gt;application, meaning that the impact is only on a single application and thus can be taken by the application owner&lt;/li&gt;
&lt;li&gt;instance, meaning that the impact is on an instance and thus might be broader than a single application, but is otherwise contained to the technology. Waivers are granted by the responsible system administrator and application owner(s)&lt;/li&gt;
&lt;li&gt;system, meaning that the impact is on the entire system and thus goes beyond the technology. Waivers are granted by the responsible system administrator, application owner(s) and with advise from a security officer&lt;/li&gt;
&lt;li&gt;network, meaning that the impact can spread to other systems or influence behavior of other systems, but remains technical in nature. Waivers are granted by an infrastructure architecture board with advise from a security officer&lt;/li&gt;
&lt;li&gt;organization, meaning that the impact goes beyond technical influence but also impacts business processes. Waivers are granted by an architecture board with advise from a security officer and senior service owner, and might even be redirected to a higher management board.&lt;/li&gt;
&lt;li&gt;group, meaning that the impact influences multiple businesses. Waivers are granted by a specific management board&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each scope also has a "-pending" value, so "network-pending". This means that the owner of the configuration baseline suggests that this is the scope on which waivers can be established, but still needs to receive formal validation.&lt;/p&gt;
&lt;p&gt;The main decision body is then a particular infrastructure architecture board, which will redirect requests to other decision bodies if the scope goes beyond what that architecture board handles.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Architectural settings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first chapter in a baseline is perhaps the more controversial one, as it is not a technical setting and hard to validate. However, in my experience, tying architectural constraints in a configuration baseline is much more efficient than having a separate track for a number of reasons.&lt;/p&gt;
&lt;p&gt;For one, I strongly believe that architecture deviations are like configuration deviations. They should be documented similarly, and follow the same path as configuration baseline deviations. The scope off architectural rules are also all over the place, from application-level impact up to organization-wide.&lt;/p&gt;
&lt;p&gt;Furthermore, architectural positioning of services should not be solely an (infrastructure) architecture concern, but supported by the other stakeholders as well, and especially the responsible for the technology service.&lt;/p&gt;
&lt;p&gt;For instance, a rule could be that no databases should be positioned within an organizations &lt;em&gt;DeMilitarized Zone (DMZ)&lt;/em&gt;, which is a network design that shields off internally positioned services from the outside world. Although this is not a configuration setting, it makes sense to place it in the configuration baseline of the database technology. There are several ways to validate automatically if this rule is followed, depending for instance the organization IP plan.&lt;/p&gt;
&lt;p&gt;Another rule could be that web applications that host browser-based applications should only be linked through a reverse proxy, or that a load balancer must be put in front of an application server, etc. This might result in additional rules in the chapter that covers access control as well (such as having a particular IP filter in place), but these rules are the consequence of the architectural positioning of the service.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Operating system and services&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The second chapter covers settings specific to the operating system on which the technology is deployed. Such settings can be system-wide settings like Linux' sysctl parameters, services which need to be enabled or disabled when the technology is deployed, and deviations from the configuration baseline of the operating system.&lt;/p&gt;
&lt;p&gt;An example of the latter depends of course on the configuration baseline of the operating system (assuming this is a baseline for a technology deployed on top of an operating system, it could very well be a different platform). Suppose for instance that the baseline has the &lt;code&gt;squashfs&lt;/code&gt; kernel module disabled, but the technology itself requires squashfs, then a waiver is needed. This is the level where this is documented.&lt;/p&gt;
&lt;p&gt;Another setting could be an extension of the SSH configuration (the term "services" in the chapter title here focuses on system services, such as OpenSSH), or the implementation of additional audit rules on OS-level (although auditing can also be covered in a different section).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Software deployment and file system&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The third chapter focuses on the installation of the technology itself, and the file system requirements related to the technology service.&lt;/p&gt;
&lt;p&gt;Rules here look into file ownership and permissions, mount settings, and file system declarations. Some baselines might even define rules about integrity of certain files (the &lt;em&gt;Open Vulnerability and Assessment Language (OVAL)&lt;/em&gt; supports checksum-based validations) although I think this is better tackled through a specific integrity process. Still, if such an integrity process does not exist and automated validation of baselines is implemented, then integrity validation of critical files could be in scope.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Technical service settings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the fourth chapter, settings are declared regarding the service without being service-specific. A service-specific setting is one that requires functional knowledge of the service, whereas technical service settings can be interpreted without functionally understanding the technology at hand.&lt;/p&gt;
&lt;p&gt;Let's take PostgreSQL as an example. A service-specific setting would be the maximum number of non-frozen transaction IDs before a VACUUM operation is triggered (the &lt;code&gt;autovacuum_freeze_max_age&lt;/code&gt; parameter). If you are not working with PostgreSQL much, then this makes as much sense as &lt;a href="https://en.wikipedia.org/wiki/Prisencolinensinainciusol"&gt;Prisencolinensinainciusol&lt;/a&gt;. It sounds like English, but that's about as far as you get.&lt;/p&gt;
&lt;p&gt;A technical service setting on PostgreSQL that is likely more understandable is the runtime account under which the database runs (you don't want it to run as root), or the TCP port on which it listens. Although both are technical in nature, they're much more understandable for others and, perhaps the most important reason of all, often more reusable in deployments across technologies.&lt;/p&gt;
&lt;p&gt;This reusability is key for larger organizations as they will have numerous technologies to support, and the technical service settings offer a good baseline for initial secure setup. They focus on the runtime account of the service, the privileges of the runtime account (be it capability-based on Linux or account rights on Windows), the interfaces on which the service is reachable, the protocol or protocols it supports, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Authentication, authorization, access control and auditing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The next chapter focuses on the &lt;em&gt;Authentication, Authorization and Accounting (AAA)&lt;/em&gt; services, but slightly worded differently (AAA is commonly used in networking related setups, I just borrow it and extend it). If the configuration baseline is extensive, then it might make sense to have separate sections for each of these security concepts.&lt;/p&gt;
&lt;p&gt;Some technologies have a strong focus on user management as well. In that case, it might make sense to first describe the various types of users that the technology supports (like regular users, machine users, internal service users, shared users, etc.) and then, per user type, document how these security services act on it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service specific settings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The next chapter covers settings that are very specific to the service. These are often the settings that are found in the best practices documentation, secure deployment instructions of the vendor, performance tuning parameters, etc.&lt;/p&gt;
&lt;p&gt;I tend to look first at the base configuration and administration guides for technologies, and see what the main structure is that those documents follow. Often, this can be borrowed for the configuration baseline. Next, consider performance related tuning, as that is often service specific and not related to the other chapters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cryptographic services&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this chapter, the focus is on the cryptographic services and configuration.&lt;/p&gt;
&lt;p&gt;The most well-known example here is related to any TLS configuration and tuning. Whereas the location of the private key (used for TLS services) is generally mentioned in the third chapter (or at least the secure storage of the private key), this section will focus on using this properly. It looks at selecting proper TLS version, making a decent and manageable set of ciphers to support, enabling &lt;em&gt;Online Certificate Status Protocol (OCSP)&lt;/em&gt; on web servers, etc.&lt;/p&gt;
&lt;p&gt;But services often use cryptographic related algorithms in various other places as well. Databases can provide transparent data file encryption to ensure that offline access to the database files does not result in data leakage for instance. Or they implement column-level encryption.&lt;/p&gt;
&lt;p&gt;Application servers might support crypto related routines to the applications they host, and the configuration baseline can then identify which crypto modules are supported and which ones aren't.&lt;/p&gt;
&lt;p&gt;Services might be using cryptographic hashes which are configurable, or could be storing user passwords in a database using configurable settings. OpenLDAP for instance supports multiple hashing methods (and also supports storing in plain-text if you want this), so it makes sense to select a hashing method that is hard to brute-force (slow to compute for instance) and is salted (to make certain types of attacks more challenging).&lt;/p&gt;
&lt;p&gt;If the service makes use of stored credentials or keytabs, document how they are protected here as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data and information handling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Information handling covers both the regular data management activities (like backup/restore, data retention, archival, etc.) as well as sensitive information handling (to comply with privacy rules).&lt;/p&gt;
&lt;p&gt;The regular data management related settings look into both the end user data handling (as far as this is infrastructurally related - this isn't meant to become a secure development guide) as well as service-internal data handling. When the technology is meant to handle data (like a database or LDAP) then certain related settings could be both in the service specific settings chapter or in this one. Personally, I tend to prefer that technology-specific and non-reusable settings are in the former, while the data and information handling chapter covers the integration and technology-agnostic data handling.&lt;/p&gt;
&lt;p&gt;If the service handles sensitive information, it is very likely that additional constraints or requirements were put in place beyond the "traditional" cryptographic requirements. Although such requirements are often implemented on the application level (like tagging the data properly and then, based on the tags, handle specific fine-grained access controls, archival and data retention), more and more technologies provide out-of-the-box (or at least reusable) methods that can be configured.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;An XCCDF template&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To support the above structure, I've made an &lt;a href="https://blog.siphos.be/static/2018/xccdf-template.xml"&gt;XCCDF template&lt;/a&gt; that might be a good start for documenting the configuration baseline of a technology. It also structures the chapters a bit more with various sections, but those are definitely not mandatory to use as it strongly depends on the technology being documented, the maturity of the organization, etc.&lt;/p&gt;</content><category term="Security"></category><category term="xccdf"></category><category term="scap"></category><category term="baseline"></category></entry><entry><title>Documenting configuration changes</title><link href="https://blog.siphos.be/2018/01/documenting-configuration-changes/" rel="alternate"></link><published>2018-01-07T21:20:00+01:00</published><updated>2018-01-07T21:20:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2018-01-07:/2018/01/documenting-configuration-changes/</id><summary type="html">&lt;p&gt;IT teams are continuously under pressure to set up and maintain infrastructure services quickly, efficiently and securely. As an infrastructure architect, my main concerns are related to the manageability of these services and the secure setup. And within those realms, a properly documented configuration setup is in my opinion very crucial.&lt;/p&gt;
&lt;p&gt;In this blog post series, I'm going to look into using the &lt;em&gt;Extensible Configuration Checklist Description Format (XCCDF)&lt;/em&gt; as the way to document these. This first post is an introduction to XCCDF functionally, and what I position it for.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;IT teams are continuously under pressure to set up and maintain infrastructure services quickly, efficiently and securely. As an infrastructure architect, my main concerns are related to the manageability of these services and the secure setup. And within those realms, a properly documented configuration setup is in my opinion very crucial.&lt;/p&gt;
&lt;p&gt;In this blog post series, I'm going to look into using the &lt;em&gt;Extensible Configuration Checklist Description Format (XCCDF)&lt;/em&gt; as the way to document these. This first post is an introduction to XCCDF functionally, and what I position it for.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Documentation is a good thing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With the ongoing struggle for time and resources, documenting configurations and architectures is often not top-of-mind. However, the lack of this information also leads to various problems: incidents due to misconfiguration, slow recovery timings due to incomprehensible setups, and not to forget: meetings. Yes, meetings, which are continuously discussing service aspects that influence one or more parameters, without any good traceability of past decisions.&lt;/p&gt;
&lt;p&gt;Some technologies allow to keep track of some metadata regarding to configurations. In configuration management tools like &lt;a href="https://puppet.com"&gt;Puppet&lt;/a&gt; or &lt;a href="https://saltstack.com"&gt;Saltstack&lt;/a&gt; engineers define the target state of their infrastructure, and the configuration management tool enforces this state on the service. Engineers can add in historical information as comments into these systems, and use version control on the files to have traceability of the settings.&lt;/p&gt;
&lt;p&gt;However, although in-line comments are very important, even for configuration sets, it is not a full documentation approach. In larger environments, where you are regularly audited for quality and security, or where multiple roles and stakeholders need to understand the settings and configuration of services, pointing to the code is not going to cut it.&lt;/p&gt;
&lt;p&gt;Configuration items need to be documented not solely with the documentation rule itself, but with the motivation related to it, and additional fields of interest depending on how the organization deals with it. This documentation can then be referred to from the configuration management infrastructure (so engineers and technical stakeholders can trace back settings) but also vice-versa: the documentation can refer to the configuration management implementation (so other stakeholders can deduce how the settings are implemented or even enforced).&lt;/p&gt;
&lt;p&gt;With a proper configuration document at hand, especially if it is supported through the configuration management tool(s) in the organization (regardless if it is one or multiple), it is much easier to have the necessary interviews with auditors, project leaders, functional and technical analysts, architects or even remote support teams.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Two-part documentation hierarchy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first thing to decide upon is at which level a team will document the settings. Is a single document possible for all infrastructure services? Most likely not. I believe that settings should be documented on the technology level (as it is specific to a particular technology) and on the 'business service' level (as it is specific to a particular implementation).&lt;/p&gt;
&lt;p&gt;On the technology level, we're talking about configuration documentation for "PostgreSQL", "Apache Knox" or "Nginx". At this level, the baseline is defined for a technology. The resulting document is then the &lt;em&gt;configuration baseline&lt;/em&gt; for that component.&lt;/p&gt;
&lt;p&gt;On the business service level, we're talking about configuration documentation for a particular service that is a combination of multiple implementations. For instance, a company intranet portal service is operationally implemented through a reverse proxy (HAProxy), an intelligent load balancer (Seesaw), next-gen firewall (pfSense), web server (Nginx), application server (Node.js), database (PostgreSQL), and operating systems (Linux). And more technologies come into play when we consider software deployment, monitoring, backup/restore, software-defined network, storage provisioning, archival solutions, license management services, etc.&lt;/p&gt;
&lt;p&gt;Hence, a configuration document should be available on this service level ("company intranet portal") which defines the usage profile of a service (more about that later) and the specific parameters related to this service, but only when they either deviate from the configuration baseline, or take a particular value within a range defined in the configuration baseline. This document is the &lt;em&gt;service technical configuration&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;So, as an example, on the Nginx configuration baseline, a rule might state that the maximum file size per upload is 12M (through the &lt;code&gt;client_max_body_size&lt;/code&gt; parameter). If the service has no problem with this rule, then it does not need to be documented on the service technical configuration. However, if this needs to be adapted (say that for the company portal the maximum file size is 64M) then it is documented.&lt;/p&gt;
&lt;p&gt;Another example is a ranged setting, where the baseline identifies a set of valid values and the service technical configuration makes a particular selection. For instance, the Nginx configuration baseline might mention that there must be between 5 and 50 worker processes (through the &lt;code&gt;worker_processes&lt;/code&gt; parameter). In the service technical configuration the particular value is then selected.&lt;/p&gt;
&lt;p&gt;From an architecture and security point of view, the first example is a deviation which must consider the risks and consequences that are applicable to the rule. These are (or should be) documented in the configuration baseline, including where this deviation can be approved (assuming the organization has a decision body for such things). The second example is not a deviation and, as such, is free to be chosen by the implementation team. The configuration baseline will generally inform the implementation teams about how to pick a proper value.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service usage profiles&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I've talked about a &lt;em&gt;service usage profile&lt;/em&gt; earlier up, but didn't expand on it yet. So, what are these service usage profiles?&lt;/p&gt;
&lt;p&gt;Well, most technologies can be implemented for a number of targets and functional purposes. A database could be implemented as a dedicated service (one set of databases on a dedicated set of instances for a single business service) or a shared service (multiple databases, possibly on multiple instances for several business services). It can be tuned for online transactional purposes (OLTP) or online analytical processing (OLAP), often through data warehouse designs.&lt;/p&gt;
&lt;p&gt;A service usage profile is part of the configuration baseline, with settings specific to that particular usage. So for a database the engineering team responsible for the database technology setup might devise that the following usage profiles are applicable to their component:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dedicated OLTP&lt;/li&gt;
&lt;li&gt;Shared OLTP&lt;/li&gt;
&lt;li&gt;Dedicated DWH&lt;/li&gt;
&lt;li&gt;Shared DWH&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each usage profile has a number of configuration settings (of which many, if not most, are shared across other usage profiles) and a range of valid values (fine-tuning for a service). The service technical configuration for a particular business service then selects the particular usage profile. For instance, the company intranet portal might use a Dedicated OLTP usage profile for its PostgreSQL database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How XCCDF supports this structure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Until now, I've only spoken about the values related to configuration documentation, and a high-level introduction to the hierarchy on the configurations. But how does the &lt;a href="https://scap.nist.gov/specifications/xccdf/"&gt;Extensible Configuration Checklist Description&lt;/a&gt; position itself in this?&lt;/p&gt;
&lt;p&gt;A number of reasons why XCCDF is a valid choice for configuration documentation are given next.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;XCCDF allows technical writers to write the documentation in (basic) HTML while still linking the documentation to specific rules. Rather than having to use a tabular expression on all the valid configuration sets (like using a large spreadsheet table for all rules) and trying to force some documentation in it (Excel is not a text editor), XCCDF uses a hierarchical approach to structure documentation in logical sections (which it calls &lt;em&gt;Groups&lt;/em&gt;) and then refers to the rules applicable to that section (using the &lt;em&gt;Rule&lt;/em&gt; identifier).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;XCCDF has out-of-the-box support for service profiles (through &lt;em&gt;Profile&lt;/em&gt; declarations). Fine-tuning and selecting profiles is called &lt;em&gt;tailoring&lt;/em&gt; in XCCDF. This also includes support for ranged values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;XCCDF is meant to (but does not have to) refer to the (automated or interview-based) validation of the rules as well. Automated validation of settings means that an engine can read the XCCDF document (and the referred statements) and check if an implementation adheres to the baseline. The standard for this is called &lt;em&gt;Open Vulnerability and Assessment Language (OVAL)&lt;/em&gt;, and a popular free software engine for this is &lt;a href="https://www.open-scap.org"&gt;OpenSCAP&lt;/a&gt;. The standard for interview-based validation is &lt;em&gt;Open Checklist Interactive Language (OCIL)&lt;/em&gt;. I have not played around with OCIL and supporting tooling, so comments on this are always welcome.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;XCCDF is an XML-based format, so its "source code" can easily be versioned in common version control systems like Git. This allows organizations to not only track changes on the documentation, but also have an active development lifecycle management on the configuration documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;XCCDFs schema implies a set of metadata to be defined during various declarations. It includes support for the &lt;a href="http://www.dublincore.org/specifications/"&gt;Dublin core metadata&lt;/a&gt; terms for content, references to link other resources structurally, and most importantly has a wide set of supporting entities for rules (which is the level on which configuration items are documented). This includes the rationale (why is the rule defined as is), fix text (human readable), fix (machine readable), rule role (is it security-sensitive and as such must be taken up in a security assessment report or not), severity (how bad is it if this rule is not followed), and many more. This both forces the user to consider the consequences of the rule, as well as guide the writer into properly structured documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;XCCDF also suggests a number of classes for the documentation to standardize certain information types. This includes warnings, critical text, examples, and instructions. Such semantic declarations allow for a more uniform set of documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, a few constraints exist that you need to be aware of when approaching XCCDF.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;XCCDF is an XML-based document format, and although NIST offers the necessary XML Schema definitions, writing proper XML has always been a challenge for many people. Also, no decent GUI or WYSIWYG tool that manages XCCDF files exists in my opinion. Yes, we have the &lt;a href="https://www.open-scap.org/tools/scap-workbench/"&gt;SCAP Workbench&lt;/a&gt; and the &lt;a href="https://www.g2-inc.com/scap.html"&gt;eSCAPe editor&lt;/a&gt;, but I feel that they are not as effective as they should be. As a result, the team or teams that write the baselines should either be XML-savvy, or you need to provide supporting infrastructure and services for it. However, YMMV.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the organization is not interested in compliance checks themselves (i.e. automated validation of adherence to the configuration baseline and service technical configuration) then XCCDF will entail too much overhead versus just having a template or approach (such as documenting items in a wiki). However, with some support (and perhaps automation) writing and maintaining XCCDF based configuration baselines becomes much easier.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;More resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the past I've &lt;a href="http://blog.siphos.be/tag/xccdf/"&gt;blogged about XCCDF&lt;/a&gt; already, but that was with a previous blog technology and the migration wasn't as successful as I originally thought. XML snippets were all removed, and I'm too lazy to go back to my backups from 2013 and individually correct blogs.&lt;/p&gt;
&lt;p&gt;A good resource on XCCDF is the &lt;a href="https://csrc.nist.gov/CSRC/media/Publications/nistir/7275/rev-4/final/documents/nistir-7275r4_updated-march-2012_clean.pdf"&gt;NIST IR-7275 publication (PDF)&lt;/a&gt; which covers the XCCDF standard in much detail.&lt;/p&gt;
&lt;p&gt;The Center for Internet Security (CISecurity) maintains more than a hundred &lt;a href="https://www.cisecurity.org/cis-benchmarks/"&gt;CIS Benchmarks&lt;/a&gt;, all available for free as PDFs, and are often based on XCCDF (available to subscribed members).&lt;/p&gt;
&lt;p&gt;In the next blog post, I'll talk about the in-document structure of a good configuration baseline.&lt;/p&gt;</content><category term="Security"></category><category term="xccdf"></category><category term="scap"></category><category term="baseline"></category></entry><entry><title>Authenticating with U2F</title><link href="https://blog.siphos.be/2017/09/authenticating-with-u2f/" rel="alternate"></link><published>2017-09-11T18:25:00+02:00</published><updated>2017-09-11T18:25:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2017-09-11:/2017/09/authenticating-with-u2f/</id><summary type="html">&lt;p&gt;In order to further secure access to my workstation, after the &lt;a href="http://blog.siphos.be/2017/08/switch-to-gentoo-sources/"&gt;switch to Gentoo
sources&lt;/a&gt;, I now enabled two-factor authentication through my Yubico U2F
USB device. Well, at least for local access - remote access through SSH requires
both userid/password as well as the correct SSH key, by &lt;a href="https://lwn.net/Articles/544640/"&gt;chaining authentication
methods in OpenSSH&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Enabling U2F on (Gentoo) Linux is fairly easy. The various guides online which talk
about the &lt;code&gt;pam_u2f&lt;/code&gt; setup are indeed correct that it is fairly simple. For completeness
sake, I've documented what I know on the Gentoo Wiki, as the &lt;a href="https://wiki.gentoo.org/wiki/Pam_u2f"&gt;pam_u2f article&lt;/a&gt;.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;In order to further secure access to my workstation, after the &lt;a href="http://blog.siphos.be/2017/08/switch-to-gentoo-sources/"&gt;switch to Gentoo
sources&lt;/a&gt;, I now enabled two-factor authentication through my Yubico U2F
USB device. Well, at least for local access - remote access through SSH requires
both userid/password as well as the correct SSH key, by &lt;a href="https://lwn.net/Articles/544640/"&gt;chaining authentication
methods in OpenSSH&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Enabling U2F on (Gentoo) Linux is fairly easy. The various guides online which talk
about the &lt;code&gt;pam_u2f&lt;/code&gt; setup are indeed correct that it is fairly simple. For completeness
sake, I've documented what I know on the Gentoo Wiki, as the &lt;a href="https://wiki.gentoo.org/wiki/Pam_u2f"&gt;pam_u2f article&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;The setup, basically&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The setup of U2F is done in a number of steps:
1. Validate that the kernel is ready for the USB device
2. Install the PAM module and supporting tools
3. Generate the necessary data elements for each user (keys and such)
4. Configure PAM to require authentication through the U2F key&lt;/p&gt;
&lt;p&gt;For the kernel, the configuration item needed is the raw HID device support.
Now, in current kernels, two settings are available that both talk about
raw HID device support: &lt;code&gt;CONFIG_HIDRAW&lt;/code&gt; is the general raw HID device support,
while &lt;code&gt;CONFIG_USB_HIDDEV&lt;/code&gt; is the USB-specific raw HID device support.&lt;/p&gt;
&lt;p&gt;It is very well possible that only a single one is needed, but both where active
on my kernel configuration already, and Internet sources are not clear which one is
needed, so let's assume for now both are.&lt;/p&gt;
&lt;p&gt;Next, the PAM module needs to be installed. On Gentoo, this is a matter of installing
the &lt;code&gt;pam\_u2f&lt;/code&gt; package, as the necessary dependencies will be pulled in automatically:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~# emerge pam_u2f
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next, for each user, a registration has to be made. This registration is needed for the
U2F components to be able to correctly authenticate the use of a U2F key for a particular
user. This is done with &lt;code&gt;pamu2fcfg&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ pamu2fcfg -u&amp;lt;username&amp;gt; &amp;gt; ~/.config/Yubico/u2f_keys
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The U2F USB key must be plugged in when the command is executed, as a succesful keypress (on the
U2F device) is needed to complete the operation.&lt;/p&gt;
&lt;p&gt;Finally, enable the use of the &lt;code&gt;pam\_u2f&lt;/code&gt; module in PAM. On my system, this is done
through the &lt;code&gt;/etc/pam.d/system-local-login&lt;/code&gt; PAM configuration file used by all
local logon services.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;auth     required     pam_u2f.so
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Consider the problems you might face&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When fiddling with PAM, it is important to keep in mind what could fail. During the setup, it
is recommended to have an open administrative session on the system so that you can validate if
the PAM configuration works, without locking yourself out of the system.&lt;/p&gt;
&lt;p&gt;But other issues need to be considered as well.&lt;/p&gt;
&lt;p&gt;My Yubico U2F USB key might have a high MTBF (Mean Time Between Failures) value, but once it fails,
it would lock me out of my workstation (and even remote services and servers that use it). For
that reason, I own a second one, safely stored, but is a valid key nonetheless for my workstation
and remote systems/services. Given the low cost of a simple U2F key, it is a simple solution for
this threat.&lt;/p&gt;
&lt;p&gt;Another issue that could come up is a malfunction in the PAM module itself. For me, this is handled
by having remote SSH access done without this PAM module (although other PAM modules are still involved,
so a generic PAM failure itself wouldn't resolve this). Of course, worst case, the system needs to be
rebooted in single user mode.&lt;/p&gt;
&lt;p&gt;One issue that I faced was the SELinux policy. Some applications that provide logon services don't have
the proper rights to handle U2F, and because PAM just works in the address space (and thus SELinux
domain) of the application, the necessary privileges need to be added to these services. My initial
investigation revealed the following necessary policy rules (refpolicy-style);&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;udev_search_pids(...)
udev_read_db(...)
dev_rw_generic_usb_dev(...)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first two rules are needed because the operation to trigger the USB key uses the udev tables
to find out where the key is located/attached, before it interacts with it. This interaction is then
controlled through the first rule.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simple yet effective&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Enabling the U2F authentication on the system is very simple, and gives a higher confidence that
malicious activities through regular accounts will have it somewhat more challenging to switch to
a more privileged session (one control is the SELinux policy of course, but for those domains that
are allowed to switch then the PAM-based authentication is another control), as even evesdropping on
my password (or extracting it from memory) won't suffice to perform a successful authentication.&lt;/p&gt;
&lt;p&gt;If you want to use a different two-factor authentication, check out the use of the &lt;a href="https://wiki.gentoo.org/wiki/Google_Authenticator"&gt;Google
authenticator&lt;/a&gt;, another nice article on the Gentoo wiki. It is also possible to use Yubico keys
for remote authentication, but that uses the OTP (One Time Password) functionality which isn't active
on the Yubico keys that I own.&lt;/p&gt;</content><category term="Security"></category><category term="gentoo"></category><category term="security"></category><category term="yubico"></category><category term="u2f"></category><category term="pam"></category></entry><entry><title>Matching MD5 SSH fingerprint</title><link href="https://blog.siphos.be/2017/05/matching-md5-ssh-fingerprint/" rel="alternate"></link><published>2017-05-18T18:20:00+02:00</published><updated>2017-05-18T18:20:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2017-05-18:/2017/05/matching-md5-ssh-fingerprint/</id><summary type="html">&lt;p&gt;Today I was attempting to update a local repository, when SSH complained
about a changed fingerprint, something like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the ECDSA key sent by the remote host is
SHA256:p4ZGs+YjsBAw26tn2a+HPkga1dPWWAWX+NEm4Cv4I9s.
Please contact your system administrator.
Add correct host key in /home/user/.ssh/known_hosts to get rid of this message.
Offending ECDSA key in /home/user/.ssh/known_hosts:9
ECDSA host key for 192.168.56.101 has changed and you have requested strict checking.
Host key verification failed.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
</summary><content type="html">&lt;p&gt;Today I was attempting to update a local repository, when SSH complained
about a changed fingerprint, something like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the ECDSA key sent by the remote host is
SHA256:p4ZGs+YjsBAw26tn2a+HPkga1dPWWAWX+NEm4Cv4I9s.
Please contact your system administrator.
Add correct host key in /home/user/.ssh/known_hosts to get rid of this message.
Offending ECDSA key in /home/user/.ssh/known_hosts:9
ECDSA host key for 192.168.56.101 has changed and you have requested strict checking.
Host key verification failed.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;



&lt;p&gt;I checked if the host was changed recently, or the alias through
which I connected switched host, or the SSH key changed. But that
wasn't the case. Or at least, it wasn't the case recently, and I
distinctly remember connecting to the same host two weeks ago.&lt;/p&gt;
&lt;p&gt;Now, what happened I don't know yet, but I do know I didn't want
to connect until I reviewed the received SSH key fingerprint. I
obtained the fingerprint from the administration (who graceously
documented it on the wiki)...&lt;/p&gt;
&lt;p&gt;... only to realize that the documented fingerprint are MD5
hashes (and in hexadecimal result) whereas the key shown by the
SSH command shows it in base64 SHA256 by default.&lt;/p&gt;
&lt;p&gt;Luckily, a quick search revealed this &lt;a href="https://superuser.com/questions/929566/sha256-ssh-fingerprint-given-by-the-client-but-only-md5-fingerprint-known-for-se"&gt;superuser&lt;/a&gt;
post which told me to connect to the host using the
&lt;code&gt;FingerprintHash md5&lt;/code&gt; option:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ ssh -o FingerprintHash=md5 192.168.56.11
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The result is SSH displaying the MD5 hashed fingerprint which I
can now validate against the documented one. Once I validated that
the key is the correct one, I accepted the change and continued
with my endeavour.&lt;/p&gt;
&lt;p&gt;I later discovered (or, more precisely, have strong assumptions)
that I had an old elliptic curve key registered in my &lt;code&gt;known_hosts&lt;/code&gt;
file, which was not used for the communication for quite some time.
I recently re-enabled elliptic curve support in OpenSSH (with Gentoo's
USE="-bindist") which triggered the validation of the old key.&lt;/p&gt;</content><category term="Security"></category><category term="openssh"></category><category term="fingerprint"></category><category term="md5"></category></entry><entry><title>Talk about SELinux on GSE Linux/Security</title><link href="https://blog.siphos.be/2014/03/talk-about-selinux-on-gse-linuxsecurity/" rel="alternate"></link><published>2014-03-25T23:11:00+01:00</published><updated>2014-03-25T23:11:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2014-03-25:/2014/03/talk-about-selinux-on-gse-linuxsecurity/</id><summary type="html">&lt;p&gt;On today's &lt;a href="http://www.gsebelux.com"&gt;GSE Linux / GSE Security&lt;/a&gt; meeting
(in cooperation with
&lt;a href="http://www.imug.be/events_be/IMUG_LinuxSecurity_Event.asp"&gt;IMUG&lt;/a&gt;) I
gave a small (30 minutes) presentation about what SELinux is. The
&lt;a href="http://dev.gentoo.org/~swift/blog/201403/20140325_GSE_SELinux.pdf"&gt;slides are
online&lt;/a&gt;
and cover two aspects of SELinux: some of its design principles, and
then a set of features provided by SELinux. The talk is directed …&lt;/p&gt;</summary><content type="html">&lt;p&gt;On today's &lt;a href="http://www.gsebelux.com"&gt;GSE Linux / GSE Security&lt;/a&gt; meeting
(in cooperation with
&lt;a href="http://www.imug.be/events_be/IMUG_LinuxSecurity_Event.asp"&gt;IMUG&lt;/a&gt;) I
gave a small (30 minutes) presentation about what SELinux is. The
&lt;a href="http://dev.gentoo.org/~swift/blog/201403/20140325_GSE_SELinux.pdf"&gt;slides are
online&lt;/a&gt;
and cover two aspects of SELinux: some of its design principles, and
then a set of features provided by SELinux. The talk is directed towards
less technical folks - still IT of course, but not immediately involved
in daily operations - so no commands and example/output.&lt;/p&gt;
&lt;p&gt;SELinux came across the board a few times during the entire day. In the
talks about &lt;em&gt;Open Source Security&lt;/em&gt; and &lt;em&gt;Security Guidelines for z/VM and
Linux on System z&lt;/em&gt; SELinux came (of course) up as the technology of
choice for providing in-operating system mandatory access control (on
the zEnterprise' Z/VM level - the hypervisor - this is handled through
RACF Mandatory Access Control) and the &lt;em&gt;Security Enablement on Virtual
Machines&lt;/em&gt; had SELinux in the front line for the sVirt security
protection measures (which focuses on the segregation through MLS
categories).&lt;/p&gt;
&lt;p&gt;And during the talk about &lt;em&gt;A customer story about logging and audit&lt;/em&gt;,
well, you can guess which technology is also one of the many sources of
logging. Right. SELinux ;-)&lt;/p&gt;
&lt;p&gt;Anyway, if your company is interested in such GSE events, make sure to
follow the &lt;a href="http://www.gsebelux.com"&gt;gsebelux.com&lt;/a&gt; site for updates.
It's a great way for networking as well as sharing experiences.&lt;/p&gt;</content><category term="Security"></category><category term="gse"></category><category term="mainframe"></category><category term="s390x"></category><category term="security"></category><category term="selinux"></category><category term="zenterprise"></category></entry><entry><title>Giving weights to compliance rules</title><link href="https://blog.siphos.be/2013/12/giving-weights-to-compliance-rules/" rel="alternate"></link><published>2013-12-26T04:13:00+01:00</published><updated>2013-12-26T04:13:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-26:/2013/12/giving-weights-to-compliance-rules/</id><summary type="html">&lt;p&gt;Now that we wrote up a few OVAL statements and used those instead of SCE
driven checks (where possible), let's finish up and go back to the XCCDF
document and see how we can put weights in place.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;CVE (Common Vulnerability Exposure)&lt;/strong&gt; standard allows for
vulnerabilities to be given …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Now that we wrote up a few OVAL statements and used those instead of SCE
driven checks (where possible), let's finish up and go back to the XCCDF
document and see how we can put weights in place.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;CVE (Common Vulnerability Exposure)&lt;/strong&gt; standard allows for
vulnerabilities to be given weights through a scoring mechanism called
&lt;strong&gt;CVSS (Common Vulnerability Scoring System)&lt;/strong&gt;. The method for giving
weights to such vulnerabilities is based on several factors, which you
can play with through an &lt;a href="https://nvd.nist.gov/cvss.cfm?calculator&amp;amp;version=2"&gt;online CVSS
calculator&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Giving weights on a vulnerability based on these metrics is not that
difficult, but what about compliance misconfigurations?&lt;/p&gt;
&lt;p&gt;There is a suggested standard for this, &lt;strong&gt;CCSS (Common Configuration
Scoring System)&lt;/strong&gt; which is based on the CVSS scoring and CMSS scoring.
Especially the base scoring is tailored to the CVSS scoring, so let's
look at an example from the &lt;a href="http://dev.gentoo.org/~swift/docs/security_benchmarks/guide-gentoo-xccdf.html"&gt;Gentoo Security
Benchmark&lt;/a&gt;
(still in draft):&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;The base scoring of a misconfiguration focuses on the following items:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Access Vector (AV)&lt;/dt&gt;
&lt;dd&gt;How can the misconfiguration be "reached" or exploited - Local (on
the system), Adjacent Network or Network&lt;/dd&gt;
&lt;dt&gt;Access Complexity (AC)&lt;/dt&gt;
&lt;dd&gt;How complex would it be to exploit the misconfiguration - High,
Medium or Low&lt;/dd&gt;
&lt;dt&gt;Authentication (Au)&lt;/dt&gt;
&lt;dd&gt;Does the attacker need to be authenticated in order to exploit the
misconfiguration - None, Single (one account) or Multiple (several
accounts or multi-factor authenticated)&lt;/dd&gt;
&lt;dt&gt;Confidentiality (C)&lt;/dt&gt;
&lt;dd&gt;Does a successful exploit have impact on the confidentiality of the
system or data (None, Partial or Complete)&lt;/dd&gt;
&lt;dt&gt;Integrity (I)&lt;/dt&gt;
&lt;dd&gt;Does a successful exploit have impact on the integrity of the system
or data (None, Partial or Complete)&lt;/dd&gt;
&lt;dt&gt;Availability (A)&lt;/dt&gt;
&lt;dd&gt;Does a successful exploit have impact on the availability of the
system or data (None, Partial or Complete)&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;In order to exploit that &lt;code&gt;/tmp&lt;/code&gt; is not on a separate file system, we can
think about dumping lots of information in &lt;code&gt;/tmp&lt;/code&gt;, flooding the root
file system. This is simple to accomplish locally and requires a single
authentication (you need to be authenticated on the system). Once
performed, this only impacts availability.&lt;/p&gt;
&lt;p&gt;The CCSS (and thus CVSS) base vector looks like so:
&lt;code&gt;AV:L/AC:L/Au:S/C:N/I:N/A:C&lt;/code&gt; and gives a base score of 4.6, which is
reflected in the XCCDF in the &lt;code&gt;weight="4.6"&lt;/code&gt; attribute.&lt;/p&gt;
&lt;p&gt;The severity I give in the XCCDF is "gut feeling". Basically, I use the
following description:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;high constitutes a grave or critical problem. A rule with this
    severity MUST be tackled as it detected a misconfiguration that is
    easily exploitable and could lead to full system compromise.&lt;/li&gt;
&lt;li&gt;medium reflects a fairly serious problem. A rule with this severity
    SHOULD be tackled as it detected a misconfiguration that is
    easily exploitable.&lt;/li&gt;
&lt;li&gt;low reflects a non-serious problem. A rule with this severity has
    detected a misconfiguration but its influence on the overall system
    security is minor (if other compliance rules are followed).&lt;/li&gt;
&lt;li&gt;info reflects an informational rule. Failure to comply with this
    rule does not mean failure to comply with the document itself.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, you can put your own weights and severities in your XCCDF
documents. Important however is to make sure it is properly documented -
other people who read the document must be aware of the consequences of
the rules if they are not compliant.&lt;/p&gt;
&lt;p&gt;By introducing weights and severities, administrators of systems that
are not compliant (or of a large set of systems) can prioritize which
misconfigurations or vulnerabilities they will handle first. And it
reduces the amount of discussions as well, because without these, your
administrators will start debating what to tackle first, each with their
own vision and opinion. Which is great, but not when time is ticking.
Having a predefined priority list makes it clear how to react now.&lt;/p&gt;
&lt;p&gt;That's it for this post series. I hope you enjoyed it and learned from
it. Of course, this wont be the last post related to SCAP so stay tuned
for more ;-)&lt;/p&gt;
&lt;p&gt;This post is the final one in a series on SCAP content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;Documenting security best practices – XCCDF
    introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;An XCCDF skeleton for
    PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;Documenting a bit more than just
    descriptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;Running a bit with the XCCDF
    document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/remediation-through-scap/"&gt;Remediation through
    SCAP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/what-is-oval/"&gt;What is OVAL?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/doing-a-content-check-with-oval/"&gt;Doing a content check with
    OVAL&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Security"></category><category term="ccss"></category><category term="cvss"></category><category term="scap"></category><category term="xccdf"></category></entry><entry><title>Doing a content check with OVAL</title><link href="https://blog.siphos.be/2013/12/doing-a-content-check-with-oval/" rel="alternate"></link><published>2013-12-24T04:25:00+01:00</published><updated>2013-12-24T04:25:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-24:/2013/12/doing-a-content-check-with-oval/</id><summary type="html">&lt;p&gt;Let's create an OVAL check to see if &lt;code&gt;/etc/inittab&lt;/code&gt;'s single user
definitions only refer to &lt;code&gt;/sbin/sulogin&lt;/code&gt; or &lt;code&gt;/sbin/rc single&lt;/code&gt;. First,
the skeleton:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;The first thing we notice is that there are several namespaces defined
within OVAL. These namespaces refer to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let's create an OVAL check to see if &lt;code&gt;/etc/inittab&lt;/code&gt;'s single user
definitions only refer to &lt;code&gt;/sbin/sulogin&lt;/code&gt; or &lt;code&gt;/sbin/rc single&lt;/code&gt;. First,
the skeleton:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;The first thing we notice is that there are several namespaces defined
within OVAL. These namespaces refer to the platforms on which the tests
can be executed. OVAL has independent definitions, unix-global
definitions or linux-specific definitions. You can find the overview of
&lt;a href="http://oval.mitre.org/language/version5.10.1/"&gt;all supported schemas and definitions
online&lt;/a&gt; - definitely
something to bookmark if you plan on developing your own OVAL checks.&lt;/p&gt;
&lt;p&gt;So let's create the definition:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;There is lots of information to be found in this simple snippet.&lt;/p&gt;
&lt;p&gt;First of all, notice the &lt;code&gt;class="compliance"&lt;/code&gt; part. OVAL definitions can
be given a class that informs the OVAL interpreter what kind of test it
is.&lt;/p&gt;
&lt;p&gt;Supported classes are:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;compliance&lt;/dt&gt;
&lt;dd&gt;Does the system adhere to a predefined wanted state&lt;/dd&gt;
&lt;dt&gt;inventory&lt;/dt&gt;
&lt;dd&gt;Is the given software or hardware available/installed on the system&lt;/dd&gt;
&lt;dt&gt;patch&lt;/dt&gt;
&lt;dd&gt;Is the selected patch installed on the system&lt;/dd&gt;
&lt;dt&gt;vulnerability&lt;/dt&gt;
&lt;dd&gt;Is the system vulnerable towards this particular exposure (CVE)&lt;/dd&gt;
&lt;dt&gt;miscellaneous&lt;/dt&gt;
&lt;dd&gt;Everything that doesn't fit the above&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Next, we see metadata that tells the OVAL interpreter that the
definition applies to Unix family systems, and more specifically a
Gentoo Linux system. However, this is not a CPE entry
(&lt;em&gt;cpe:/o:gentoo:linux&lt;/em&gt;). The idea is that the OVAL Interpreter should
interpret the information as it wants without focusing on CPE details -
I think (I might be mistaken though) because the SCAP standard does not
want to introduce loops - a CPE that refers to an OVAL to validate,
which in turn refers to the same CPE.&lt;/p&gt;
&lt;p&gt;Also, a reference is included in the OVAL. Remember that we also had
references in the XCCDF document? Well, the same is true for OVAL
statements - you can add in references that help administrators get more
information about a definition. In this case, it refers to a &lt;strong&gt;CCE
(Common Configuration Enumeration)&lt;/strong&gt; entry. You can find all official
CCE entries &lt;a href="https://nvd.nist.gov/cce/index.cfm"&gt;online as well&lt;/a&gt;. This
particular one, CCE-4241-6, sais:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;CCE-4241-6  Platform: rhel5     Date: (C)2011-10-07   (M)2013-11-28

The requirement for a password to boot into single-user mode should be configured correctly.

Parameter: enabled/disabled

Technical Mechanism: via /etc/inittab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By requiring &lt;strong&gt;sulogin&lt;/strong&gt; or &lt;strong&gt;rc single&lt;/strong&gt; in &lt;code&gt;inittab&lt;/code&gt;, Gentoo Linux
will ask for the root password before granting a shell, thereby
complying with the requirement to have a password before providing a
shell in single-user mode.&lt;/p&gt;
&lt;p&gt;Finally, the definition refers to a single test, which we will now look
into:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;This particular test is part of the &lt;em&gt;independent&lt;/em&gt; definitions. Checking
the content of a file is something all platforms support. Within this
independent definition set, a &lt;a href="http://oval.mitre.org/language/version5.10.1/ovaldefinition/documentation/independent-definitions-schema.html"&gt;large set of
tests&lt;/a&gt;
are supported, including file hash checking (does the checksum of a file
still match), environment variable test (verifying the existence and
content of an environment variable), LDAP tests and also text file
content tests.&lt;/p&gt;
&lt;p&gt;In the test, there are two important attributes to closely look into:
&lt;code&gt;check&lt;/code&gt; and &lt;code&gt;check_existence&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;check_existence&lt;/code&gt; attribute tells the OVAL interpreter how to deal
with the object definition. In our case, the object will refer to the
lines in the &lt;code&gt;/etc/inittab&lt;/code&gt; file that match a certain pattern. With
&lt;code&gt;check_existence="at_least_one_exists"&lt;/code&gt; the OVAL interpreter knows it
has to have at least one line that matches the pattern before it can
continue. If no line matches, then the test fails.&lt;/p&gt;
&lt;p&gt;Other values for &lt;code&gt;check_existence&lt;/code&gt; are "all_exist" (every object
described must exist), any_exist (doesn't matter if zero, one or more
exists), none_exist (no object described must exist) and
"only_one_exists" (one, and only one match for the described objects
must exist).&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;check&lt;/code&gt; attributes tells the OVAL interpreter how to match the
object (if there is one) with the state. In our example, &lt;code&gt;check="all"&lt;/code&gt;
tells the OVAL interpreter that all lines that match the object
definition must also match the state definition.&lt;/p&gt;
&lt;p&gt;Other values for &lt;code&gt;check&lt;/code&gt; are "at least one", "none satisfy" and "only
one". These should be self-explanatory. Notice that there are no
underscores involved here (unlike with the &lt;code&gt;check_existence&lt;/code&gt; attribute).&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://oval.mitre.org/language/version5.10.1/ovaldefinition/documentation/oval-common-schema.html"&gt;common
schema&lt;/a&gt;
for more general OVAL attribute information.&lt;/p&gt;
&lt;p&gt;The test refers to the following object:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;The object represents lines in the &lt;code&gt;/etc/inittab&lt;/code&gt; file that match the
expression &lt;code&gt;^[\S]+:S:[\S]+:.*&lt;/code&gt;. The OVAL definition uses &lt;a href="http://oval.mitre.org/language/about/perlre.html"&gt;perl-style
regular expressions&lt;/a&gt;,
so this means that the lines must start with a non-whitespace string,
followed by a colon (:), followed by the letter "S", followed by a
colon, followed by non-whitespace string, followed by colon and then a
remainder string.&lt;/p&gt;
&lt;p&gt;Also, the object evaluates if at least one such line is found.&lt;/p&gt;
&lt;p&gt;The state, also referred to by the test, looks like so:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;Here again we see a regular expression; this time, the expression sais
that the line must start with "su" and that the fourth field equals
&lt;code&gt;/sbin/rc single&lt;/code&gt; or &lt;code&gt;/sbin/sulogin&lt;/code&gt;. In our example, if there is at
least one "single user" line that does not match this expression, then
the OVAL statement will return a failure and the system is
non-compliant.&lt;/p&gt;
&lt;p&gt;Now you could be wondering if this is the best approach. We can create
an object that refers to all single-user lines in &lt;code&gt;/etc/inittab&lt;/code&gt; that do
not comply with the expression just in the object definition. The
expression would be more complex by itself, but wouldn't need a state
anymore. True, but the advantage here is that the object itself matches
all single user lines, and can be reused later in other tests. Also, if
we later evaluate the OVAL statements, we will get an overview of all
lines that match the object (and then evaluate these lines against the
state) - similar to the script output we got with SCE tests.&lt;/p&gt;
&lt;p&gt;We can create other OVALs for all other tests. To refer to these OVAL
tests in an XCCDF document, take a look at the following example:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;Instead of referring to the SCE engine (with
&lt;code&gt;system="http://open-scap.org/page/SCE"&lt;/code&gt;) we refer to the OVAL with
&lt;code&gt;system="http://oval.mitre.org/XMLSchema/oval-definitions-5"&lt;/code&gt;, point the
XCCDF interpreter where the OVAL statements are stored in
&lt;code&gt;href="gentoo-oval.xml"&lt;/code&gt; and what definition we want to test
(&lt;code&gt;oval:org.gentoo.dev.swift:def:22&lt;/code&gt;). The XCCDF interpreter will then
pass this information on to the OVAL interpreter (in case of openscap,
this is the same tool, but it doesn't have to be) so it can evaluate the
right OVAL statement on the system.&lt;/p&gt;
&lt;p&gt;In the next post, I'll use the &lt;a href="http://dev.gentoo.org/~swift/docs/security_benchmarks/guide-gentoo-xccdf.html"&gt;Gentoo Security
Benchmark&lt;/a&gt;
as a guide to explain how to further structure and document things in
XCCDF/OVAL.&lt;/p&gt;
&lt;p&gt;This post is part of a series on SCAP content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;Documenting security best practices - XCCDF
    introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;An XCCDF skeleton for
    PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;Documenting a bit more than just
    descriptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;Running a bit with the XCCDF
    document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/remediation-through-scap/"&gt;Remediation through
    SCAP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/what-is-oval/"&gt;What is OVAL?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Security"></category><category term="openscap"></category><category term="oval"></category><category term="scap"></category><category term="xccdf"></category></entry><entry><title>What is OVAL?</title><link href="https://blog.siphos.be/2013/12/what-is-oval/" rel="alternate"></link><published>2013-12-22T04:40:00+01:00</published><updated>2013-12-22T04:40:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-22:/2013/12/what-is-oval/</id><summary type="html">&lt;p&gt;Time to discuss &lt;strong&gt;OVAL (Open Vulnerability Assessment Language)&lt;/strong&gt;. In
all the &lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;previous
posts&lt;/a&gt;
I focused the checking of rules (does the system comply with the given
rule) on scripts, through the Script Check Engine supported by openscap.
The advantage of SCE is that most people can quickly provide automated
checks …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Time to discuss &lt;strong&gt;OVAL (Open Vulnerability Assessment Language)&lt;/strong&gt;. In
all the &lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;previous
posts&lt;/a&gt;
I focused the checking of rules (does the system comply with the given
rule) on scripts, through the Script Check Engine supported by openscap.
The advantage of SCE is that most people can quickly provide automated
checks to run in script format. But SCE has a few downsides.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You cannot guarantee that the scripts will do no harm on the system.
    A badly written script might manipulate system settings, get a huge
    amount of resources, leave stale result files on the system, flood
    file systems and more. If you get scripts from other parties, you'll
    need to review them thoroughly before running them against all
    your systems. Especially when you run the compliance validation tool
    (openscap in our example) as root.&lt;/li&gt;
&lt;li&gt;SCE support is only available for openscap (and perhaps one or
    two others) as it is not an international standard. If you use any
    of the &lt;a href="https://nvd.nist.gov/scapproducts.cfm"&gt;SCAP validated tools&lt;/a&gt;
    then you will not be able to benefit from the SCE scripts. And that
    would make the XCCDF document back to a purely documenting
    best practice.&lt;/li&gt;
&lt;li&gt;Every rule requires separate scripts, even though many of the rules
    will be very similar and thus reuse a lot of the scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OVAL on the other hand provides those advantages. An OVAL file is an XML
file that contains the tests to run, in an (I must say) somewhat complex
manner. Really, OVAL is not simple, but it does contain advantages that
SCE doesn't.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is a standard, part of the SCAP standards. OVAL files are
    reusable across multiple tools, allowing you to focus once on the
    rules rather than having to rewrite the rules for every time you
    change the tool.&lt;/li&gt;
&lt;li&gt;OVAL can be platform-agnostic. Of course, not all tests are
    platform-agnostic (validating registry keys is a Windows-only check)
    but many are.&lt;/li&gt;
&lt;li&gt;All rules can be mentioned in a single file (or spread across
    multiple files if that makes management easier), but more
    importantly rules will also reuse definitions from other rules. If
    you have three rules that pertain to a file (say &lt;code&gt;/etc/rc.conf&lt;/code&gt;)
    then the definition of that file is shared across all rules.&lt;/li&gt;
&lt;li&gt;The OVAL standard is designed to be non-intrusive. All declarations
    you do in an OVAL file are pure read-only statements. This gives
    more confidence to have OVAL statements from third parties ran
    across your organization. Of course, reviewing them never hurts, but
    you already know that they will not modify any setting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Like SCE, OVAL checks are individual checks that are executed and
returned. They too return a success or failure (or error) and can
deliver more detailed information as part of their result (like the SCE
results output we looked at before) so allow administrators to
investigate further why a rule failed (without needing to log on to the
system and look for themselves).&lt;/p&gt;
&lt;p&gt;A basic structure of OVAL is a &lt;em&gt;definition&lt;/em&gt; that describes what the rule
is for. The definition refers to one or more &lt;em&gt;tests&lt;/em&gt; that are evaluated
on a system. These tests refer to an &lt;em&gt;object&lt;/em&gt; that needs to be checked,
and optionally a &lt;em&gt;state&lt;/em&gt; to which the object should (or shouldn't)
match.&lt;/p&gt;
&lt;p&gt;Consider the test we made with SCE to see if a platform is a Gentoo
Linux system:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;span class="normal"&gt;1&lt;/span&gt;
&lt;span class="normal"&gt;2&lt;/span&gt;
&lt;span class="normal"&gt;3&lt;/span&gt;
&lt;span class="normal"&gt;4&lt;/span&gt;
&lt;span class="normal"&gt;5&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="c1"&gt;# If /etc/gentoo-release exists then the system is a Gentoo Linux system.&lt;/span&gt;
&lt;span class="nb"&gt;test&lt;/span&gt; -f /etc/gentoo-release &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;XCCDF_RESULT_PASS&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;XCCDF_RESULT_FAIL&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;p&gt;In OVAL, this would be structured as follows (pseudo-OVAL):&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;definition&lt;/dt&gt;
&lt;dd&gt;The system is a Gentoo Linux system&lt;/dd&gt;
&lt;dt&gt;test&lt;/dt&gt;
&lt;dd&gt;The object that represents /etc/gentoo-release must exist&lt;/dd&gt;
&lt;dt&gt;object&lt;/dt&gt;
&lt;dd&gt;The /etc/gentoo-release file&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;The resulting OVAL file is quite complex for a simple rule. I see the
OVAL complexity as part of a normalization (similar to database
normalization) process to allow higher reuse. If we later want to check
the content of the &lt;code&gt;gentoo-release&lt;/code&gt; file, we will reuse the definition
(object with id &lt;em&gt;oval:org.gentoo.dev.swift:obj:1&lt;/em&gt;) rather than making a
second object for it, and use that definition to create new tests.&lt;/p&gt;
&lt;p&gt;The structure of OVAL is the same everywhere. First define the
definitions, then the tests, then the objects and then, optionally, the
states. A very important aspect is to have the identifiers (&lt;code&gt;id="..."&lt;/code&gt;)
correct. The structure of OVAL identifiers is standardized as well:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;namespace&lt;/dt&gt;
&lt;dd&gt;Like the namespace used in XCCDF documents, this is the reverse
notation of a domainname. In the example above, this
is org.gentoo.dev.swift.&lt;/dd&gt;
&lt;dt&gt;type&lt;/dt&gt;
&lt;dd&gt;The type of the entry in OVAL. This can be def (definition), tst
(test), obj (object), ste (state) or var (variable).&lt;/dd&gt;
&lt;dt&gt;id&lt;/dt&gt;
&lt;dd&gt;The identifier of this particular entry. This identifier has to be a
positive integer.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;By standardizing the identifiers, you can create repositories within
your organization, and have other teams reuse your OVAL components when
needed. As the identifier remains the same (even when you update the
OVAL object itself to be more precise) those tests keep validating
correctly. For instance, say that Gentoo Linux would be changed in the
future not to provide a &lt;code&gt;gentoo-release&lt;/code&gt; file anymore, but
&lt;code&gt;gentoo-linux-release&lt;/code&gt; file instead (not that it is planning that, it is
just hypothetical), then you can update the test (with description
"Gentoo Linux is installed") to check if either of the two files exist:&lt;/p&gt;
&lt;p&gt;(XML content lost due to blog conversion)&lt;/p&gt;
&lt;p&gt;If we save all Gentoo releated OVAL statements in a file called
&lt;code&gt;gentoo-oval.xml&lt;/code&gt; then we can update the &lt;code&gt;gentoo-cpe.xml&lt;/code&gt; file (which we
discussed in the past) to the following:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;With this change, openscap (or any other XCCDF interpreter) will use the
OVAL definition to see if a platform is Gentoo Linux or not, and does
not need to execute the &lt;code&gt;gentoo-platform.sh&lt;/code&gt; script anymore, which is
now fully deprecated and superceded by the OVAL statement.&lt;/p&gt;
&lt;p&gt;In the next posts, I'll write up one of the other tests we had (which
checks the content of a file - one of the most used tests I think) in
OVAL, and have the XCCDF document updated to only use OVAL statements.&lt;/p&gt;
&lt;p&gt;This post is part of a series on SCAP content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;Documenting security best practices - XCCDF
    introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;An XCCDF skeleton for
    PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;Documenting a bit more than just
    descriptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;Running a bit with the XCCDF
    document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/remediation-through-scap/"&gt;Remediation through
    SCAP&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Security"></category><category term="openscap"></category><category term="oval"></category><category term="scap"></category><category term="sce"></category><category term="xccdf"></category></entry><entry><title>Remediation through SCAP</title><link href="https://blog.siphos.be/2013/12/remediation-through-scap/" rel="alternate"></link><published>2013-12-20T04:47:00+01:00</published><updated>2013-12-20T04:47:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-20:/2013/12/remediation-through-scap/</id><summary type="html">&lt;p&gt;I promised in my &lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;previous
post&lt;/a&gt;
to give some information about remediation.&lt;/p&gt;
&lt;p&gt;Remediation is the process where you fix a system to become compliant
again after finding out there is a violation on the system. The easiest
form of remediation of course is to just notify the administrator and
give …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I promised in my &lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;previous
post&lt;/a&gt;
to give some information about remediation.&lt;/p&gt;
&lt;p&gt;Remediation is the process where you fix a system to become compliant
again after finding out there is a violation on the system. The easiest
form of remediation of course is to just notify the administrator and
give him the instructions to fix the problem - and in the majority of
cases, this is exactly what you will do, considering that automatically
fixing things might create more breakage if you are not careful.&lt;/p&gt;
&lt;p&gt;But suppose that you know, for a few rules, what the remediation really
should be, and you want to automate it. Well, in that case, you can
document the remediation (the commands or scripts) in the XCCDF
document. As you might have noticed in the previous example, this is
handled through a &lt;code&gt;&amp;lt;fix&amp;gt;&lt;/code&gt; entity.&lt;/p&gt;
&lt;p&gt;In the fix, we mention how the fix should be executed
(&lt;em&gt;urn:xccdf:fix:system:commands&lt;/em&gt; is to tell the XCCDF interpreter that
the remediation are commands executed on the command line (or verbatim
within a script). The platform attribute allows us to differentiate
based on the platform (or even version of the platform). The other
attributes, such as &lt;em&gt;complexity&lt;/em&gt;, &lt;em&gt;disruption&lt;/em&gt; and &lt;em&gt;reboot&lt;/em&gt; is metadata
that helps in deciding which auto-remediation you want to execute.&lt;/p&gt;
&lt;p&gt;With openscap, the remediation can be triggered online during the
evaluation, by adding &lt;code&gt;--remediate&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf eval --remediate --profile ${PROFILE} --cpe gentoo-cpe.xml --results results-test-xccdf.xml test-xccdf.xml
Title   There should be no /dev/ROOT in /etc/fstab
Rule    xccdf_org.gentoo.dev.swift_rule_installation-fstab-root
Result  pass

Title   There should be no /dev/BOOT in /etc/fstab
Rule    xccdf_org.gentoo.dev.swift_rule_installation-fstab-boot
Result  pass

Title   rc_sys should be defined in /etc/rc.conf
Rule    xccdf_org.gentoo.dev.swift_rule_installation-rc_sys
Result  fail

 --- Starting remediation ---
Title   rc_sys should be defined in /etc/rc.conf
Rule    xccdf_org.gentoo.dev.swift_rule_installation-rc_sys
Result  fixed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And indeed, the file has been changed and now complies with the rules
again.&lt;/p&gt;
&lt;p&gt;We can also generate the remediation scripts offline:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf eval --profile ${PROFILE} --results results-test-xccdf.xml --cpe gentoo-cpe.xml test-xccdf.xml
~$ oscap xccdf generate fix --output remediate.sh results-test-xccdf.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The resulting &lt;code&gt;remediate.sh&lt;/code&gt; script then contains the steps to remediate
the failures reported in the &lt;code&gt;results-test-xccdf.xml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;In general however, auto-remediation is not that recommended. The amount
of effort you put in creating remediation scripts that are safe to
execute is huge. If you do this for a single system, it is much easier
to just remediate manually. If you need to do it for a large set of
systems, it makes more sense to use a configuration management solution
like &lt;a href="http://www.ansibleworks.com/"&gt;ansible&lt;/a&gt; or
&lt;a href="http://puppetlabs.com/"&gt;puppet&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, now that we have experience with documenting our best practices and
running validation, I'll talk about OVAL in the next post.&lt;/p&gt;
&lt;p&gt;This post is part of a series on SCAP content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;Documenting security best practices - XCCDF
    introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;An XCCDF skeleton for
    PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;Documenting a bit more than just
    descriptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/"&gt;Running a bit with the XCCDF
    document&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Security"></category><category term="openscap"></category><category term="remediation"></category><category term="scap"></category><category term="xccdf"></category></entry><entry><title>Running a bit with the XCCDF document</title><link href="https://blog.siphos.be/2013/12/running-a-bit-with-the-xccdf-document/" rel="alternate"></link><published>2013-12-18T04:23:00+01:00</published><updated>2013-12-18T04:23:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-18:/2013/12/running-a-bit-with-the-xccdf-document/</id><summary type="html">&lt;p&gt;In my &lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;previous
post&lt;/a&gt;
I introduced automated checking of rules through &lt;em&gt;SCE (Script Check
Engine)&lt;/em&gt;. Let's focus a bit more now on running with an XCCDF document:
how to automatically check the system, read the results and find more
information of those results.&lt;/p&gt;
&lt;p&gt;To provide a usable example, you can …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In my &lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;previous
post&lt;/a&gt;
I introduced automated checking of rules through &lt;em&gt;SCE (Script Check
Engine)&lt;/em&gt;. Let's focus a bit more now on running with an XCCDF document:
how to automatically check the system, read the results and find more
information of those results.&lt;/p&gt;
&lt;p&gt;To provide a usable example, you can download the following files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/test-xccdf.txt"&gt;test-xccdf.xml&lt;/a&gt;,
    a sample XCCDF document that documents and tests a few settings
    (save it with the &lt;code&gt;.xml&lt;/code&gt; extension, I publish it as txt to make
    downloading and viewing easier).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/gentoo-cpe.txt"&gt;gentoo-cpe.xml&lt;/a&gt;
    which defines when a system is a Gentoo system (I'll cover this in
    a minute).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/gentoo-platform.sh"&gt;gentoo-platform.sh&lt;/a&gt;
    which is the script that tests if a system is a Gentoo system.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/gentoo-fstab-noroot.sh"&gt;gentoo-fstab-noroot.sh&lt;/a&gt;
    which tests that &lt;code&gt;/dev/ROOT&lt;/code&gt; is not set in &lt;code&gt;/etc/fstab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/gentoo-fstab-noboot.sh"&gt;gentoo-fstab-noboot.sh&lt;/a&gt;
    which tests that &lt;code&gt;/dev/BOOT&lt;/code&gt; is not set in &lt;code&gt;/etc/fstab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/gentoo-rc.conf-rc_sys.sh"&gt;gentoo-rc.conf-rc_sys.sh&lt;/a&gt;
    which tests that the &lt;code&gt;rc_sys&lt;/code&gt; variable is declared in
    &lt;code&gt;/etc/rc.conf&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Extract it to a directory of your choice, and let's get started.&lt;/p&gt;
&lt;p&gt;With &lt;a href="http://www.open-scap.org"&gt;openscap&lt;/a&gt; (available as
&lt;em&gt;app-forensics/openscap&lt;/em&gt; in Gentoo), we can generate a guide of the
XCCDF document as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf generate guide test-xccdf.xml &amp;gt; guide-test-xccdf.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The
&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/guide-test-xccdf.html"&gt;result&lt;/a&gt;
is an HTML guide that reflects the content of the XCCDF document. By
default, it contains all text and rules, but shows no information about
the profiles (if any). We can add in the &lt;code&gt;--profile ...&lt;/code&gt; tag to include
an overview of the checks that are selected if that profile is selected.
That would give a result similar to &lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/guide-test-xccdf-withprofile.html"&gt;this
one&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;--format docbook&lt;/code&gt; arguments, the output can also be DocBook
instead of HTML. The advantage of DocBook is that it can generate a
multitude of other formats, including
&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/guide-test-xccdf-withprofile.pdf"&gt;PDF&lt;/a&gt;,
although I had to do some manual cleanups in the output to have it
render a PDF here using FOP (there are other methods to create PDFs too)
such as removing the &lt;code&gt;&amp;lt;preface&amp;gt;&lt;/code&gt; part.&lt;/p&gt;
&lt;p&gt;Let's try evaluating the XCCDF document on the system:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf eval test-xccdf.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Nothing happened. That is because there are no rules that are by default
selected (all rules in the document have &lt;code&gt;selected="false"&lt;/code&gt;) and we have
not passed on a profile. I don't know if there is a way to automatically
make a particular profile default, so let's try it with the
&lt;em&gt;xccdf_org.gentoo.dev.swift_profile_default&lt;/em&gt; (which I always use as
the default profile name for all my XCCDF documents):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ export PROFILE=&amp;quot;xccdf_org.gentoo.dev.swift_profile_default&amp;quot;
~$ oscap xccdf eval --profile ${PROFILE} test-xccdf.xml

Title   There should be no /dev/ROOT in /etc/fstab
Rule    xccdf_org.gentoo.dev.swift_rule_installation-fstab-root
Result  notapplicable

Title   There should be no /dev/BOOT in /etc/fstab
Rule    xccdf_org.gentoo.dev.swift_rule_installation-fstab-boot
Result  notapplicable

Title   rc_sys should be defined in /etc/rc.conf
Rule    xccdf_org.gentoo.dev.swift_rule_installation-rc_sys
Result  notapplicable
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At least we have output now, but still no results. In fact, all rules
have &lt;em&gt;notapplicable&lt;/em&gt; as a result. What gives?&lt;/p&gt;
&lt;p&gt;The reason is that the XCCDF interpreter (&lt;strong&gt;oscap&lt;/strong&gt;) does not know about
the Gentoo Linux platform, whereas the XCCDF document explicitly
mentions that it is applicable to a Gentoo Linux system.&lt;/p&gt;
&lt;p&gt;What we need to do is to provide the XCCDF interpreter with a test that
helps it evaluate if a system is a Gentoo Linux system or not. In other
words, a test that the XCCDF interpreter will run if the
&lt;em&gt;cpe:/o:gentoo:linux&lt;/em&gt; platform is mentioned. We do this with a &lt;em&gt;CPE
dictionary&lt;/em&gt; element which is saved as
&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/gentoo-cpe.txt"&gt;gentoo-cpe.xml&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the dictionary, the coupling between cpe:/o:gentoo:linux and a scripted
check called gentoo-platform.sh is made. Let's now give this info to oscap:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf eval --profile ${PROFILE} --cpe gentoo-cpe.xml test-xccdf.xml
Title   There should be no /dev/ROOT in /etc/fstab
Rule    xccdf_org.gentoo.dev.swift_rule_installation-fstab-root
Result  pass

Title   There should be no /dev/BOOT in /etc/fstab
Rule    xccdf_org.gentoo.dev.swift_rule_installation-fstab-boot
Result  pass

Title   rc_sys should be defined in /etc/rc.conf
Rule    xccdf_org.gentoo.dev.swift_rule_installation-rc_sys
Result  pass

OpenSCAP Error: Document is empty [./gentoo-platform.sh:1] [elements.c:207]
No definition with ID: (null) in definition model. [oval_probe.c:338]
No definition with ID: (null) in result model. [oval_agent.c:184]
No definition with ID: (null) in definition model. [oval_probe.c:338]
No definition with ID: (null) in result model. [oval_agent.c:184]
No definition with ID: (null) in definition model. [oval_probe.c:338]
No definition with ID: (null) in result model. [oval_agent.c:184]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Great; we now see that openscap ran the tests and gave feedback. It also
gave a few errors. These can be ignored now - it is openscap that tries
to interpret the shell scripts as OVAL scripts (I'll talk about OVAL in
a later post). After changing my system to be non-compliant, I see that
openscap detects that as well:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Title   rc_sys should be defined in /etc/rc.conf
Rule    xccdf_org.gentoo.dev.swift_rule_installation-rc_sys
Result  fail
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, by itself the rule might give us enough clues as to what is wrong,
but sometimes you might want to get the output of the scripts as well.
You can enable this through the &lt;code&gt;--check-engine-results&lt;/code&gt; option. This
will leave the generated output of the scripts available as XML files.&lt;/p&gt;
&lt;p&gt;In it, we see the output (through &lt;code&gt;&amp;lt;sceres:stdout&amp;gt;&lt;/code&gt;) of the &lt;strong&gt;grep&lt;/strong&gt;
command we did in the script.&lt;/p&gt;
&lt;p&gt;Finally, by adding in a &lt;code&gt;--report report-test-xccdf.html&lt;/code&gt; to the
argument list, the results of the XCCDF evaluation is also saved as
&lt;a href="http://dev.gentoo.org/~swift/blog/201312/18/report-test-xccdf.html"&gt;HTML&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The oscap command has many more options, which I will not discuss in
more detail now, but are important to know (for instance, you can save
the XCCDF results in XML format for future processing).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ oscap xccdf eval -h
 oscap -&amp;gt; xccdf -&amp;gt; eval

Perform evaluation driven by XCCDF file and use OVAL as checking engine

Usage: oscap [options] xccdf eval [options] INPUT_FILE [oval-definitions-files]

INPUT_FILE - XCCDF file or a source data stream file

Options:
   --profile               - The name of Profile to be evaluated.
   --tailoring-file        - Use given XCCDF Tailoring file.
   --tailoring-id  - Use given DS component as XCCDF Tailoring file.
   --cpe                   - Use given CPE dictionary or language (autodetected)
                                   for applicability checks.
   --oval-results                - Save OVAL results as well.
   --sce-results                 - Save SCE results as well. (DEPRECATED! use --check-engine-results)
   --check-engine-results        - Save results from check engines loaded from plugins as well.
   --export-variables            - Export OVAL external variables provided by XCCDF.
   --results               - Write XCCDF Results into file.
   --results-arf           - Write ARF (result data stream) into file.
   --report                - Write HTML report into file.
   --skip-valid                  - Skip validation.
   --fetch-remote-resources      - Download remote content referenced by XCCDF.
   --progress                    - Switch to sparse output suitable for progress reporting.
                                   Format is &amp;quot;$rule_id:$result\n&amp;quot;.
   --datastream-id           - ID of the datastream in the collection to use.
                                   (only applicable for source datastreams)
   --xccdf-id                - ID of component-ref with XCCDF in the datastream that should be evaluated.
                                   (only applicable for source datastreams)
   --benchmark-id            - ID of XCCDF Benchmark in some component in the datastream that should be evaluated.
                                   (only applicable for source datastreams)
                                   (only applicable when datastream-id AND xccdf-id are not specified)
   --remediate                   - Automatically execute XCCDF fix elements for failed rules.
                                   Use of this option is always at your own risk.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In my next post, I'll talk a bit more about remediation.&lt;/p&gt;
&lt;p&gt;This post is part of a series on SCAP content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;Documenting security best practices - XCCDF
    introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;An XCCDF skeleton for
    PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/"&gt;Documenting a bit more than just
    descriptions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Security"></category><category term="openscap"></category><category term="scap"></category><category term="sce"></category><category term="xccdf"></category></entry><entry><title>XCCDF - Documenting a bit more than just descriptions</title><link href="https://blog.siphos.be/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/" rel="alternate"></link><published>2013-12-16T04:58:00+01:00</published><updated>2013-12-16T04:58:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-16:/2013/12/xccdf-documenting-a-bit-more-than-just-descriptions/</id><summary type="html">&lt;p&gt;In my &lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;previous
post&lt;/a&gt; I
made a skeleton XCCDF document. By now, we can create a well documented
"baseline" (best practice) for our subject (say PostgreSQL). But for now
I only talked about &lt;code&gt;&amp;lt;description&amp;gt;&lt;/code&gt; whereas XCCDF allows many other tags
as well.&lt;/p&gt;
&lt;p&gt;You can add &lt;em&gt;metadata&lt;/em&gt; information for a particular …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In my &lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;previous
post&lt;/a&gt; I
made a skeleton XCCDF document. By now, we can create a well documented
"baseline" (best practice) for our subject (say PostgreSQL). But for now
I only talked about &lt;code&gt;&amp;lt;description&amp;gt;&lt;/code&gt; whereas XCCDF allows many other tags
as well.&lt;/p&gt;
&lt;p&gt;You can add &lt;em&gt;metadata&lt;/em&gt; information for a particular &lt;code&gt;Group&lt;/code&gt;. It is
recommended to use the &lt;a href="http://dublincore.org/"&gt;dublin core&lt;/a&gt; notation:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)`&lt;/p&gt;
&lt;p&gt;If you use metadata information however, it should &lt;strong&gt;not&lt;/strong&gt; be used
&lt;em&gt;instead&lt;/em&gt; of XCCDF elements.&lt;/p&gt;
&lt;p&gt;Another set of elements that can be used are &lt;code&gt;warning&lt;/code&gt; elements:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;&amp;lt;rationale&amp;gt;&lt;/code&gt; element can be used to explain in more detail why a
rule is important.&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;Some elements we saw before also apply on the specific &lt;code&gt;&amp;lt;Group&amp;gt;&lt;/code&gt;
elements, such as &lt;code&gt;&amp;lt;status&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt;. The combination of these
elements should allow for a pretty good explanation of the secure setup
we want to achieve.&lt;/p&gt;
&lt;p&gt;But documentation is one thing - how about checking something
automatically? Enter the XCCDF &lt;code&gt;Rule&lt;/code&gt; element.&lt;/p&gt;
&lt;p&gt;Rules are particular tests, checks if you wish, that you want to have
executed. To start off, let's look at a &lt;code&gt;Rule&lt;/code&gt; element that, as
automated approach, calls a script. To accomplish this, we use the &lt;strong&gt;SCE
(Script Check Engine)&lt;/strong&gt; method. This is &lt;em&gt;not&lt;/em&gt; part of the SCAP standard
by itself (SCAP uses OVAL for automated checks - I'll discuss OVAL
later) but XCCDF allows for other check systems to be used. And SCE is
supported by &lt;a href="http://www.open-scap.org"&gt;openscap&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;First of all, we have the &lt;code&gt;Rule&lt;/code&gt; element itself, with the specially
crafted &lt;code&gt;id&lt;/code&gt; attribute as seen before. There are three attributes used
in the example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;selected="false"&lt;/code&gt; tells the XCCDF interpreter that the Rule should
    not be automatically selected. In other words, only if a &lt;code&gt;Profile&lt;/code&gt;
    refers to the rule will be rule be triggered (and the
    check executed).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;severity="low"&lt;/code&gt; is a matter of documenting how severe a
    non-compliant rule is.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight="0.0"&lt;/code&gt; gives a weight on the &lt;code&gt;Rule&lt;/code&gt;. In this case, the
    weight is 0, meaning that the rule might be recommended but by
    itself does not introduce a security vulnerability or mismatch. Of
    course, you are free to use whatever value suits you best.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also notice a &lt;code&gt;fixtext&lt;/code&gt; element. When the rule failed (the system is
not compliant to the rule) then the fixtext should assist administrators
in securing the system again. In other words, &lt;code&gt;fixtext&lt;/code&gt; are the
human-readable instructions on remediating the system.&lt;/p&gt;
&lt;p&gt;Finally, we have the &lt;code&gt;check&lt;/code&gt; element. This element tells the XCCDF
interpreter that an automated validation is defined. The type of
automated validation is provided by the &lt;code&gt;system&lt;/code&gt; attribute, which in
this case refers to the SCE system. The &lt;code&gt;check-content-ref&lt;/code&gt; element
refers to the script to be executed.&lt;/p&gt;
&lt;p&gt;Let's look at the contents of the script:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;span class="normal"&gt; 1&lt;/span&gt;
&lt;span class="normal"&gt; 2&lt;/span&gt;
&lt;span class="normal"&gt; 3&lt;/span&gt;
&lt;span class="normal"&gt; 4&lt;/span&gt;
&lt;span class="normal"&gt; 5&lt;/span&gt;
&lt;span class="normal"&gt; 6&lt;/span&gt;
&lt;span class="normal"&gt; 7&lt;/span&gt;
&lt;span class="normal"&gt; 8&lt;/span&gt;
&lt;span class="normal"&gt; 9&lt;/span&gt;
&lt;span class="normal"&gt;10&lt;/span&gt;
&lt;span class="normal"&gt;11&lt;/span&gt;
&lt;span class="normal"&gt;12&lt;/span&gt;
&lt;span class="normal"&gt;13&lt;/span&gt;
&lt;span class="normal"&gt;14&lt;/span&gt;
&lt;span class="normal"&gt;15&lt;/span&gt;
&lt;span class="normal"&gt;16&lt;/span&gt;
&lt;span class="normal"&gt;17&lt;/span&gt;
&lt;span class="normal"&gt;18&lt;/span&gt;
&lt;span class="normal"&gt;19&lt;/span&gt;
&lt;span class="normal"&gt;20&lt;/span&gt;
&lt;span class="normal"&gt;21&lt;/span&gt;
&lt;span class="normal"&gt;22&lt;/span&gt;
&lt;span class="normal"&gt;23&lt;/span&gt;
&lt;span class="normal"&gt;24&lt;/span&gt;
&lt;span class="normal"&gt;25&lt;/span&gt;
&lt;span class="normal"&gt;26&lt;/span&gt;
&lt;span class="normal"&gt;27&lt;/span&gt;
&lt;span class="normal"&gt;28&lt;/span&gt;
&lt;span class="normal"&gt;29&lt;/span&gt;
&lt;span class="normal"&gt;30&lt;/span&gt;
&lt;span class="normal"&gt;31&lt;/span&gt;
&lt;span class="normal"&gt;32&lt;/span&gt;
&lt;span class="normal"&gt;33&lt;/span&gt;
&lt;span class="normal"&gt;34&lt;/span&gt;
&lt;span class="normal"&gt;35&lt;/span&gt;
&lt;span class="normal"&gt;36&lt;/span&gt;
&lt;span class="normal"&gt;37&lt;/span&gt;
&lt;span class="normal"&gt;38&lt;/span&gt;
&lt;span class="normal"&gt;39&lt;/span&gt;
&lt;span class="normal"&gt;40&lt;/span&gt;
&lt;span class="normal"&gt;41&lt;/span&gt;
&lt;span class="normal"&gt;42&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="c1"&gt;# Get CHOST value&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Getting CHOST variable content through portageq.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;my_chost&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;portageq envvar CHOST&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;my_chost&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-- The portageq command failed. Falling back to glibc build info.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="nv"&gt;my_chost&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;cat /var/db/pkg/sys-libs/glibc-*/CHOST &lt;span class="p"&gt;|&lt;/span&gt; tail -1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-- Got CHOST=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;my_chost&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;# Get current GCC version&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Getting current GCC version through /etc/env.d/gcc/config-*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;grep CURRENT /etc/env.d/gcc/config-* &lt;span class="p"&gt;|&lt;/span&gt; sed -e &lt;span class="s2"&gt;&amp;quot;s:CURRENT=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;my_chost&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;-::g&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sed -e &lt;span class="s2"&gt;&amp;quot;s:\([0-9\.-r]*\){&lt;/span&gt;$&lt;span class="s2"&gt;,-.*&lt;/span&gt;$&lt;span class="s2"&gt;}:\1:g&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-- Got version=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;# Get type&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Getting compiler type (profile/spec) through its CURRENT= value.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;current_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;grep CURRENT /etc/env.d/gcc/config-* &lt;span class="p"&gt;|&lt;/span&gt; sed -e &lt;span class="s2"&gt;&amp;quot;s:CURRENT=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;my_chost&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;-&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;::g&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sed -e &lt;span class="s1"&gt;&amp;#39;s:^-::g&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-- Got type=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_type&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Checking USE flags of gcc-&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; for hardened USE flag.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
grep -q hardened /var/db/pkg/sys-devel/gcc-&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/USE&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;current_hardened_use&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_hardened_use&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; -ne &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;!! GCC &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; is not build with USE=hardened!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;!! Please enable a hardened profile.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;XCCDF_RESULT_FAIL&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-- GCC &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_gcc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; is build with USE=hardened.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_type&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-- The default type is used which is a hardened type.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;XCCDF_RESULT_PASS&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;!! A non-default type is used: &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;current_type&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;!! This means not all hardened toolchain measures are enabled.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;XCCDF_RESULT_FAIL&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;p&gt;As you can see, the script can give output when needed, but the most
important part is that it has to return a particular return value. This
return value is provided through environment variables
(&lt;code&gt;XCCDF_RESULT_*&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;All we need to do now is to include this &lt;code&gt;Rule&lt;/code&gt; in the &lt;code&gt;Profile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;We can now evaluate the XCCDF file on the system if we refer to the
right profile. By selecting the profile, the XCCDF interpreter will also
automatically check the rules referred to by the profile (and the rules
that do not have &lt;code&gt;selected="false"&lt;/code&gt; set too).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# oscap xccdf eval --profile ... gentoo-xccdf.xml

Title   Test if the hardened toolchain is used
Rule    xccdf_org.gentoo.dev.swift_rule_installation-toolchain-hardened
Result  pass

Title   Test if sulogin is used for single-user boot (/etc/inittab)
Rule    xccdf_org.gentoo.dev.swift_rule_inittab-sulogin
Result  fail
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, if you want to check this on several systems, you would need to
distribute not only the XCCDF file, but also all files referred to by
the XCCDF document. As this is counterproductive, SCAP supports &lt;em&gt;Data
Streams&lt;/em&gt;. A data stream is a single file that includes the content of
all files. With openscap, data streams can be made as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# oscap ds sds-compose postgresql-xccdf.xml postgresql-ds.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So now we have a document explaining the secure setup of a component,
and included automated checks to validate system compliance with the
document using scripts. In the next post, I'll go on with OVAL.&lt;/p&gt;
&lt;p&gt;This post is part of a series on SCAP content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;Documenting security best practices - XCCDF
    introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/"&gt;An XCCDF skeleton for
    PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Security"></category><category term="openscap"></category><category term="scap"></category><category term="sce"></category><category term="xccdf"></category></entry><entry><title>An XCCDF skeleton for PostgreSQL</title><link href="https://blog.siphos.be/2013/12/an-xccdf-skeleton-for-postgresql/" rel="alternate"></link><published>2013-12-14T04:00:00+01:00</published><updated>2013-12-14T04:00:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-14:/2013/12/an-xccdf-skeleton-for-postgresql/</id><summary type="html">&lt;p&gt;In a &lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;previous
post&lt;/a&gt;
I wrote about the documentation structure I have in mind for a
PostgreSQL security best practice. Considering what XCCDF can give us,
the idea is to have the following structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Hardening PostgreSQL
+- Basic setup
+- Instance level configuration
|  +- Pre-startup configuration
|  `- PostgreSQL internal configuration
+- Database recommendations
`- User definitions …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;In a &lt;a href="http://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/"&gt;previous
post&lt;/a&gt;
I wrote about the documentation structure I have in mind for a
PostgreSQL security best practice. Considering what XCCDF can give us,
the idea is to have the following structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Hardening PostgreSQL
+- Basic setup
+- Instance level configuration
|  +- Pre-startup configuration
|  `- PostgreSQL internal configuration
+- Database recommendations
`- User definitions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For the profiles, I had:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;infrastructure
instance
user
+- administrator
+- end user
`- functional account
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's bring this into an XCCDF document.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;XCCDF (Extensible Configuration Checklist Description Format)&lt;/strong&gt;
format is an XML structure in which we can document whatever we want -
but it is primarily used for configuration checklists and best
practices. The &lt;em&gt;documenting&lt;/em&gt; aspect of a security best practice in XCCDF
is done through XHTML basic tags (do not use fancy things - limit
yourself to &lt;code&gt;p&lt;/code&gt;, &lt;code&gt;pre&lt;/code&gt;, &lt;code&gt;em&lt;/code&gt;, &lt;code&gt;strong&lt;/code&gt;, ... tags), so some knowledge on
XHTML (next to XML in general) is quite important while developing XCCDF
guides. At least, if you don't use special editors for that.&lt;/p&gt;
&lt;p&gt;We start with the basics:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;Two things I want to focus on here: the &lt;code&gt;xmlns:h&lt;/code&gt; and &lt;code&gt;id&lt;/code&gt; attributes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;xmlns:h&lt;/code&gt; attribute is an XML requirement, telling whatever XML
    parser is used later that tags that use the &lt;code&gt;h:&lt;/code&gt; namespace is for
    XHTML tags. So later in the document, we'll use &lt;code&gt;&amp;lt;h:p&amp;gt;...&amp;lt;/h:p&amp;gt;&lt;/code&gt; for
    XHTML paragraphs.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;id&lt;/code&gt; attribute is XCCDF specific, and since XCCDF 1.2 also
    requires to be in this particular syntax:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;    &amp;lt;/p&amp;gt;
        xccdf_&amp;lt;namespace&amp;gt;_benchmark_&amp;lt;name&amp;gt;

    &amp;lt;p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;The `&amp;lt;namespace&amp;gt;` is recommended to be an inverted domain
name structure. I also added my nickname so there are no collisions
with namespaces provided by other developers in Gentoo. So *SwifT&amp;#39;s
dev.gentoo.org* becomes *org.gentoo.dev.swift*.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This id structure will be used in other tags as well. Instead of
&lt;code&gt;*_benchmark&lt;/code&gt; it would be &lt;code&gt;*_rule&lt;/code&gt; (for &lt;code&gt;Rule&lt;/code&gt; ids), &lt;code&gt;*_group&lt;/code&gt; (for
&lt;code&gt;Group&lt;/code&gt; ids), etc. You get the idea.&lt;/p&gt;
&lt;p&gt;Now we add in some metadata in the document (with &lt;code&gt;Benchmark&lt;/code&gt; as
parent):&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;So what is all this?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;&amp;lt;status&amp;gt;&lt;/code&gt; tag helps in tracking the state of the document.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;&amp;lt;platform&amp;gt;&lt;/code&gt; tag is to tell the XCCDF interpreter when the
    document is applicable. It references a &lt;strong&gt;CPE (Common
    Platform Enumeration)&lt;/strong&gt; entity, in this case for PostgreSQL. Later,
    we will see that an automated test is assigned to the detection of
    this CPE. If the test succeeds, then PostgreSQL is installed and the
    XCCDF interpreter can continue testing and evaluating the system for
    PostgreSQL best practices. If not, then PostgreSQL is not installed
    and the XCCDF does not apply to the system.
    &lt;/p&gt;
    &lt;p&gt;
    There is a huge advantage to this: you can check all your systems
    for compliance with the PostgreSQL best practices (this
    XCCDF document) and on the systems that PostgreSQL is not installed,
    it will simply state that the document is not applicable (without
    actually trying to validate all the rules in the document). So there
    is no direct need to only check systems you know have PostgreSQL on
    (and thus potentially ignore systems that have PostgreSQL but that
    you don't know of - usually those systems are much less secure as
    well ;-).&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt; tag versions the document.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;&amp;lt;model&amp;gt;&lt;/code&gt; tags tell the XCCDF interpreter which &lt;em&gt;scoring system&lt;/em&gt;
    should be used.
    &lt;/p&gt;
    &lt;p&gt;
    Scoring will give points to rules, and the XCCDF interpreter will
    sum the scores of all rules to give a final score to the
    "compliance" state of the system. But scoring can be done on
    several levels. The default one uses the hierarchy of the document
    (nested &lt;code&gt;Group&lt;/code&gt;s and &lt;code&gt;Rule&lt;/code&gt;s) to give a final number whereas the
    flat one does not care about the structure. Finally, the
    flat-unweighted one does not take into account the scores given by
    the author - all rules get the value of 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now we define the &lt;code&gt;Profile&lt;/code&gt;s to use. I will give the example for two:
&lt;em&gt;user&lt;/em&gt; and &lt;em&gt;administrator&lt;/em&gt;, you can fill in the other ones ;-)&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;Finally, the &lt;code&gt;Group&lt;/code&gt;s (still with &lt;code&gt;Benchmark&lt;/code&gt; as their parent, but below
the &lt;code&gt;Profile&lt;/code&gt;s) which define the documentation structure of the guide:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;With all this defined, our basic skeleton for the PostgreSQL best
practice document is ready. To create proper content, we can use the
XHTML code inside the &lt;code&gt;&amp;lt;description&amp;gt;&lt;/code&gt; tags, like so:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;As said in the previous post though, just documenting various aspects is
not enough. It is recommended to add references. In XCCDF, this is done
through the &lt;code&gt;&amp;lt;reference&amp;gt;&lt;/code&gt; tag, which is within a &lt;code&gt;Group&lt;/code&gt; and usually
below the &lt;code&gt;&amp;lt;description&amp;gt;&lt;/code&gt; information:&lt;/p&gt;
&lt;p&gt;(XML content lost during blog conversion)&lt;/p&gt;
&lt;p&gt;With this alone, it is already possible to write up an XCCDF guide
describing how to securely setup (in our case) PostgreSQL while keeping
track of the resources that helped define the secure setup. Tools like
&lt;a href="http://www.open-scap.org"&gt;openscap&lt;/a&gt; can generate HTML or even Docbook
(which in turn can be converted to manual pages, PDF, Word, RTF, ...)
from this information:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# oscap xccdf generate guide --format docbook --output guide.docbook postgresql-xccdf.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the next post, I'll talk about the other documenting entities within
XCCDF (besides &lt;code&gt;&amp;lt;description&amp;gt;&lt;/code&gt; and their meaning) and start with
enhancing the document with automated checks.&lt;/p&gt;</content><category term="Security"></category><category term="postgresql"></category><category term="scap"></category><category term="xccdf"></category></entry><entry><title>Documenting security best practices - XCCDF introduction</title><link href="https://blog.siphos.be/2013/12/documenting-security-best-practices-xccdf-introduction/" rel="alternate"></link><published>2013-12-12T16:04:00+01:00</published><updated>2013-12-12T16:04:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-12-12:/2013/12/documenting-security-best-practices-xccdf-introduction/</id><summary type="html">&lt;p&gt;When I have some free time, I try to work on a &lt;a href="http://dev.gentoo.org/~swift/docs/security_benchmarks/gentoo.html"&gt;Gentoo Security
Benchmark&lt;/a&gt;
which not only documents security best practices (loosely based on the
&lt;a href="http://www.gentoo.org/doc/en/security/security-handbook.xml"&gt;Gentoo Security
Handbook&lt;/a&gt;
which hasn't seen much updates in the last few years) but also uses the
SCAP protocols. This set of protocols allows …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I have some free time, I try to work on a &lt;a href="http://dev.gentoo.org/~swift/docs/security_benchmarks/gentoo.html"&gt;Gentoo Security
Benchmark&lt;/a&gt;
which not only documents security best practices (loosely based on the
&lt;a href="http://www.gentoo.org/doc/en/security/security-handbook.xml"&gt;Gentoo Security
Handbook&lt;/a&gt;
which hasn't seen much updates in the last few years) but also uses the
SCAP protocols. This set of protocols allows security administrators to
automate and document many of their tasks, and a security best practices
guide is almost a must-have in any organization. So I decided to do a
few write-ups about these SCAP protocols and how I hope to be using them
more in the future.&lt;/p&gt;
&lt;p&gt;In this post, I'm going to focus on a very simple matter: documenting.
SCAP goes much, much beyond documenting, but I'll discuss those various
features in subsequent posts. The end goal of the series is to have a
best practice document for PostgreSQL.&lt;/p&gt;
&lt;p&gt;To document the secure state of a component, it is important to first
have an idea about what you are going to document. Some people might
want to document best practices across many technologies so that there
is a coherent, single document explaining the security best practices
for the entire organization. In my opinion, that is not manageable in
the long term. We tried that with the Gentoo Security Handbook, but you
quickly start wrestling with the order of chapters, style concerns and
what not. Also, some technologies will be much more discussed in depth
than others, making the book look "unfinished".&lt;/p&gt;
&lt;p&gt;Personally, I rather focus on a specific technology. For instance:
&lt;a href="http://dev.gentoo.org/~swift/docs/security_benchmarks/openssh.html"&gt;Hardening
OpenSSH&lt;/a&gt;
(very much work in progress - the rules are generated automatically for
now and will be rewritten in the near future). It talks about a single
component (OpenSSH) allowing the freedom for the author to focus on what
matters. By providing security best practices on these component levels,
you'll create a set of security best practices that can often be reused.
This is what &lt;a href="http://www.cisecurity.org"&gt;the Center for Internet
Security&lt;/a&gt; is doing with its benchmarks:
popular technologies are described in detail on how to configure them to
be more secure.&lt;/p&gt;
&lt;p&gt;Once you know what technology you want to describe, we need to consider
how this technology is used. Some technologies are very flexible in
their setup, and might have different security setups depending on their
use. For instance, an OpenLDAP server can be used internally as a public
address book, or disclosed on the Internet in a multi-replicated setup
with authentication data in it. The security best practices for these
deployments will vary. The &lt;strong&gt;XCCDF (Extensible Configuration Checklist
Description Format)&lt;/strong&gt; standard allows authors to write a single guide,
while taking into account the different deployment approaches through
the use of &lt;code&gt;Profile&lt;/code&gt; settings.&lt;/p&gt;
&lt;p&gt;In XCCDF, &lt;code&gt;Profile&lt;/code&gt;s allow for selectively enabling or disabling
document fragments (called &lt;code&gt;Group&lt;/code&gt;s) and checks (called &lt;code&gt;Rule&lt;/code&gt;s - I will
post about checks later) or even change values (like the minimum
password length) depending on the profile. A document can then describe
settings with different profiles depending on the use and deployment of
the technology. Profiles can also inherit from each other, so you can
have a base (default) security conscious setup, and enhance it through
other profiles.&lt;/p&gt;
&lt;p&gt;Next to the "how", we also need to consider the structure we want for
such a best practice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We will have rules in place for the deployment of PostgreSQL itself.
    These rules range from making sure a stable, patched version is
    used, to the proper rights on the software files, partitioning and
    file system rules and operating system level requirements (such as
    particular kernel parameters).&lt;/li&gt;
&lt;li&gt;We will also have rules for each instance. We could plan on running
    multiple PostgreSQL instances next to each other, so these rules are
    distinct from the deployment rules. These rules include settings on
    instance level, process ownership (in case of running PostgreSQL as
    different service user), etc.&lt;/li&gt;
&lt;li&gt;We might even have rules for databases and users (roles) in
    the database.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It &lt;em&gt;might&lt;/em&gt; make sense to split the best practices in separate documents,
such as one for PostgreSQL infrastructure (which is database-agnostic)
and one for PostgreSQL databases (and users). I would start with one
document for the technology if I was responsible for the entire
definition, but if this responsibility is not with one person (or team),
it makes sense to use different documents. Also, as we will see later,
XCCDF documents can be "played" against a target. If the target is
different (for infrastructure, the target usually is the host on which
PostgreSQL is installed, whereas for the database settings the target is
probably the PostgreSQL instance itself) I would definitely have the
definitions through separate profiles, but that does not mean the
document needs to be split either.&lt;/p&gt;
&lt;p&gt;Finally, documenting a secure best practice also involves keeping track
of the references. It is not only about documenting something and why
&lt;em&gt;you&lt;/em&gt; think this is the best approach, but also about referring readers
to more information and other resources that collaborate your story.
These can be generic control objectives (such as those provided by the
&lt;a href="http://www.opensecurityarchitecture.org/cms/library/0802control-catalogue"&gt;open security
architecture&lt;/a&gt;)
or specific best practices of the vendor itself or third parties.&lt;/p&gt;
&lt;p&gt;At the end, for a PostgreSQL security guide, we would probably start
with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Hardening PostgreSQL
+- Basic setup
+- Instance level configuration
|  +- Pre-startup configuration
|  `- PostgreSQL internal configuration
+- Database recommendations
`- User definitions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Profile-wise, I probably would need an &lt;em&gt;infrastructure&lt;/em&gt; profile, an
&lt;em&gt;instance&lt;/em&gt; profile, a &lt;em&gt;user&lt;/em&gt; profile and a &lt;em&gt;database&lt;/em&gt; profile. I might
even have profiles for the different roles (&lt;em&gt;functional account&lt;/em&gt;,
&lt;em&gt;administrator&lt;/em&gt; and &lt;em&gt;end user&lt;/em&gt; profiles which inherit from the &lt;em&gt;user&lt;/em&gt;
profile) as they will have different rules assigned to them.&lt;/p&gt;
&lt;p&gt;In my next post, we'll create a skeleton XCCDF document and already talk
about some of the XCCDF features that we can benefit from immediately.&lt;/p&gt;</content><category term="Security"></category><category term="postgresql"></category><category term="scap"></category><category term="xccdf"></category></entry><entry><title>The mix of libffi with other changes</title><link href="https://blog.siphos.be/2013/11/the-mix-of-libffi-with-other-changes/" rel="alternate"></link><published>2013-11-03T10:27:00+01:00</published><updated>2013-11-03T10:27:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-11-03:/2013/11/the-mix-of-libffi-with-other-changes/</id><summary type="html">&lt;p&gt;I &lt;a href="http://blog.siphos.be/2013/04/securely-handling-libffi/"&gt;once again&lt;/a&gt;
came across libffi. Not only does the libffi approach fight with SELinux
alone, it also triggers the TPE (Trusted Path Execution) protections in
grSecurity. And when I tried to reinstall Portage, Portage seemed to
create some sort of runtime environment in a temporary directory as
well, and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I &lt;a href="http://blog.siphos.be/2013/04/securely-handling-libffi/"&gt;once again&lt;/a&gt;
came across libffi. Not only does the libffi approach fight with SELinux
alone, it also triggers the TPE (Trusted Path Execution) protections in
grSecurity. And when I tried to reinstall Portage, Portage seemed to
create some sort of runtime environment in a temporary directory as
well, and SELinux wasn't up to allowing that either.&lt;/p&gt;
&lt;p&gt;Let's first talk about a quick workaround for the libffi-with-TPE issue.
Because libffi wants to create executable files in a world-writable
directory and then execute that file (try finding the potential security
issue here) TPE is prohibiting the execution. The easiest workaround is
to add the &lt;code&gt;portage&lt;/code&gt; Linux user, as well as the Linux accounts that you
use to run emerge with (even just things like &lt;strong&gt;emerge --info&lt;/strong&gt;) in the
&lt;code&gt;wheel&lt;/code&gt; group. This group is exempt from TPE protections (unless you
configured a different group in your kernel for this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~# zgrep CONFIG_GRKERNSEC_TPE_TRUSTED_GID /proc/config.gz
CONFIG_GRKERNSEC_TPE_TRUSTED_GID=10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next we also need to allow the &lt;code&gt;portage_t&lt;/code&gt; domain to execute files
labeled with &lt;code&gt;portage_tmpfs_t&lt;/code&gt;. You can do this by creating your own
SELinux policy module with the following content (or use selocal):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;can_exec(portage_t, portage_tmpfs_t)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This works around the libffi issue for now. A better solution still has
to be implemented (as discussed in the previous post).&lt;/p&gt;
&lt;p&gt;With regards to the portage installation failing, you'll notice this
quickly when you get an error like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~# emerge -1 portage
Calculating dependencies  ... done!
Traceback (most recent call last):
  File &amp;quot;/usr/bin/emerge&amp;quot;, line 50, in &amp;lt;module&amp;gt;
    retval = emerge_main()
  File &amp;quot;/usr/lib64/portage/pym/_emerge/main.py&amp;quot;, line 1031, in emerge_main
    return run_action(emerge_config)
  File &amp;quot;/usr/lib64/portage/pym/_emerge/actions.py&amp;quot;, line 4062, in run_action
    emerge_config.args, spinner)
  File &amp;quot;/usr/lib64/portage/pym/_emerge/actions.py&amp;quot;, line 453, in action_build
    retval = mergetask.merge()
  File &amp;quot;/usr/lib64/portage/pym/_emerge/Scheduler.py&amp;quot;, line 946, in merge
    rval = self._handle_self_update()
  File &amp;quot;/usr/lib64/portage/pym/_emerge/Scheduler.py&amp;quot;, line 316, in _handle_self_update
    _prepare_self_update(self.settings)
  File &amp;quot;/usr/lib64/portage/pym/portage/package/ebuild/doebuild.py&amp;quot;, line 2326, in _prepare_self_update
    shutil.copytree(orig_bin_path, portage._bin_path, symlinks=True)
  File &amp;quot;/usr/lib64/portage/pym/portage/__init__.py&amp;quot;, line 259, in __call__
    rval = self._func(*wrapped_args, **wrapped_kwargs)
  File &amp;quot;/usr/lib64/python3.3/shutil.py&amp;quot;, line 343, in copytree
    raise Error(errors)
shutil.Error: [(b&amp;#39;/usr/lib64/portage/bin/ebuild-helpers/prepalldocs&amp;#39;, 
b&amp;#39;/var/tmp/portage/._portage_reinstall_.osj370/bin/ebuild-helpers/prepalldocs&amp;#39;, 
&amp;quot;[Errno 13] Permission denied: &amp;#39;/var/tmp/portage/._portage_reinstall_.osj370/bin/ebuild-helpers/prepalldocs&amp;#39;&amp;quot;), 
(b&amp;#39;/usr/lib64/portage/bin/ebuild-helpers/prepinfo&amp;#39;, 
b&amp;#39;/var/tmp/portage/._portage_reinstall_.osj370/bin/ebuild-helpers/prepinfo&amp;#39;, 
&amp;quot;[Errno 13] Permission denied: &amp;#39;/var/tmp/portage/._portage_reinstall_.osj370/bin/ebuild-helpers/prepinfo&amp;#39;&amp;quot;), 
(b&amp;#39;/usr/lib64/portage/bin/ebuild-helpers/newlib.so&amp;#39;, 
b&amp;#39;/var/tmp/portage/._portage_reinstall_.osj370/bin/ebuild-helpers/newlib.so&amp;#39;, 
&amp;quot;[Errno 13] Permission denied: &amp;#39;/var/tmp/portage/._portage_reinstall_.osj370/bin/ebuild-helpers/newlib.so&amp;#39;&amp;quot;), 
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And the errors go on and on and on.&lt;/p&gt;
&lt;p&gt;I've been able to get it working again by allowing the following SELinux
permissions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;allow portage_t portage_tmp_t:dir relabel_dir_perms;
allow portage_t portage_tmp_t:lnk_file relabel_lnk_file_perms;
allow portage_t bin_t:dir relabel_dir_perms;
allow portage_t bin_t:file relabel_file_perms;
allow portage_t bin_t:lnk_file relabel_lnk_file_perms;
allow portage_t portage_exec_t:file relabel_file_perms;
allow portage_t portage_fetch_exec_t:file relabel_file_perms;
allow portage_t lib_t:dir relabel_dir_perms;
allow portage_t lib_t:file relabel_file_perms;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can somewhat shorten this by combining types (but this doesn't work
with selocal for now):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;allow portage_t { portage_tmp_t bin_t lib_t}:dir relabel_dir_perms;
allow portage_t { portage_tmp_t bin_t }:lnk_file relabel_lnk_file_perms;
allow portage_t { bin_t portage_exec_t portage_fetch_exec_t lib_t}:file relabel_file_perms;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At the end of the emerge process (when the new portage is installed) you
might want to reset the labels of all files provided by the portage
package:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~# rlpkg portage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;These changes have not been passed into the policy yet as I first need
to find out why exactly they are needed, and as you can see from &lt;a href="http://dev.gentoo.org/devaway/"&gt;the
gentoo devaway&lt;/a&gt; page, time is not on my
side to do this. I'll try to free up some time in the next few days to
handle this as well as the &lt;a href="http://userspace.selinuxproject.org/trac/wiki/Releases"&gt;SELinux userspace
release&lt;/a&gt; but no
promises here.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edit:&lt;/em&gt; I found why - it is the &lt;code&gt;_prepare_self_update&lt;/code&gt; in the
&lt;code&gt;doebuild.py&lt;/code&gt; script. It creates temporary copies of the Portage
binaries and Portage python libraries, which is why we need to support
relabel operations on the files. Support for this is now in the policy
repository.&lt;/p&gt;
&lt;/p&gt;</content><category term="Security"></category><category term="Gentoo"></category><category term="hardened"></category><category term="libffi"></category><category term="portage"></category><category term="selinux"></category></entry><entry><title>In-browser encryption for online password management</title><link href="https://blog.siphos.be/2013/10/in-browser-encryption-for-online-password-management/" rel="alternate"></link><published>2013-10-20T21:29:00+02:00</published><updated>2013-10-20T21:29:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-10-20:/2013/10/in-browser-encryption-for-online-password-management/</id><summary type="html">&lt;p&gt;Lately I've been trying to find a good free software project that uses
PHP or cgi-bin (one of the requirements for this particular
organization) that allows its users to store passwords centrally, but
uses encryption on the browser level before the passwords are sent to
the central server. I've found …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Lately I've been trying to find a good free software project that uses
PHP or cgi-bin (one of the requirements for this particular
organization) that allows its users to store passwords centrally, but
uses encryption on the browser level before the passwords are sent to
the central server. I've found one -
&lt;a href="https://www.clipperz.com"&gt;Clipperz&lt;/a&gt; - but was not able to get it to
build and install.&lt;/p&gt;
&lt;p&gt;With the continuous revelations regarding hacked sites and servers (and
even potential snooping into server data by governments) the requirement
isn't that weird: by using strong encryption (I currently still assume
that AES-256 is safe for use) on the browser level, no unencrypted
sensitive data (such as usernames and passwords) would be sent to the
server, let alone stored (in plain text) on the server database.&lt;/p&gt;
&lt;p&gt;I did a small test to see how difficult it would be to implement this in
a simple PHP password management tool called &lt;a href="http://onlinepasswords.sourceforge.net/"&gt;online
passwords&lt;/a&gt;. The PHP-based
application does not even use a database, relying on flat-files instead.
By design, the tool encrypts the data before storing on the file system,
but I wanted to go a bit further, implementing the in-browser
encryption. The Javascript AES is provided by
&lt;a href="http://www.movable-type.co.uk/scripts/aes.html"&gt;movable-type.co.uk&lt;/a&gt; and
for the hashing algorithm I found &lt;a href="http://pajhome.org.uk/crypt/md5"&gt;pajhome's
implementation&lt;/a&gt; often cited.&lt;/p&gt;
&lt;p&gt;The first thing I did was substitute the password information needed to
log on to the site (and which is also used as encryption key for the
back-end side encryption) with a hashed version of the password. For the
application, this hardly matters - it is still the encryption key it
will use on the backend, although most likely a bit stronger than most
passwords would be.&lt;/p&gt;
&lt;p&gt;Next, I keep the real password in a local session storage (which is
supported by most modern browsers nowadays) so that the user only has to
enter it once (when logging on to the site) and it is kept in memory
then, never leaving the browser. This is needed in order to decrypt the
data as we get it without having to ask the user for the password over
and over again. Of course, I don't want to keep this password in a
Cookie (or pass it on through the URL) because that would void the idea
of keeping the password (reasonably) secure.&lt;/p&gt;
&lt;p&gt;To accomplish this, I hide the password field of the PHP application
itself, and create a second input field (outside the &lt;code&gt;&amp;lt;form&amp;gt; &amp;lt;/form&amp;gt;&lt;/code&gt; to
make sure its value is never POSTed to the site) in which the user
enters his password. Upon submit of the data, the following javascript
code will create the hash of the password (and user name) to use as the
"site password" for the application, and put that in the (hidden) input
field. It then also stores the site password in the local session
storage in the browser. The code is triggered through the &lt;em&gt;onSubmit&lt;/em&gt;
handler of the form.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;function storeAppPassword() {
  var sitepw = document.getElementById(&amp;#39;password&amp;#39;);
  var siteus = document.getElementById(&amp;#39;login&amp;#39;);
  var userpw = document.getElementById(&amp;#39;userpassword&amp;#39;);

  sessionStorage.setItem(&amp;#39;userpassword&amp;#39;, userpw.value);
  sitepw.value = hex_sha1(siteus.value + userpw.value);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now I need to make sure that the fields that need to be encrypted (the
various user ids and passwords that are stored on the site) are
encrypted before they are sent to the server, and decrypted after having
received them by the browser. For instance, if the fields are within a
form, the following javascript function could be triggered on the
&lt;em&gt;onSubmit&lt;/em&gt; handler again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;function encryptFields() {
  var useridFld = document.getElementById(&amp;#39;userid&amp;#39;);
  var passwordFld = document.getElementById(&amp;#39;password&amp;#39;);
  var notesFld = document.getElementById(&amp;#39;notes&amp;#39;);

  var pw = sessionStorage.getItem(&amp;#39;userpassword&amp;#39;);
  useridFld.value = Aes.Ctr.encrypt(useridFld.value, pw, 256);
  passwordFld.value = Aes.Ctr.encrypt(passwordFld.value, pw, 256);
  notesFld.value = Aes.Ctr.encrypt(notesFld.value, pw, 256);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Similarly, to decrypt the fields (inside the same form), that part of
the code would become:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;useridFld.value = Aes.Ctr.decrypt(useridFld.value, pw, 256);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Decryption of the fields can be called by a simple javascript call at
the end of the page.&lt;/p&gt;
&lt;p&gt;If the data is within regular fields (non-form related), such as a
table, you'll need to find the right DOM element and call the decryption
function there.&lt;/p&gt;
&lt;p&gt;With those few changes, I was able to get it up and running quickly. I
don't think I'll use the PHP application itself in production though, as
it doesn't look like it sanitizes the field data in the PHP code and it
starts to show performance issues when called with only a few hundred
accounts, each having a few dozen passwords. But that hardly matters for
this post where I want to point out that it isn't that hard to put some
higher security on such sites.&lt;/p&gt;
&lt;p&gt;The big downside right now is that, if the user forgets his password, he
wont have access to all his data (similar to the Clipperz one). And
unlike Clipperz, the approach above does not allow for password changes
yet (although it doesn't look that hard to implement some logic
decrypting and re-encrypting the data with a different password if that
comes about). An approach to resolve that would be to encrypt all data
with a static key, and then encrypt that key with the password, storing
the encrypted key on the server. A password change only requires a
decrypt/encrypt of the key while all values remain encrypted with the
static key.&lt;/p&gt;
&lt;p&gt;Moral of the story: application managers of web password storage sites:
please add in-browser encryption for those of us that want to make
*really* sure that no sensitive data is sent over unencrypted (I don't
count SSL/TLS as that "ends" at the remote side while this one is full
end-to-end encryption).&lt;/p&gt;</content><category term="Security"></category><category term="aes"></category><category term="encryption"></category><category term="javascript"></category><category term="password"></category><category term="passwordmanagement"></category></entry><entry><title>Switching gpg key to 0x2EDD52403B68AF47</title><link href="https://blog.siphos.be/2013/09/switching-gpg-key-to-0x2edd52403b68af47/" rel="alternate"></link><published>2013-09-19T21:17:00+02:00</published><updated>2013-09-19T21:17:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-09-19:/2013/09/switching-gpg-key-to-0x2edd52403b68af47/</id><summary type="html">&lt;p&gt;I recently switched my GnuPG key. The previous key - which is still in
place for now (no revocation send out yet) - was 0x5DFAB3ECCDBA2FDB and
was a 1024 bit DSA key. The new one, 0x2EDD52403B68AF47, is a 4096 bit
RSA key. It also has the following preferences:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;gpg&amp;gt; showpref
[ultimate] (1 …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;I recently switched my GnuPG key. The previous key - which is still in
place for now (no revocation send out yet) - was 0x5DFAB3ECCDBA2FDB and
was a 1024 bit DSA key. The new one, 0x2EDD52403B68AF47, is a 4096 bit
RSA key. It also has the following preferences:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;gpg&amp;gt; showpref
[ultimate] (1). Sven Vermeulen &amp;lt;sven.vermeulen@siphos.be&amp;gt;
[ultimate] (2)  Sven Vermeulen &amp;lt;swift@gentoo.org&amp;gt;
     Cipher: AES256, AES192, AES, CAST5, 3DES
     Digest: SHA512, SHA384, SHA256, SHA224, SHA1
     Compression: BZIP2, ZLIB, ZIP, Uncompressed
     Features: MDC, Keyserver no-modify
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The new key's fingerprint is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;gpg&amp;gt; fpr
pub   4096R/0x2EDD52403B68AF47 2013-09-16 Sven Vermeulen 
 Primary key fingerprint: 7264 9F85 E8F1 6F6A 4B68  1102 2EDD 5240 3B68 AF47
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A signed &lt;a href="http://dev.gentoo.org/~swift/key-transition.txt.asc"&gt;key transition
statement&lt;/a&gt; can be
found on my Gentoo development page; the document is signed with both of
my keys (the old one and new one).&lt;/p&gt;</content><category term="Security"></category><category term="gpg"></category><category term="key"></category></entry><entry><title>cvechecker 3.3 released</title><link href="https://blog.siphos.be/2013/09/cvechecker-3-3-released/" rel="alternate"></link><published>2013-09-16T16:06:00+02:00</published><updated>2013-09-16T16:06:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-09-16:/2013/09/cvechecker-3-3-released/</id><summary type="html">&lt;p&gt;I just uploaded a new release of &lt;a href="http://cvechecker.sf.net"&gt;cvechecker&lt;/a&gt;
to the project files. The release is a (long overdue) bugfix release,
but includes two small enhancements: support standard input for the
binary list (so you can pipe the output of one command to cvechecker)
and the introduction of the &lt;code&gt;CVECHECKER_CONFFILE&lt;/code&gt; variable …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I just uploaded a new release of &lt;a href="http://cvechecker.sf.net"&gt;cvechecker&lt;/a&gt;
to the project files. The release is a (long overdue) bugfix release,
but includes two small enhancements: support standard input for the
binary list (so you can pipe the output of one command to cvechecker)
and the introduction of the &lt;code&gt;CVECHECKER_CONFFILE&lt;/code&gt; variable to refer to
another location for the configuration file.&lt;/p&gt;
&lt;p&gt;Big thanks to &lt;a href="http://mulhern-at-yocto.dreamwidth.org/"&gt;Anne Mulhern&lt;/a&gt;
for the various patches submitted!&lt;/p&gt;</content><category term="Security"></category><category term="cvechecker"></category><category term="release"></category></entry><entry><title>Putting OVAL at work</title><link href="https://blog.siphos.be/2013/08/putting-oval-at-work/" rel="alternate"></link><published>2013-08-01T15:01:00+02:00</published><updated>2013-08-01T15:01:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-08-01:/2013/08/putting-oval-at-work/</id><summary type="html">&lt;p&gt;When we look at the &lt;a href="http://scap.nist.gov/"&gt;SCAP security standards&lt;/a&gt;,
you might get the feeling of "How does this work". The underlying
interfaces, like OVAL and XCCDF, might seem a bit daunting to implement.&lt;/p&gt;
&lt;p&gt;This is correct, but you need to remember that the standards are
protocols, agreements that can be made …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When we look at the &lt;a href="http://scap.nist.gov/"&gt;SCAP security standards&lt;/a&gt;,
you might get the feeling of "How does this work". The underlying
interfaces, like OVAL and XCCDF, might seem a bit daunting to implement.&lt;/p&gt;
&lt;p&gt;This is correct, but you need to remember that the standards are
protocols, agreements that can be made across products so that several
products, each with their own expertise, can work together easily. It is
a matter of interoperability between components.&lt;/p&gt;
&lt;p&gt;Let's look at the following diagram to see how OVAL and XCCDF &lt;em&gt;can&lt;/em&gt; be
used. I'm not saying this is the only way forward, but it is a possible
approach.&lt;/p&gt;
&lt;p&gt;(Diagram lost during blog conversion)&lt;/p&gt;
&lt;p&gt;On the local side (and local here doesn't mean a single server, but
rather an organization or company) a list of checks is maintained. These
checks are OVAL checks, which can be downloaded from reputable sites
like NVD or are given to you by vendors (some vendors provide OVAL as
part of vulnerability reports). Do not expect this list to be hundreds
of checks - start small, the local database of checks will grow anyhow.&lt;/p&gt;
&lt;p&gt;The advantage is that the downloaded checks (OVALs) already have a
unique identifier (the OVAL ID). For instance, the check "Disable Java
in Firefox" for Windows is &lt;code&gt;oval:org.mitre.oval:def:12609&lt;/code&gt;. If
additional Windows operating systems are added, this ID remains the same
(it is updated) because the check (and purpose) remains the same.&lt;/p&gt;
&lt;p&gt;Locally, the OVAL checks are ran against targets by an OVAL interpreter.
Usually, you will have multiple interpreters in the organization, some
of them focused on desktops, some on servers, some perhaps on network
equipment, etc. By itself that doesn't matter, as long as they interpret
the OVAL checks. The list of targets to check against are usually
managed in a configuration management database.&lt;/p&gt;
&lt;p&gt;Targets can be of various granularity. The "Disable Java in Firefox"
will be against an operating system (where the check then sees if the
installed Firefox indeed has the setting disabled), but a check that
validates the permissions (rights) of a user will be against this user
account.&lt;/p&gt;
&lt;p&gt;The results of the OVAL checks are stored in a database that maps the
result against the target. By itself this result database does not
contain much more logic than "This rule is OK against this target and
that rule isn't" (well, there is some granularity, but not much more)
and the time stamp when this was done.&lt;/p&gt;
&lt;p&gt;Next comes the XCCDF. XCCDF defines the state that you want the system
to be in. It is a benchmark, a document describing how the system /
target should be configured. XCCDF documents usually contain the whole
shebang of configuration settings, and then differentiate them based on
profiles. For instance, a web server attached to the Internet might have
a different profile than a web server used internally or for development
purposes.&lt;/p&gt;
&lt;p&gt;The XCCDF document refers to OVAL checks, and thus uses the results from
the OVAL result database to see if a target is fully aligned with the
requirements or not. The XCCDF results themselves are also stored, often
together with exceptions (if any) that are approved (for instance, you
want to keep track of the workstations where Java &lt;em&gt;is&lt;/em&gt; enabled in
Firefox and only report for those systems where it is enabled by the
user without approval). Based on these results, reports can be generated
on the state of your park.&lt;/p&gt;
&lt;p&gt;Not all checks are already available as OVAL checks. Of course you can
write them yourself, but there are also other possibilities. Next to
OVAL, there are (less standardized) methods for doing checks which
integrate with XCCDF as well. The idea you'll need to focus on then is
the same as with OVAL: what is your source, how do you store it, you
need interpreters that can "play" it, and on the reporting side you'll
need to store the results so you can combine them later in your
reporting.&lt;/p&gt;</content><category term="Security"></category><category term="baseline"></category><category term="benchmark"></category><category term="oval"></category><category term="security"></category><category term="xccdf"></category></entry><entry><title>Looking at the local Linux kernel privilege escalation</title><link href="https://blog.siphos.be/2013/05/looking-at-the-local-linux-kernel-privilege-escalation/" rel="alternate"></link><published>2013-05-17T03:50:00+02:00</published><updated>2013-05-17T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-17:/2013/05/looking-at-the-local-linux-kernel-privilege-escalation/</id><summary type="html">&lt;p&gt;There has been a few posts already on the local Linux kernel privilege
escalation, which has received the
&lt;a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2013-2094"&gt;CVE-2013-2094&lt;/a&gt;
ID.
&lt;a href="http://arstechnica.com/security/2013/05/critical-linux-vulnerability-imperils-users-even-after-silent-fix/"&gt;arstechnica&lt;/a&gt;
has a write-up with links to good resources on the Internet, but I
definitely want to point readers to the
&lt;a href="http://www.reddit.com/r/netsec/comments/1eb9iw/sdfucksheeporgs_semtexc_local_linux_root_exploit/c9ykrck"&gt;explanation&lt;/a&gt;
that Brad Spengler made on the vulnerability.&lt;/p&gt;
&lt;p&gt;In …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There has been a few posts already on the local Linux kernel privilege
escalation, which has received the
&lt;a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2013-2094"&gt;CVE-2013-2094&lt;/a&gt;
ID.
&lt;a href="http://arstechnica.com/security/2013/05/critical-linux-vulnerability-imperils-users-even-after-silent-fix/"&gt;arstechnica&lt;/a&gt;
has a write-up with links to good resources on the Internet, but I
definitely want to point readers to the
&lt;a href="http://www.reddit.com/r/netsec/comments/1eb9iw/sdfucksheeporgs_semtexc_local_linux_root_exploit/c9ykrck"&gt;explanation&lt;/a&gt;
that Brad Spengler made on the vulnerability.&lt;/p&gt;
&lt;p&gt;In short, the vulnerability is an &lt;em&gt;out-of-bound&lt;/em&gt; access to an array
within the Linux perf code (which is a performance measuring subsystem
enabled when &lt;code&gt;CONFIG_PERF_EVENTS&lt;/code&gt; is enabled). This subsystem is often
enabled as it offers a wide range of performance measurement techniques
(see &lt;a href="https://perf.wiki.kernel.org/index.php/Main_Page"&gt;its wiki&lt;/a&gt; for
more information). You can check on your own system through the kernel
configuration (&lt;strong&gt;zgrep CONFIG_PERF_EVENTS /proc/config.gz&lt;/strong&gt; if you
have the latter pseudo-file available - it is made available through
&lt;code&gt;CONFIG_IKCONFIG_PROC&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The public exploit maps memory in userland, fills it with known data,
then triggers an out-of-bound decrement that tricks the kernel into
decrementing this data (mapped in userland). By looking at where the
decrement occurred, the exploit now knows the base address of the array.
Next, it targets (through the same vulnerability) the IDT base
(Interrupt Descriptor Table) and targets the overflow interrupt vector.
It increments the top part of the address that the vector points to
(which is 0xffffffff, becoming 0x00000000 thus pointing to the
userland), maps this memory region itself with shellcode, and then
triggers the overflow. The shell code used in the public exploit
modifies the credentials of the current task, sets uid/gid with root and
gives full capabilities, and then executes a shell.&lt;/p&gt;
&lt;p&gt;As Brad mentions, &lt;a href="https://grsecurity.net/~spender/uderef.txt"&gt;UDEREF&lt;/a&gt;
(an option in a grSecurity enabled kernel) should mitigate the attempt
to get to the userland. On my system, the exploit fails with the
following (start of) oops (without affecting the system further) when it
tries to close the file descriptor returned from the syscall that
invokes the decrement:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[ 1926.226678] PAX: please report this to pageexec@freemail.hu
[ 1926.227019] BUG: unable to handle kernel paging request at 0000000381f5815c
[ 1926.227019] IP: [] sw_perf_event_destroy+0x1a/0xa0
[ 1926.227019] PGD 58a7c000 
[ 1926.227019] Thread overran stack, or stack corrupted
[ 1926.227019] Oops: 0002 [#4] PREEMPT SMP 
[ 1926.227019] Modules linked in: libcrc32c
[ 1926.227019] CPU 0 
[ 1926.227019] Pid: 4267, comm: test Tainted: G      D      3.8.7-hardened #1 Bochs Bochs
[ 1926.227019] RIP: 0010:[]  [] sw_perf_event_destroy+0x1a/0xa0
[ 1926.227019] RSP: 0018:ffff880058a03e08  EFLAGS: 00010246
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The exploit also finds that the decrement didn't succeed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;test: semtex.c:76: main: Assertion &amp;#39;i&amp;lt;0x0100000000/4&amp;#39; failed.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A second mitigation is that
&lt;a href="http://pax.grsecurity.net/docs/PaXTeam-H2HC12-PaX-kernel-self-protection.pdf"&gt;KERNEXEC&lt;/a&gt;
(also offered through grSecurity) which prevents the kernel from
executing data that is writable (including userland data). So modifying
the IDT would be mitigated as well.&lt;/p&gt;
&lt;p&gt;Another important mitigation is TPE - &lt;em&gt;Trusted Path Execution&lt;/em&gt;. This
feature prevents the execution of binaries that are not located in a
root-owned directory and owned by a trusted group (which on my system is
10 = wheel). So users attempting to execute such code will fail with a
&lt;em&gt;Permission denied&lt;/em&gt; error, and the following is shown in the logs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[ 3152.165780] grsec: denied untrusted exec (due to not being in trusted group and file in non-root-owned directory) of /home/user/test by /home/user/test[bash:4382] uid/euid:1000/1000 gid/egid:100/100, parent /bin/bash[bash:4352] uid/euid:1000/1000 gid/egid:100/100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;However, even though a nicely hardened system should be fairly immune
against the currently circling public exploit, it should be noted that
it is not immune against the vulnerability itself. The methods above
mentioned make it so that that particular way of gaining root access is
not possible, but it still allows an attacker to decrement and increment
memory in specific locations so other exploits might be found to modify
the system.&lt;/p&gt;
&lt;p&gt;Now out-of-bound vulnerabilities are not new. Recently (february this
year), a
&lt;a href="http://www.phoronix.com/scan.php?page=news_item&amp;amp;px=MTMxMTg"&gt;vulnerability&lt;/a&gt;
in the networking code also provided an attack vector to get a local
privilege escalation. A mandatory access control system like SELinux has
little impact on such vulnerabilities if you allow users to execute
their own code. Even confined users can modify the exploit to disable
SELinux (since the shell code is ran with ring0 privileges it can access
and modify the SELinux state information in the kernel).&lt;/p&gt;
&lt;p&gt;Many thanks to Brad for the excellent write-up, and to the &lt;a href="http://www.gentoo.org/proj/en/hardened"&gt;Gentoo
Hardened&lt;/a&gt; team for providing the
grSecurity PaX/TPE protections in its &lt;code&gt;hardened-sources&lt;/code&gt; kernel.&lt;/p&gt;</content><category term="Security"></category><category term="event"></category><category term="grsecurity"></category><category term="kernexec"></category><category term="linux"></category><category term="pax"></category><category term="perf"></category><category term="selinux"></category><category term="uderef"></category><category term="vulnerability"></category></entry><entry><title>Highlevel assessment of Cdorked and Gentoo Hardened/SELinux</title><link href="https://blog.siphos.be/2013/05/highlevel-assessment-of-cdorked-and-gentoo-hardenedselinux/" rel="alternate"></link><published>2013-05-14T03:50:00+02:00</published><updated>2013-05-14T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-14:/2013/05/highlevel-assessment-of-cdorked-and-gentoo-hardenedselinux/</id><summary type="html">&lt;p&gt;With all the
&lt;a href="http://www.welivesecurity.com/2013/05/07/linuxcdorked-malware-lighttpd-and-nginx-web-servers-also-affected/"&gt;reports&lt;/a&gt;
surrounding
&lt;a href="https://threatpost.com/attack-using-backdoored-apache-binaries-to-lead-to-blackhole-kit/"&gt;Cdorked&lt;/a&gt;,
I took a look at if SELinux and/or other Gentoo Hardened technologies
could reduce the likelihood that this infection occurs on your system.&lt;/p&gt;
&lt;p&gt;First of all, we don't know yet how the malware gets installed on the
server. We do know that the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;With all the
&lt;a href="http://www.welivesecurity.com/2013/05/07/linuxcdorked-malware-lighttpd-and-nginx-web-servers-also-affected/"&gt;reports&lt;/a&gt;
surrounding
&lt;a href="https://threatpost.com/attack-using-backdoored-apache-binaries-to-lead-to-blackhole-kit/"&gt;Cdorked&lt;/a&gt;,
I took a look at if SELinux and/or other Gentoo Hardened technologies
could reduce the likelihood that this infection occurs on your system.&lt;/p&gt;
&lt;p&gt;First of all, we don't know yet how the malware gets installed on the
server. We do know that the Apache binaries themselves are modified, so
the first thing to look at is to see if this risk can be reduced. Of
course, using an intrusion detection system like
&lt;a href="https://wiki.gentoo.org/wiki/AIDE"&gt;AIDE&lt;/a&gt; helps, but even with Gentoo's
&lt;strong&gt;qcheck&lt;/strong&gt; command you can test the integrity of the files:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# qcheck www-servers/apache
Checking www-servers/apache-2.2.24 ...
  * 424 out of 424 files are good
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If the binary is modified, this would result in something equivalent to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Checking www-servers/apache-2.2.24 ...
 MD5-DIGEST: /usr/sbin/apache2
  * 423 out of 424 files are good
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I don't know if the modified binary would otherwise work just fine, I
have not been able to find exact details on the infected binary to (in a
sandbox environment of course) analyze this further. Also, because we
don't know how they are installed, it is not easy to know if binaries
that you built yourself are equally likely to be modified/substituted or
if the attack checks checksums of the binaries against a known list.&lt;/p&gt;
&lt;p&gt;Assuming that it would run, then the infecting malware would need to set
the proper SELinux context on the file (if it overwrites the existing
binary, then the context is retained, otherwise it gets the default
context of &lt;code&gt;bin_t&lt;/code&gt;). If the context is wrong, then starting Apache
results in:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;apache2: Syntax error on line 61 of /etc/apache2/httpd.conf: Cannot load /usr/lib64/apache2/modules/mod_actions.so into server: /usr/lib64/apache2/modules/mod_actions.so: cannot open shared object file: Permission denied
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is because the modified binary stays in the calling domain context
(&lt;code&gt;initrc_t&lt;/code&gt;). If you use a targeted policy, then this will not present
itself as &lt;code&gt;initrc_t&lt;/code&gt; is an unconfined domain. But with strict policies,
&lt;code&gt;initrc_t&lt;/code&gt; is not allowed to read &lt;code&gt;httpd_modules_t&lt;/code&gt;. Even worse, the
remainder of SELinux protections don't apply anymore, since with
unconfined domains, all bets are off. That is why Gentoo focuses this
hard on using a strict policy.&lt;/p&gt;
&lt;p&gt;So, what if the binary runs in the proper domain? Well then, from the
articles I read, the malware can do a reverse connect. That means that
the domain will attempt to connect to an IP address provided by the
attacker (in a specifically crafted URL). For SELinux, this means that
the &lt;em&gt;name_connect&lt;/em&gt; permission is checked:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# sesearch -s httpd_t -c tcp_socket -p name_connect -ACTS
Found 20 semantic av rules:
   allow nsswitch_domain dns_port_t : tcp_socket { name_connect } ; 
DT allow httpd_t port_type : tcp_socket { name_connect } ; [ httpd_can_network_connect ]
DT allow httpd_t ftp_port_t : tcp_socket { name_connect } ; [ httpd_can_network_relay ]
DT allow httpd_t smtp_port_t : tcp_socket { name_connect } ; [ httpd_can_sendmail ]
DT allow httpd_t postgresql_port_t : tcp_socket { name_connect } ; [ httpd_can_network_connect_db ]
DT allow httpd_t oracledb_port_t : tcp_socket { name_connect } ; [ httpd_can_network_connect_db ]
DT allow httpd_t squid_port_t : tcp_socket { name_connect } ; [ httpd_can_network_relay ]
DT allow httpd_t mssql_port_t : tcp_socket { name_connect } ; [ httpd_can_network_connect_db ]
DT allow httpd_t kerberos_port_t : tcp_socket { name_connect } ; [ allow_kerberos ]
DT allow nsswitch_domain ldap_port_t : tcp_socket { name_connect } ; [ authlogin_nsswitch_use_ldap ]
DT allow httpd_t http_cache_port_t : tcp_socket { name_connect } ; [ httpd_can_network_relay ]
DT allow httpd_t http_port_t : tcp_socket { name_connect } ; [ httpd_can_network_relay ]
DT allow httpd_t http_port_t : tcp_socket { name_connect } ; [ httpd_graceful_shutdown ]
DT allow httpd_t mysqld_port_t : tcp_socket { name_connect } ; [ httpd_can_network_connect_db ]
DT allow httpd_t ocsp_port_t : tcp_socket { name_connect } ; [ allow_kerberos ]
DT allow nsswitch_domain kerberos_port_t : tcp_socket { name_connect } ; [ allow_kerberos ]
DT allow httpd_t pop_port_t : tcp_socket { name_connect } ; [ httpd_can_sendmail ]
DT allow nsswitch_domain ocsp_port_t : tcp_socket { name_connect } ; [ allow_kerberos ]
DT allow httpd_t gds_db_port_t : tcp_socket { name_connect } ; [ httpd_can_network_connect_db ]
DT allow httpd_t gopher_port_t : tcp_socket { name_connect } ; [ httpd_can_network_relay ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So by default, the Apache (&lt;code&gt;httpd_t&lt;/code&gt;) domain is allowed to connect to
DNS port (to resolve hostnames). All other &lt;em&gt;name_connect&lt;/em&gt; calls depend
on SELinux booleans (mentioned after it) that are by default disabled
(at least on Gentoo). Disabling hostname resolving is not really
feasible, so if the attacker uses a DNS port as port that the malware
needs to connect to, SELinux will not deny it (unless you use additional
networking constraints).&lt;/p&gt;
&lt;p&gt;Now, the reverse connect is an interesting feature of the malware, but
not the main one. The main focus of the malware is to redirect customers
to particular sites that can trick the user in downloading additional
(client) malware. Because this is done internally within Apache, SELinux
cannot deal with this. As a user, make sure you configure your browser
not to trust non-local iframes and such (always do this, not just
because there is a possible threat right now). The configuration of
Cdorked is a shared memory segment of Apache itself. Of course, since
Apache uses shared memory, the malware embedded within will also have
access to the shared memory. However, if this shared memory would need
to be accessed by third party applications (the malware seems to grant
read/write rights on everybody to this segment) SELinux will prevent
this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# sesearch -t httpd_t -c shm -ACTS
Found 2 semantic av rules:
   allow unconfined_domain_type domain : shm { create destroy getattr setattr read write associate unix_read unix_write lock } ; 
   allow httpd_t httpd_t : shm { create destroy getattr setattr read write associate unix_read unix_write lock } ;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Only unconfined domains and the &lt;code&gt;httpd_t&lt;/code&gt; domain itself have access to
&lt;code&gt;httpd_t&lt;/code&gt; labeled shared memory.&lt;/p&gt;
&lt;p&gt;So what about IMA/EVM? Well, those will not help here since IMA checks
for integrity of files that were modified &lt;em&gt;offline&lt;/em&gt;. As the modification
of the Apache binaries is most likely done online, IMA would just accept
this.&lt;/p&gt;
&lt;p&gt;For now, it seems that a good system integrity approach is the most
effective until we know more about how the malware-infected binary is
written to the system in the first place (as this is better protected by
MAC controls like SELinux).&lt;/p&gt;</content><category term="Security"></category><category term="apache"></category><category term="cdorked"></category><category term="Gentoo"></category><category term="hardened"></category><category term="ima"></category><category term="selinux"></category></entry><entry><title>Overview of Linux capabilities, part 3</title><link href="https://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-3/" rel="alternate"></link><published>2013-05-06T03:50:00+02:00</published><updated>2013-05-06T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-06:/2013/05/overview-of-linux-capabilities-part-3/</id><summary type="html">&lt;p&gt;In &lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro/"&gt;previous&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/restricting-and-granting-capabilities/"&gt;posts&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-1/"&gt;I&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-2/"&gt;talked&lt;/a&gt;
about capabilities and gave an introduction to how this powerful
security feature within Linux can be used (and also exploited). I also
covered a few capabilities, so let's wrap this up with the remainder of
them.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;CAP_AUDIT_CONTROL&lt;/dt&gt;
&lt;dd&gt;Enable and disable kernel auditing; change auditing filter …&lt;/dd&gt;&lt;/dl&gt;</summary><content type="html">&lt;p&gt;In &lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro/"&gt;previous&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/restricting-and-granting-capabilities/"&gt;posts&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-1/"&gt;I&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-2/"&gt;talked&lt;/a&gt;
about capabilities and gave an introduction to how this powerful
security feature within Linux can be used (and also exploited). I also
covered a few capabilities, so let's wrap this up with the remainder of
them.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;CAP_AUDIT_CONTROL&lt;/dt&gt;
&lt;dd&gt;Enable and disable kernel auditing; change auditing filter rules;
retrieve auditing status and filtering rules&lt;/dd&gt;
&lt;dt&gt;CAP_AUDIT_WRITE&lt;/dt&gt;
&lt;dd&gt;Write records to kernel auditing log&lt;/dd&gt;
&lt;dt&gt;CAP_BLOCK_SUSPEND&lt;/dt&gt;
&lt;dd&gt;Employ features that can block system suspend&lt;/dd&gt;
&lt;dt&gt;CAP_MAC_ADMIN&lt;/dt&gt;
&lt;dd&gt;Override Mandatory Access Control (implemented for the SMACK LSM)&lt;/dd&gt;
&lt;dt&gt;CAP_MAC_OVERRIDE&lt;/dt&gt;
&lt;dd&gt;Allow MAC configuration or state changes (implemented for the
SMACK LSM)&lt;/dd&gt;
&lt;dt&gt;CAP_NET_ADMIN&lt;/dt&gt;
&lt;dd&gt;Perform various network-related operations:
&lt;/p&gt;
-   interface configuration
-   administration of IP firewall, masquerading and accounting
-   modify routing tables
-   bind to any address for transparent proxying
-   set type-of-service (TOS)
-   clear driver statistics
-   set promiscuous mode
-   enabling multicasting
-   use &lt;em&gt;setsockopt()&lt;/em&gt; for privileged socket operations&lt;/dd&gt;
&lt;dt&gt;CAP_NET_BIND_SERVICE&lt;/dt&gt;
&lt;dd&gt;Bind a socket to Internet domain privileged ports (less than 1024)&lt;/dd&gt;
&lt;dt&gt;CAP_NET_RAW&lt;/dt&gt;
&lt;dd&gt;Use RAW and PACKET sockets, and bind to any address for transparent
proxying&lt;/dd&gt;
&lt;dt&gt;CAP_SETPCAP&lt;/dt&gt;
&lt;dd&gt;Allow the process to add any capability from the calling thread's
bounding set to its inheritable set, and drop capabilities from the
bounding set (using &lt;em&gt;prctl()&lt;/em&gt;) and make changes to the
&lt;em&gt;securebits&lt;/em&gt; flags.&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_ADMIN&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Very powerful capability, includes:
&lt;/p&gt;
-   Running quota control, mount, swap management, set hostname, ...
-   Perform &lt;em&gt;VM86_REQUEST_IRQ vm86&lt;/em&gt; command
-   Perform &lt;em&gt;IPC_SET&lt;/em&gt; and &lt;em&gt;IPC_RMID&lt;/em&gt; operations on arbitrary
    System V IPC objects
-   Perform operations on &lt;code&gt;trusted.*&lt;/code&gt; and &lt;code&gt;security.*&lt;/code&gt; extended
    attributes
-   Use &lt;em&gt;lookup_dcookie&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
and many, many more. &lt;strong&gt;man capabilities&lt;/strong&gt; gives a good overview
of them.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_BOOT&lt;/dt&gt;
&lt;dd&gt;Use &lt;em&gt;reboot()&lt;/em&gt; and &lt;em&gt;kexec_load()&lt;/em&gt;&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_CHROOT&lt;/dt&gt;
&lt;dd&gt;Use &lt;em&gt;chroot()&lt;/em&gt;&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_MODULE&lt;/dt&gt;
&lt;dd&gt;Load and unload kernel modules&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_RESOURCE&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Another capability with many consequences, including:
&lt;/p&gt;
-   Use reserved space on ext2 file systems
-   Make &lt;em&gt;ioctl()&lt;/em&gt; calls controlling ext3 journaling
-   Override disk quota limits
-   Increase resource limits
-   Override &lt;code&gt;RLIMIT_NPROC&lt;/code&gt; resource limits&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
and many more.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_TIME&lt;/dt&gt;
&lt;dd&gt;Set system clock and real-time hardware clock&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_TTY_CONFIG&lt;/dt&gt;
&lt;dd&gt;Use &lt;em&gt;vhangup()&lt;/em&gt; and employ various privileged &lt;em&gt;ioctl()&lt;/em&gt; operations
on virtual terminals&lt;/dd&gt;
&lt;dt&gt;CAP_SYSLOG&lt;/dt&gt;
&lt;dd&gt;Perform privileged &lt;em&gt;syslog()&lt;/em&gt; operations and view kernel addresses
exposed with &lt;code&gt;/proc&lt;/code&gt; and other interfaces (if &lt;code&gt;kptr_restrict&lt;/code&gt;
is set)&lt;/dd&gt;
&lt;dt&gt;CAP_WAKE_ALARM&lt;/dt&gt;
&lt;dd&gt;Trigger something that will wake up the system&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Now when you look through the manual page of the capabilities, you'll
notice it talks about &lt;em&gt;securebits&lt;/em&gt; as well. This is an additional set of
flags that govern how capabilities are used, inherited etc. System
administrators don't set these flags - they are governed by the
applications themselves (when creating threads, forking, etc.) These
flags are set on a per-thread level, and govern the following behavior:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;SECBIT_KEEP_CAPS&lt;/dt&gt;
&lt;dd&gt;Allow a thread with UID 0 to retain its capabilities when it
switches its UIDs to a nonzero (non-root) value. By default, this
flag is &lt;em&gt;not&lt;/em&gt; set, and even if it is set, it is cleared on an
&lt;em&gt;execve&lt;/em&gt; call, reducing the likelihood that capabilities
are "leaked".&lt;/dd&gt;
&lt;dt&gt;SECBIT_NO_SETUID_FIXUP&lt;/dt&gt;
&lt;dd&gt;When set, the kernel will not adjust the capability sets when the
thread's effective and file system UIDs are switched between
zero (root) and non-zero values.&lt;/dd&gt;
&lt;dt&gt;SECBIT_NOROOT&lt;/dt&gt;
&lt;dd&gt;If set, the kernel does not grant capabilities when a setuid-root
program is executed, or when a process with an effective or real UID
of 0 (root) calls &lt;em&gt;execve&lt;/em&gt;.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Manipulating these bits requires the &lt;code&gt;CAP_SETPCAP&lt;/code&gt; capability. Except
for the &lt;code&gt;SECBIT_KEEP_CAPS&lt;/code&gt; security bit, the others are preserved on an
&lt;em&gt;execve()&lt;/em&gt; call, and all bits are inherited by child processes (such as
when &lt;em&gt;fork()&lt;/em&gt; is used).&lt;/p&gt;
&lt;p&gt;As a user or admin, you can also see capability-related information
through the &lt;code&gt;/proc&lt;/code&gt; file system:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt; # grep ^Cap /proc/$$/status
CapInh: 0000000000000000
CapPrm: 0000001fffffffff
CapEff: 0000001fffffffff
CapBnd: 0000001fffffffff

$ grep ^Cap /proc/$$/status
CapInh: 0000000000000000
CapPrm: 0000000000000000
CapEff: 0000000000000000
CapBnd: 0000001fffffffff
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The capabilities listed therein are bitmasks for the various
capabilities. The mask &lt;code&gt;1FFFFFFFFF&lt;/code&gt; holds 37 positions, which match the
37 capabilities known (again, see &lt;code&gt;uapi/linux/capabilities.h&lt;/code&gt; in the
kernel sources to see the values of each of the capabilities). Again,
the &lt;strong&gt;pscap&lt;/strong&gt; can be used to get information about the enabled
capabilities of running processes in a more human readable format. But
another tool provided by the &lt;code&gt;sys-libs/libcap&lt;/code&gt; is interested as well to
look at: &lt;strong&gt;capsh&lt;/strong&gt;. The tool offers many capability-related features,
including decoding the &lt;code&gt;status&lt;/code&gt; fields:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ capsh --decode=0000001fffffffff
0x0000001fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,
cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,
cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,
cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,
cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,
cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,
cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,
cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,
cap_syslog,35,36
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next to fancy decoding, &lt;strong&gt;capsh&lt;/strong&gt; can also launch a shell with reduced
capabilities. This makes it a good utility for jailing chroots even
more.&lt;/p&gt;</content><category term="Security"></category><category term="capabilities"></category><category term="capsh"></category><category term="libcap"></category><category term="linux"></category></entry><entry><title>Overview of Linux capabilities, part 2</title><link href="https://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-2/" rel="alternate"></link><published>2013-05-05T03:50:00+02:00</published><updated>2013-05-05T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-05:/2013/05/overview-of-linux-capabilities-part-2/</id><summary type="html">&lt;p&gt;As I've (in a very high level) &lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro/"&gt;described
capabilities&lt;/a&gt;
and talked a bit on how to &lt;a href="http://blog.siphos.be/2013/05/restricting-and-granting-capabilities/"&gt;work with
them&lt;/a&gt;,
I started with a small overview of
&lt;a href="http://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-1/"&gt;file-related&lt;/a&gt;
capabilities. So next up are process-related capabilities (note, this
isn't a conform terminology, more some categorization that I do myself).&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;CAP_IPC_LOCK&lt;/dt&gt;
&lt;dd&gt;Allow the …&lt;/dd&gt;&lt;/dl&gt;</summary><content type="html">&lt;p&gt;As I've (in a very high level) &lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro/"&gt;described
capabilities&lt;/a&gt;
and talked a bit on how to &lt;a href="http://blog.siphos.be/2013/05/restricting-and-granting-capabilities/"&gt;work with
them&lt;/a&gt;,
I started with a small overview of
&lt;a href="http://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-1/"&gt;file-related&lt;/a&gt;
capabilities. So next up are process-related capabilities (note, this
isn't a conform terminology, more some categorization that I do myself).&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;CAP_IPC_LOCK&lt;/dt&gt;
&lt;dd&gt;Allow the process to lock memory&lt;/dd&gt;
&lt;dt&gt;CAP_IPC_OWNER&lt;/dt&gt;
&lt;dd&gt;Bypass the permission checks for operations on System V IPC objects
(similar to the &lt;code&gt;CAP_DAC_OVERRIDE&lt;/code&gt; for files)&lt;/dd&gt;
&lt;dt&gt;CAP_KILL&lt;/dt&gt;
&lt;dd&gt;Bypass permission checks for sending signals&lt;/dd&gt;
&lt;dt&gt;CAP_SETUID&lt;/dt&gt;
&lt;dd&gt;Allow the process to make arbitrary manipulations of process UIDs
and create forged UID when passing socket credentials via UNIX
domain sockets&lt;/dd&gt;
&lt;dt&gt;CAP_SETGID&lt;/dt&gt;
&lt;dd&gt;Same, but then for GIDs&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_NICE&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;This capability governs several permissions/abilities, namely to
allow the process to
&lt;/p&gt;
-   change the &lt;em&gt;nice&lt;/em&gt; value of itself and other processes
-   set real-time scheduling priorities for itself, and set
    scheduling policies and priorities for arbitrary processes
-   set the CPU affinity for arbitrary processes
-   apply &lt;em&gt;migrate_pages&lt;/em&gt; to arbitrary processes and allow
    processes to be migrated to arbitrary nodes
-   apply &lt;em&gt;move_pages&lt;/em&gt; to arbitrary processes
-   use the &lt;code&gt;MPOL_MF_MOVE_ALL&lt;/code&gt; flag with &lt;em&gt;mbind()&lt;/em&gt; and
    &lt;em&gt;move_pages()&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;
The abilities related to page moving, migration and nodes is of
importance for NUMA systems, not something most workstations have
or need.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_PACCT&lt;/dt&gt;
&lt;dd&gt;Use &lt;em&gt;acct()&lt;/em&gt;, to enable or disable system resource accounting for
the process&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_PTRACE&lt;/dt&gt;
&lt;dd&gt;Allow the process to trace arbitrary processes using &lt;em&gt;ptrace()&lt;/em&gt;,
apply &lt;em&gt;get_robust_list()&lt;/em&gt; against arbitrary processes and inspect
processes using &lt;em&gt;kcmp()&lt;/em&gt;.&lt;/dd&gt;
&lt;dt&gt;CAP_SYS_RAWIO&lt;/dt&gt;
&lt;dd&gt;Allow the process to perform I/O port operations, access
&lt;code&gt;/proc/kcore&lt;/code&gt; and employ the &lt;code&gt;FIBMAP&lt;/code&gt; &lt;em&gt;ioctl()&lt;/em&gt; operation.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Capabilities such as &lt;code&gt;CAP_KILL&lt;/code&gt; and &lt;code&gt;CAP_SETUID&lt;/code&gt; are very important to
govern correctly, but this post would be rather dull (given that the
definitions of the above capabilities can be found from the manual page)
if I wouldn't talk a bit more about its feasibility. Take a look at the
following C application code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;sys/capability.h&amp;gt;
#include &amp;lt;sys/prctl.h&amp;gt;
#include &amp;lt;sys/types.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

int main(int argc, char ** argv) {
  printf(&amp;quot;cap_setuid and cap_setgid: %d\n&amp;quot;, prctl(PR_CAPBSET_READ, CAP_SETUID|CAP_SETGID, 0, 0, 0));
  printf(&amp;quot; %s\n&amp;quot;, cap_to_text(cap_get_file(argv[0]), NULL));
  printf(&amp;quot; %s\n&amp;quot;, cap_to_text(cap_get_proc(), NULL));
  if (setresuid(0, 0, 0));
    printf(&amp;quot;setresuid(): %s\n&amp;quot;, strerror(errno));
  execve(&amp;quot;/bin/sh&amp;quot;, NULL, NULL);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At first sight, it looks like an application to get root privileges
(&lt;em&gt;setresuid()&lt;/em&gt;) and then spawn a shell. If that application would be
given &lt;code&gt;CAP_SETUID&lt;/code&gt; and &lt;code&gt;CAP_SETGID&lt;/code&gt; effectively, it would allow anyone
who executed it to automatically get a root shell, wouldn't it?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ gcc -o test -lcap test.c
# setcap cap_setuid,cap_setgid+ep test
$ ./test
cap_setuid and cap_setgid: 1
 = cap_setgid,cap_setuid+ep
 =
setresuid() failed: Operation not permitted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So what happened? After all, the two capabilities are set with the &lt;em&gt;+ep&lt;/em&gt;
flags given. Then why aren't these capabilities enabled? Well, this
binary was stored on a file system that is mounted with the &lt;em&gt;nosuid&lt;/em&gt;
option. As a result, this capability is &lt;em&gt;not&lt;/em&gt; enabled and the
application didn't work. If I move the file to another file system that
doesn't have the &lt;em&gt;nosuid&lt;/em&gt; option:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ /usr/local/bin/test
cap_setuid and cap_setgid: 1
 = cap_setgid,cap_setuid+ep
 = cap_setgid,cap_setuid+ep
setresuid() failed: Operation not permitted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So the capabilities now do get enabled, so why does this still fail?
This now is due to SELinux:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;type=AVC msg=audit(1367393377.342:4778): avc:  denied  { setuid } for  pid=21418 comm=&amp;quot;test&amp;quot; capability=7  scontext=staff_u:staff_r:staff_t tcontext=staff_u:staff_r:staff_t tclass=capability
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And if you enable grSecurity's TPE, we can't even start the binary to
begin with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ ./test
-bash: ./test: Permission denied
$ /lib/ld-linux-x86-64.so.2 /home/test/test
/home/test/test: error while loading shared libraries: /home/test/test: failed to map segment from shared object: Permission denied

# dmesg
...
[ 5579.567842] grsec: From 192.168.100.1: denied untrusted exec (due to not being in trusted group and file in non-root-owned directory) of /home/test/test by /home/test/test[bash:4221] uid/euid:1002/1002 gid/egid:100/100, parent /bin/bash[bash:4195] uid/euid:1002/1002 gid/egid:100/100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When all these "security obstacles" are not enabled, then the call
succeeds:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ /usr/local/bin/test
cap_setuid and cap_setgid: 1
 = cap_setgid,cap_setuid+ep
 = cap_setgid,cap_setuid+ep
setresuid() failed: Success
root@hpl tmp #
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This again shows how important it is to regularly review
capability-enabled files on the file system, as this is a major security
problem that cannot be detected by only looking for setuid binaries, but
also that securing a system is not limited to one or a few settings: one
always has to take the entire setup into consideration, hardening the
system so it becomes more difficult for malicious users to abuse it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# filecap -a
file                 capabilities
/usr/local/bin/test     setgid, setuid
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="Security"></category><category term="capabilities"></category><category term="grsecurity"></category><category term="linux"></category><category term="nosuid"></category><category term="selinux"></category><category term="tpe"></category></entry><entry><title>Overview of Linux capabilities, part 1</title><link href="https://blog.siphos.be/2013/05/overview-of-linux-capabilities-part-1/" rel="alternate"></link><published>2013-05-04T03:50:00+02:00</published><updated>2013-05-04T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-04:/2013/05/overview-of-linux-capabilities-part-1/</id><summary type="html">&lt;p&gt;In the
&lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro/"&gt;previous&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/restricting-and-granting-capabilities/"&gt;posts&lt;/a&gt;,
I talked about capabilities and how they can be used to allow processes
to run in a privileged fashion without granting them full root access to
the system. An example given was how capabilities can be leveraged to
run &lt;strong&gt;ping&lt;/strong&gt; without granting it setuid root rights …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the
&lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro/"&gt;previous&lt;/a&gt;
&lt;a href="http://blog.siphos.be/2013/05/restricting-and-granting-capabilities/"&gt;posts&lt;/a&gt;,
I talked about capabilities and how they can be used to allow processes
to run in a privileged fashion without granting them full root access to
the system. An example given was how capabilities can be leveraged to
run &lt;strong&gt;ping&lt;/strong&gt; without granting it setuid root rights. But what are the
various capabilities that Linux is, well, capable of?&lt;/p&gt;
&lt;p&gt;There are many, and as time goes by, more capabilities are added to the
set. The last capability added to the main Linux kernel tree was the
&lt;code&gt;CAP_BLOCK_SUSPEND&lt;/code&gt; in the 3.5 series. An overview of all capabilities
can be seen with &lt;strong&gt;man capabilities&lt;/strong&gt; or by looking at the Linux kernel
source code, &lt;code&gt;include/uapi/linux/capability.h&lt;/code&gt;. But because you are all
lazy, and because it is a good exercise for myself, I'll go through many
of them in this and the next few posts.&lt;/p&gt;
&lt;p&gt;For now, let's look at file related capabilities. As a reminder, if you
want to know which SELinux domains are "granted" a particular
capability, you can look this up using &lt;strong&gt;sesearch&lt;/strong&gt;. The capability is
either in the &lt;em&gt;capability&lt;/em&gt; or &lt;em&gt;capability2&lt;/em&gt; class, and is named after
the capability itself, without the &lt;code&gt;CAP_&lt;/code&gt; prefix:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sesearch -c capability -p chown -A
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;dl&gt;
&lt;dt&gt;CAP_CHOWN&lt;/dt&gt;
&lt;dd&gt;Allow making changes to the file UIDs and GIDs.&lt;/dd&gt;
&lt;dt&gt;CAP_DAC_OVERRIDE&lt;/dt&gt;
&lt;dd&gt;Bypass file read, write and execute permission checks. I came across
a &lt;a href="http://www.reddit.com/r/linux/comments/1cnn15/for_chmod_why_is_root_allowed_to_execute_programs/"&gt;reddit
post&lt;/a&gt;
that was about this capability not that long ago.&lt;/dd&gt;
&lt;dt&gt;CAP_DAC_READ_SEARCH&lt;/dt&gt;
&lt;dd&gt;Bypass file read permission and directory read/search
permission checks.&lt;/dd&gt;
&lt;dt&gt;CAP_FOWNER&lt;/dt&gt;
&lt;dd&gt;This capability governs 5 capabilities in one:
&lt;/p&gt;
-   Bypass permission checks on operations that normally require the
    file system UID of the process to match the UID of the file
    (unless already granted through &lt;code&gt;CAP_DAC_READ_SEARCH&lt;/code&gt; and/or
    &lt;code&gt;CAP_DAC_OVERRIDE&lt;/code&gt;)
-   Allow to set extended file attributes
-   Allow to set access control lists
-   Ignore directory sticky bit on file deletion
-   Allow specifying &lt;code&gt;O_NOATIME&lt;/code&gt; for files in &lt;em&gt;open()&lt;/em&gt; and &lt;em&gt;fnctl()&lt;/em&gt;
    calls&lt;/dd&gt;
&lt;dt&gt;CAP_FSETID&lt;/dt&gt;
&lt;dd&gt;Do not clear the setuid/setgid permission bits when a file is
modified&lt;/dd&gt;
&lt;dt&gt;CAP_LEASE&lt;/dt&gt;
&lt;dd&gt;Allow establishing leases on files&lt;/dd&gt;
&lt;dt&gt;CAP_LINUX_IMMUTABLE&lt;/dt&gt;
&lt;dd&gt;Allow setting &lt;em&gt;FS_APPEND_FL&lt;/em&gt; and &lt;em&gt;FP_IMMUTABLE_FL&lt;/em&gt; inode flags&lt;/dd&gt;
&lt;dt&gt;CAP_MKNOD&lt;/dt&gt;
&lt;dd&gt;Allow creating special files with &lt;strong&gt;mknod&lt;/strong&gt;&lt;/dd&gt;
&lt;dt&gt;CAP_SETFCAP&lt;/dt&gt;
&lt;dd&gt;Allow setting file capabilities (what I did with the &lt;strong&gt;anotherping&lt;/strong&gt;
binary in the previous post)&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;When working with SELinux (especially when writing applications), you'll
find that the &lt;code&gt;CAP_DAC_READ_SEARCH&lt;/code&gt; and &lt;code&gt;CAP_DAC_OVERRIDE&lt;/code&gt; capability
come up often. This is the case when applications are written to run as
root yet want to scan through, read or even execute non-root owned
files. Without SELinux, because these run as root, this is all granted.
However, when you start confining those applications, it becomes
apparent that they require this capability. Another example is when you
run user applications, as root, like when trying to play a movie or
music file with &lt;strong&gt;mplayer&lt;/strong&gt; when this file is owned by a regular user:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;type=AVC msg=audit(1367145131.860:18785): avc:  denied  { dac_read_search } for
pid=8153 comm=&amp;quot;mplayer&amp;quot; capability=2  scontext=staff_u:sysadm_r:mplayer_t
tcontext=staff_u:sysadm_r:mplayer_t tclass=capability

type=AVC msg=audit(1367145131.860:18785): avc:  denied  { dac_override } for
pid=8153 comm=&amp;quot;mplayer&amp;quot; capability=1  scontext=staff_u:sysadm_r:mplayer_t
tcontext=staff_u:sysadm_r:mplayer_t tclass=capability
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notice the time stamp: both checks are triggered at the same time. What
happens is that the Linux security hooks first check for
&lt;code&gt;DAC_READ_SEARCH&lt;/code&gt; (the "lesser" grants of the two) and then for
&lt;code&gt;DAC_OVERRIDE&lt;/code&gt; (which contains &lt;code&gt;DAC_READ_SEARCH&lt;/code&gt; and more). In both
cases, the check failed in the above example.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;CAP_LEASE&lt;/code&gt; capability is one that I had not heard about before
(actually, I had not heard of getting "file leases" on Linux either). A
file lease allows for the lease holder (which requires this capability)
to be notified when another process tries to open or truncate the file.
When that happens, the call itself is blocked and the lease holder is
notified (usually using SIGIO) about the access. It is not really to
lock a file (since, if the lease holder doesn't properly release it, it
is forcefully "broken" and the other process can continue its work) but
rather to properly close the file descriptor or flushing caches, etc.&lt;/p&gt;
&lt;p&gt;BTW, on my system, only 5 SELinux domains hold the &lt;em&gt;lease&lt;/em&gt; capability.&lt;/p&gt;
&lt;p&gt;There are 37 capabilities known by the Linux kernel at this time. The
above list has 9 file related ones. So perhaps next I can talk about
process capabilities.&lt;/p&gt;</content><category term="Security"></category><category term="capabilities"></category><category term="linux"></category></entry><entry><title>Restricting and granting capabilities</title><link href="https://blog.siphos.be/2013/05/restricting-and-granting-capabilities/" rel="alternate"></link><published>2013-05-03T03:50:00+02:00</published><updated>2013-05-03T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-03:/2013/05/restricting-and-granting-capabilities/</id><summary type="html">&lt;p&gt;As
&lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro"&gt;capabilities&lt;/a&gt;
are a way for running processes with some privileges, without having the
need to grant them root privileges, it is important to understand that
they exist if you are a system administrator, but also as an auditor or
other security-related function. Having processes run as a non-root user …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As
&lt;a href="http://blog.siphos.be/2013/05/capabilities-a-short-intro"&gt;capabilities&lt;/a&gt;
are a way for running processes with some privileges, without having the
need to grant them root privileges, it is important to understand that
they exist if you are a system administrator, but also as an auditor or
other security-related function. Having processes run as a non-root user
is no longer sufficient to assume that they do not hold any rights to
mess up the system or read files they shouldn't be able to read.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://grsecurity.net/"&gt;grsecurity&lt;/a&gt; kernel patch set, which is
applied to the Gentoo hardened kernel sources, contains for instance
&lt;code&gt;CONFIG_GRKERNSEC_CHROOT_CAPS&lt;/code&gt; which, as per its documentation,
"restrcts the capabilities on all root processes within a chroot jail to
stop module insertion, raw i/o, system and net admin tasks, rebooting
the system, modifying immutable files, modifying IPC owned by another,
and changing the system time." But other implementations might even use
capabilities to restrict the users. Consider
&lt;a href="http://lxc.sourceforge.net/"&gt;LXC&lt;/a&gt; (Linux Containers). When a container
is started, &lt;code&gt;CAP_SYS_BOOT&lt;/code&gt; (the ability to shutdown/reboot the
system/container) is removed so that users cannot abuse this privilege.&lt;/p&gt;
&lt;p&gt;You can also grant capabilities to users selectively, using &lt;code&gt;pam_cap.so&lt;/code&gt;
(the Capabilities Pluggable Authentication Module). For instance, to
allow some users to ping, instead of granting the &lt;code&gt;cap_net_raw&lt;/code&gt;
immediately (&lt;em&gt;+ep&lt;/em&gt;), we can assign the capability to some users through
PAM, and have the &lt;strong&gt;ping&lt;/strong&gt; binary inherit and use this capability
instead (&lt;em&gt;+p&lt;/em&gt;). That doesn't mean that the capability is in effect, but
rather that it is in a sort-of permitted set. Applications that are
granted a certain permission this way can either use this capability if
the user is allowed to have it, or won't otherwise.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# setcap cap_net_raw+p anotherping

# vim /etc/pam.d/system-login
... add in something like
auth     required     pam_cap.so

# vim /etc/security/capability.conf
... add in something like
cap_net_raw           user1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The logic used with capabilities can be described as follows (it is not
as difficult as it looks):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;        pI&amp;#39; = pI
  (***) pP&amp;#39; = fP | (fI &amp;amp; pI)
        pE&amp;#39; = pP&amp;#39; &amp;amp; fE          [NB. fE is 0 or ~0]

  I=Inheritable, P=Permitted, E=Effective // p=process, f=file
  &amp;#39; indicates post-exec().
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So, for instance, the second line reads "The permitted set of
capabilities of the newly forked process is set to the permitted set of
capabilities of its executable file, together with the result of the AND
operation between the inherited capabilities of the file and the
inherited capabilities of the parent process."&lt;/p&gt;
&lt;p&gt;As an admin, you might want to keep an eye out for binaries that have
particular capabilities set. With &lt;strong&gt;filecap&lt;/strong&gt; you can list which
capabilities are in the effective set of files found on the file system
(for instance, &lt;em&gt;+ep&lt;/em&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# filecap 
file                 capabilities
/bin/anotherping     net_raw
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Similarly, with &lt;strong&gt;pscap&lt;/strong&gt; you can see the capabilities set on running
processes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# pscap -a
ppid  pid   name        command           capabilities
6148  6152  root        bash              full
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It might be wise to take this up in the daily audit reports.&lt;/p&gt;</content><category term="Security"></category><category term="capabilities"></category><category term="linux"></category></entry><entry><title>Capabilities, a short intro</title><link href="https://blog.siphos.be/2013/05/capabilities-a-short-intro/" rel="alternate"></link><published>2013-05-02T03:50:00+02:00</published><updated>2013-05-02T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-05-02:/2013/05/capabilities-a-short-intro/</id><summary type="html">&lt;p&gt;Capabilities. You probably have heard of them already, but when you
start developing SELinux policies, you'll notice that you come in closer
contact with them than before. This is because SELinux, when
applications want to do something "root-like", checks the capability of
that application. Without SELinux, this either requires the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Capabilities. You probably have heard of them already, but when you
start developing SELinux policies, you'll notice that you come in closer
contact with them than before. This is because SELinux, when
applications want to do something "root-like", checks the capability of
that application. Without SELinux, this either requires the binary to
have the proper capability set, or the application to run in root modus.
With SELinux, the capability also needs to be granted to the SELinux
context (the domain in which the application runs).&lt;/p&gt;
&lt;p&gt;But forget about SELinux for now, and let's focus on capabilities.
Capabilities in Linux are flags that tell the kernel what the
application is allowed to do, but unlike file access, capabilities for
an application are system-wide: there is no "target" to which it
applies. Think about an "ability" of an application. See for yourself
through &lt;strong&gt;man capabilities&lt;/strong&gt;. If you have no additional security
mechanism in place, the Linux root user has all capabilities assigned to
it. And you can remove capabilities from the root user if you want to,
but generally, capabilities are used to grant applications that tiny bit
more privileges, without needing to grant them root rights.&lt;/p&gt;
&lt;p&gt;Consider the &lt;strong&gt;ping&lt;/strong&gt; utility. It is marked setuid root on some
distributions, because the utility requires the (cap)ability to send raw
packets. This capability is known as &lt;code&gt;CAP_NET_RAW&lt;/code&gt;. However, thanks to
capabilities, you can now mark the &lt;strong&gt;ping&lt;/strong&gt; application with this
capability and drop the setuid from the file. As a result, the
application does not run with full root privileges anymore, but with the
restricted privileges of the user plus one capability, namely the
&lt;code&gt;CAP_NET_RAW&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let's take this &lt;strong&gt;ping&lt;/strong&gt; example to the next level: copy the binary
(possibly relabel it as &lt;code&gt;ping_exec_t&lt;/code&gt; if you run with SELinux), make
sure it does not hold the setuid and try it out:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# cp ping anotherping
# chcon -t ping_exec_t anotherping
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now as a regular user:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ ping -c 1 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.057 ms

$ anotherping -c 1 127.0.0.1
ping: icmp open socket: Operation not permitted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's assign the binary with the &lt;code&gt;CAP_NET_RAW&lt;/code&gt; capability flag:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# setcap cap_net_raw+ep anotherping
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And tadaa:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ anotherping -c 1 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.054 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What &lt;strong&gt;setcap&lt;/strong&gt; did was place an extended attribute to the file, which
is a binary representation of the capabilities assigned to the
application. The additional information (&lt;code&gt;+ep&lt;/code&gt;) means that the
capability is &lt;em&gt;p&lt;/em&gt;ermitted and &lt;em&gt;e&lt;/em&gt;ffective.&lt;/p&gt;
&lt;p&gt;So long for the primer, I'll talk about the various capabilities in a
later post.&lt;/p&gt;</content><category term="Security"></category><category term="capabilities"></category><category term="linux"></category><category term="ping"></category><category term="selinux"></category></entry><entry><title>Securely handling libffi</title><link href="https://blog.siphos.be/2013/04/securely-handling-libffi/" rel="alternate"></link><published>2013-04-28T03:50:00+02:00</published><updated>2013-04-28T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-04-28:/2013/04/securely-handling-libffi/</id><summary type="html">&lt;p&gt;I've recently came across &lt;a href="http://sourceware.org/libffi/"&gt;libffi&lt;/a&gt; again.
No, not because it was mentioned during the &lt;a href="http://www.gentoo.org/proj/en/hardened"&gt;Gentoo
Hardened&lt;/a&gt; online meeting, but
because my &lt;code&gt;/var/tmp&lt;/code&gt; wasn't mounted correctly, and &lt;strong&gt;emerge&lt;/strong&gt; (actually
python) uses libffi. Most users won't notice this, because libffi works
behind the scenes. But when it fails, it fails bad …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've recently came across &lt;a href="http://sourceware.org/libffi/"&gt;libffi&lt;/a&gt; again.
No, not because it was mentioned during the &lt;a href="http://www.gentoo.org/proj/en/hardened"&gt;Gentoo
Hardened&lt;/a&gt; online meeting, but
because my &lt;code&gt;/var/tmp&lt;/code&gt; wasn't mounted correctly, and &lt;strong&gt;emerge&lt;/strong&gt; (actually
python) uses libffi. Most users won't notice this, because libffi works
behind the scenes. But when it fails, it fails bad. And SELinux actually
helped me quickly identify what the problem is.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ emerge --info
segmentation fault
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The abbreviation "libffi" comes from &lt;em&gt;Foreign Function Interface&lt;/em&gt;, and
is a library that allows developers to dynamically call code from
another application or library. But the method how it approaches this
concerns me a bit. Let's look at some &lt;strong&gt;strace&lt;/strong&gt; output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;8560  open(&amp;quot;/var/tmp/ffiZ8gKPd&amp;quot;, O_RDWR|O_CREAT|O_EXCL, 0600) = 11
8560  unlink(&amp;quot;/var/tmp/ffiZ8gKPd&amp;quot;)      = 0
8560  ftruncate(11, 4096)               = 0
8560  mmap(NULL, 4096, PROT_READ|PROT_EXEC, MAP_SHARED, 11, 0) = -1 EACCES (Permission denied)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Generally, what libffi does, is to create a file somewhere where it can
write files (it checks the various mounts on a system to get a list of
possible target file systems), adds the necessary data (that it wants to
execute) to it, unlinks the file from the file system (but keep the file
descriptor open, so that the file cannot (easily) be modified on the
system anymore) and then maps it to memory for executable access. &lt;em&gt;If&lt;/em&gt;
executing is allowed by the system (for instance because the mount point
does not have &lt;code&gt;noexec&lt;/code&gt;), then SELinux will trap it because the domain
(in our case now, &lt;code&gt;portage_t&lt;/code&gt;) is trying to execute an (unlinked) file
for which it holds no execute rights on:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;type=AVC msg=audit(1366656205.201:2221): avc:  denied  { execute } for  
pid=8560 comm=&amp;quot;emerge&amp;quot; path=2F7661722F66666962713154465A202864656C6574656429 
dev=&amp;quot;dm-3&amp;quot; ino=6912 scontext=staff_u:sysadm_r:portage_t tcontext=staff_u:object_r:var_t
tclass=file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When you notice something like this (an execute on an unnamed file),
then this is because the file descriptor points to a file already
unlinked from the system. Finding out what it was about might be hard
(but with &lt;strong&gt;strace&lt;/strong&gt; it is easy as ... well, whatever is easy for you).&lt;/p&gt;
&lt;p&gt;Now what happened was that, because &lt;code&gt;/var/tmp&lt;/code&gt; wasn't mounted, files
created inside it got the standard type (&lt;code&gt;var_t&lt;/code&gt;) which the Portage
domain isn't allowed to execute. It is allowed to execute a lot of
types, but not that one ;-) When &lt;code&gt;/var/tmp&lt;/code&gt; is properly mounted, the
file gets the &lt;code&gt;portage_tmp_t&lt;/code&gt; type where it does hold execute rights
for.&lt;/p&gt;
&lt;p&gt;Now generally, I don't like having world-writeable locations without
&lt;code&gt;noexec&lt;/code&gt;. For &lt;code&gt;/tmp&lt;/code&gt;, &lt;code&gt;noexec&lt;/code&gt; is enabled, but for &lt;code&gt;/var/tmp&lt;/code&gt; I have
(well, had ;-) to allow execution from the file system, mainly because
some (many?) Gentoo package builds require it. So how about this dual
requirement, of allowing Portage to write (and execute) its own files,
and allow libffi to do its magic? Certainly, from a security point of
view, I might want to restrict this further...&lt;/p&gt;
&lt;p&gt;Well, we need to make sure that the location where Portage works with
(the location pointed to by &lt;code&gt;$PORTAGE_TMPDIR&lt;/code&gt;) is specifically made
available for Portage: have the directory only writable by the Portage
user. I keep it labeled as &lt;code&gt;tmp_t&lt;/code&gt; so that the existing policies apply,
but it might work with &lt;code&gt;portage_tmp_t&lt;/code&gt; immediately set as well. Perhaps
I'll try that one later. With that set, we can have this mount-point set
with exec rights (so that libffi can place its file there) in a somewhat
more secure manner than allowing exec on world-writeable locations.&lt;/p&gt;
&lt;p&gt;So now my &lt;code&gt;/tmp&lt;/code&gt; and &lt;code&gt;/var/tmp&lt;/code&gt; (and &lt;code&gt;/run&lt;/code&gt; and &lt;code&gt;/dev/shm&lt;/code&gt; and
&lt;code&gt;/lib64/rc/init.d&lt;/code&gt;) are tmpfs-mounts with the &lt;code&gt;noexec&lt;/code&gt; (as well as
&lt;code&gt;nodev&lt;/code&gt; and &lt;code&gt;nosuid&lt;/code&gt;) bits set, with the location pointed towards by
&lt;code&gt;$PORTAGE_TMPDIR&lt;/code&gt; being only really usable by the Portage user:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ ls -ldZ /var/portage
drwxr-x---. 4 portage root system_u:object_r:tmp_t 4096 Apr 22 21:45 /var/portage/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And libffi? Well, allowing applications to create their own executables
and executing it is something that should be carefully governed. I'm not
aware of any existing or past vulnerabilities, but I can imagine that
opening the &lt;code&gt;ffi*&lt;/code&gt; file(s) the moment they come up (to make sure you
have a file descriptor) allows you to overwrite the content after libffi
has created it but before the application actually executes it. By
limiting the locations where applications can write files to (important
step one) and the types they can execute (important step two) we can
already manage this a bit more. Using regular DAC, this is quite
difficult to achieve, but with SELinux, we can actually control this a
bit more.&lt;/p&gt;
&lt;p&gt;Let's first see how many domains are allowed to create, write and
execute files:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sesearch -c file -p write,create,execute -A | grep write | grep create   
 | grep execute | awk &amp;#39;{print $1}&amp;#39; | sort | uniq | wc -l
32
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Okay, 32 target domains. Not that bad, and certainly doable to verify
manually (hell, even in a scripted manner). You can now check which of
those domains have rights to execute generic binaries (&lt;code&gt;bin_t&lt;/code&gt;),
possibly needed for command execution vulnerabilities or privilege
escalation. Or that have specific capabilities. And if you want to know
which of those domains use libffi, you can use &lt;strong&gt;revdep-rebuild&lt;/strong&gt; to
find out which files are linked to the libffi libraries.&lt;/p&gt;
&lt;p&gt;It goes to show that trying to keep your box secure is a never-ending
story (please, companies, allow your system administrators to do their
job by giving them the ability to continuously increase security rather
than have them ask for budget to investigate potential security
mitigation directives based on the paradigm of business case and return
on investment using pareto-analytics blaaaahhhh....), and that SELinux
can certainly be an important method to help achieve it.&lt;/p&gt;</content><category term="Security"></category><category term="libffi"></category><category term="selinux"></category><category term="strace"></category></entry><entry><title>Mitigating DDoS attacks</title><link href="https://blog.siphos.be/2013/04/mitigating-ddos-attacks/" rel="alternate"></link><published>2013-04-22T03:50:00+02:00</published><updated>2013-04-22T03:50:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-04-22:/2013/04/mitigating-ddos-attacks/</id><summary type="html">&lt;p&gt;Lately, DDoS attacks have been in the news more than I was hoping for.
It seems that the botnets or other methods that are used to generate
high-volume traffic to a legitimate service are becoming more and more
easy to get and direct. At the time that I'm writing this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Lately, DDoS attacks have been in the news more than I was hoping for.
It seems that the botnets or other methods that are used to generate
high-volume traffic to a legitimate service are becoming more and more
easy to get and direct. At the time that I'm writing this post (a few
days before its published though), the popular
&lt;a href="http://www.reddit.com"&gt;Reddit&lt;/a&gt; site is undergoing a DDoS attack which I
hope will be finished (or mitigated) soon.&lt;/p&gt;
&lt;p&gt;But what can a service do against DDoS attacks? After all, DDoS is like
gasping for air if you can't swim and are (almost) drowning: the air is
the legitimate traffic, but the water is overwhelming and your mouth,
pharynx and trachea just aren't made to deal with this properly. And
unlike specific Denial-of-Service attacks that use a vulnerability or
malcrafted URL, you cannot just install some filter or upgrade a
component to be safe again.&lt;/p&gt;
&lt;p&gt;Methods for mitigating DDoS attacks (beyond increasing your bandwidth as
that is very expensive and the botnets involved can go &lt;a href="http://arstechnica.com/security/2013/04/fueled-by-super-botnets-ddos-attacks-grow-meaner-and-ever-more-powerful/"&gt;up to 130
Gbps&lt;/a&gt;,
not a bandwidth you are probably willing to pay for if legitimate
services on your site have enough with 10 Mbps) that come to mind are of
all sorts of "classes"...&lt;/p&gt;
&lt;p&gt;Configure your servers and services that they &lt;strong&gt;stay alive under
pressure&lt;/strong&gt;. Look for the sweet spot where performance of the services is
still stable where a higher load means performance degradation. If you
have some experience with load testing, you know that throughput on a
service initially goes up linearly with the load (first phase). Then, it
slows down (but still rises - phase 2) up to a point that, when you
increase the load even further just a bit, the service degrades (and
sometimes doesn't even get back to its feed when you remove the
additional load again - phase3). You need to look for the spot where
load and performance is stable (somewhere at the middle of the second
phase) and configure your systems so that additional load is dropped.
Yes, this means that the DDoS will be more effective, but also means
that your systems can easily get back up to their feet when the attack
has finished (and you get a more predictable load and consequences).&lt;/p&gt;
&lt;p&gt;Investigate if you can have a &lt;strong&gt;backup service&lt;/strong&gt; that has a higher
throughput ability (with reduced functionality). If the DDoS attack
focuses on the system resources rather than network resources involved,
such a backup "lighter" service can be used to still provide basic
functionality (for instance a more static website), but even in case of
network resource consumption it can have the advantage that the network
consumption that your servers are placing (while replying to the
requests) are lower.&lt;/p&gt;
&lt;p&gt;Depending on the service you offer (and financial means you have at your
disposal) you can look at &lt;strong&gt;redirecting traffic&lt;/strong&gt; to more specialized
services. Companies like &lt;a href="http://www.prolexic.com"&gt;Prolexic&lt;/a&gt; have
systems that "scrub" the DDoS traffic from all traffic and only send
legitimate requests to your systems. There are several methods for
redirecting load, but a common one is to change the DNS records for your
service(s) to point to the addresses of those specialized services
instead. The lower the TTL (Time To Live) is of the records, the faster
the redirect might take place. If you want to be able to handle an
increase in load without specialized services, you might want to be able
to redirect traffic to cloud services (where you host your service as
well) which are generally capable of handling higher throughput than
your own equipment (but this too comes at an additional cost).&lt;/p&gt;
&lt;p&gt;Some people mention that you can &lt;strong&gt;switch IP address&lt;/strong&gt;. This is true
only if the DDoS attack is targeting IP addresses and not (DNS-resolved)
URIs. You could set up additional IP addresses that are not registered
in DNS (yet) and during the attack, extend the service resolving towards
the additional addresses as well. If you do not notice a load spread of
the DDoS attack towards the new addresses, you can remove the old
addresses from DNS. But again, this won't work generally - not only are
most DDoS attacks using DNS-resolved URIs, most of the time attackers
are actively involved in the attack and will quickly notice if such a
"failover" has occurred (and react against it).&lt;/p&gt;
&lt;p&gt;Depending on your relationship with your provider or location service,
you can ask if the edge routers (preferably those of the ISP) can have
&lt;strong&gt;fallback source filtering rules&lt;/strong&gt; available to quickly enable. Those
fallback rules would then only allow traffic from networks that you know
most (all?) of your customers and clients are at. This isn't always
possible, but if you have a service that targets mainly people within
your country, have the filter only allow traffic from networks of that
country. If the DDoS attack uses geographically spread resources, it
might be that the number of bots inside those allowed networks are low
enough that your service can continue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Configure your firewalls&lt;/strong&gt; (and ask that your ISP does the same) to
not accept (drop) traffic not expected. If the services on your
architecture do not use external DNS, then you can drop incoming DNS
response packets (a popular DDoS attack method is by using spoofed
addresses towards open DNS resolvers; called a DNS reflection attack).&lt;/p&gt;
&lt;p&gt;And finally, if you are not bound to a single data center, you might
want to spread services across &lt;strong&gt;multiple locations&lt;/strong&gt;. Although more
difficult from a management point of view, a dispersed/distributed
architecture allows other services to continue running while one is
being attacked.&lt;/p&gt;</content><category term="Security"></category><category term="ddos"></category><category term="dns"></category><category term="mitigation"></category><category term="security"></category></entry><entry><title>What could SELinux have done to mitigate the postgresql vulnerability?</title><link href="https://blog.siphos.be/2013/04/what-could-selinux-have-done-to-mitigate-the-postgresql-vulnerability/" rel="alternate"></link><published>2013-04-16T14:00:00+02:00</published><updated>2013-04-16T14:00:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-04-16:/2013/04/what-could-selinux-have-done-to-mitigate-the-postgresql-vulnerability/</id><summary type="html">&lt;p&gt;&lt;a href="http://www.gentoo.org"&gt;Gentoo&lt;/a&gt; is one of the various distributions
which supports &lt;a href="http://www.gentoo.org/proj/en/hardened/selinux"&gt;SELinux&lt;/a&gt;
as a &lt;em&gt;Mandatory Access Control&lt;/em&gt; system to, amongst other things,
mitigate the results of a succesfull exploit against software. So what
about the recent &lt;a href="http://www.postgresql.org/support/security/faq/2013-04-04/"&gt;PostgreSQL
vulnerability&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;When correctly configured, the PostgreSQL daemon will run in the
&lt;code&gt;postgresql_t&lt;/code&gt; domain. In SELinux-speak …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://www.gentoo.org"&gt;Gentoo&lt;/a&gt; is one of the various distributions
which supports &lt;a href="http://www.gentoo.org/proj/en/hardened/selinux"&gt;SELinux&lt;/a&gt;
as a &lt;em&gt;Mandatory Access Control&lt;/em&gt; system to, amongst other things,
mitigate the results of a succesfull exploit against software. So what
about the recent &lt;a href="http://www.postgresql.org/support/security/faq/2013-04-04/"&gt;PostgreSQL
vulnerability&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;When correctly configured, the PostgreSQL daemon will run in the
&lt;code&gt;postgresql_t&lt;/code&gt; domain. In SELinux-speak, a domain can be seen as a name
granted to a set of permissions (what is allowed) and assigned to one or
more processes. A process that "runs in domain postgresql_t" will be
governed by the policy rules (what is and isn't allowed) for that
domain.&lt;/p&gt;
&lt;p&gt;The vulnerability we speak of is about creating new files or overwriting
existing files, potentially corrupting the database itself (when the
database files are overwritten). Creating new files is handled through
the &lt;em&gt;create&lt;/em&gt; privilege on files (and &lt;em&gt;add_name&lt;/em&gt; on directories),
writing into files is handled through the &lt;em&gt;write&lt;/em&gt; privilege. Given
certain circumstances, one could even &lt;a href="http://blog.blackwinghq.com/2013/04/08/2/"&gt;write commands inside
files&lt;/a&gt; that are executed by
particular users on the system (btw, the link gives a great explanation
on the vulnerability).&lt;/p&gt;
&lt;p&gt;So let's look at what SELinux does and could have done.&lt;/p&gt;
&lt;p&gt;In the current situation, as we explained, &lt;code&gt;postgresql_t&lt;/code&gt; is the only
domain we need to take into account (the PostgreSQL policy does not use
separate domains for the runtime processes). Let's look at what
directory labels it is allowed to write into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sesearch -s postgresql_t -c dir -p add_name -SCATd
Found 11 semantic av rules:
   allow postgresql_t postgresql_log_t : dir { add_name } ; 
   allow postgresql_t var_log_t : dir { add_name } ; 
   allow postgresql_t var_lock_t : dir { add_name } ; 
   allow postgresql_t tmp_t : dir { add_name } ; 
   allow postgresql_t postgresql_tmp_t : dir { add_name } ; 
   allow postgresql_t postgresql_var_run_t : dir { add_name } ; 
   allow postgresql_t postgresql_db_t : dir { add_name } ; 
   allow postgresql_t etc_t : dir { add_name } ; 
   allow postgresql_t tmpfs_t : dir { add_name } ; 
   allow postgresql_t var_lib_t : dir { add_name } ; 
   allow postgresql_t var_run_t : dir { add_name } ;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So the PostgreSQL service is allowed to create files inside directories
labeled with one of the following labels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;postgresql_log_t&lt;/code&gt;, used for PostgreSQL log files
    (&lt;code&gt;/var/log/postgresql&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var_log_t&lt;/code&gt;, used for the generic log files (&lt;code&gt;/var/log&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var_lock_t&lt;/code&gt;, used for lock files (&lt;code&gt;/run/lock&lt;/code&gt; or &lt;code&gt;/var/lock&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tmp_t&lt;/code&gt;, used for the temporary file directory (&lt;code&gt;/tmp&lt;/code&gt; or
    &lt;code&gt;/var/tmp&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;postgresql_tmp_t&lt;/code&gt;, used for the PostgreSQL temporary
    files/directories&lt;/li&gt;
&lt;li&gt;&lt;code&gt;postgresql_var_run_t&lt;/code&gt;, used for the runtime information (like
    PID files) of PostgreSQL (&lt;code&gt;/var/run/postgresql&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;postgresql_db_t&lt;/code&gt;, used for the PostgreSQL database files
    (&lt;code&gt;/var/lib/postgresql&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;etc_t&lt;/code&gt;, used for the generic system configuration files (&lt;code&gt;/etc/&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var_lib_t&lt;/code&gt;, used for the &lt;code&gt;/var/lib&lt;/code&gt; data&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var_run_t&lt;/code&gt;, used for the &lt;code&gt;/var/run&lt;/code&gt; or &lt;code&gt;/run&lt;/code&gt; data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next to this, depending on the label of the directory, the PostgreSQL
service is allowed to write into files with the following label assigned
(of importance to both creating new files as well as overwriting
existing ones):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sesearch -s postgresql_t -c file -p write -SCATd
Found 11 semantic av rules:
   allow postgresql_t postgresql_log_t : file { write } ; 
   allow postgresql_t postgresql_lock_t : file { write } ; 
   allow postgresql_t faillog_t : file { write } ; 
   allow postgresql_t lastlog_t : file { write } ; 
   allow postgresql_t postgresql_tmp_t : file { write } ; 
   allow postgresql_t hugetlbfs_t : file { write } ; 
   allow postgresql_t postgresql_var_run_t : file { write } ; 
   allow postgresql_t postgresql_db_t : file { write } ; 
   allow postgresql_t postgresql_t : file { write } ; 
   allow postgresql_t security_t : file { write } ; 
   allow postgresql_t etc_t : file { write } ;

Found 6 semantic te rules:
   type_transition postgresql_t var_log_t : file postgresql_log_t; 
   type_transition postgresql_t var_lock_t : file postgresql_lock_t; 
   type_transition postgresql_t tmp_t : file postgresql_tmp_t; 
   type_transition postgresql_t tmpfs_t : file postgresql_tmp_t; 
   type_transition postgresql_t var_lib_t : file postgresql_db_t; 
   type_transition postgresql_t var_run_t : file postgresql_var_run_t;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If an exploit creates a new file, the &lt;em&gt;add_name&lt;/em&gt; permission on the
directory is needed. If otoh the exploit is overwriting existing files,
I think the only permission needed here is the &lt;em&gt;write&lt;/em&gt; on the files
(also &lt;em&gt;open&lt;/em&gt; but all the writes have &lt;em&gt;open&lt;/em&gt; as well in the above case).&lt;/p&gt;
&lt;p&gt;Now accessing and being able to write files into the database file
directory is expected - it is the functionality of the server, so unless
we could separate domains more, this is a "hit" we need to take. Sadly
though, this is also the label used for the PostgreSQL service account
home directory here (not sure if this is for all distributions), making
it more realistic that an attacker writes something in the home
directory &lt;code&gt;.profile&lt;/code&gt; file and hopes for the administrator to do
something like &lt;strong&gt;su postgres -&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Next, the &lt;code&gt;etc_t&lt;/code&gt; write privileges also worry me, not mainly because it
can write there, but also because I can hardly understand why -
PostgreSQL is supposed to run under its own, non-root user (luckily) so
unless there are &lt;code&gt;etc_t&lt;/code&gt; labeled directories owned by the PostgreSQL
service account (or world writeable - please no, kthx). And this isn't
an "inherited" permission from something - the policy currently has
&lt;code&gt;files_manage_etc_files(postgresql_t)&lt;/code&gt; set, and has been since 2005 or
earlier. I'm really wondering if this is still needed.&lt;/p&gt;
&lt;p&gt;But I digress. Given that there are no PostgreSQL-owned directories nor
world-writeable ones in &lt;code&gt;/etc&lt;/code&gt;, let's look at a few other ones.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;security_t&lt;/code&gt; is used for the SELinux pseudo file system, and is used
    for the SEPostgreSQL support. From the looks of it, only the root
    Linux user has the rights to do really harmful things on this file
    system (and only if he too has write permissions on &lt;code&gt;security_t&lt;/code&gt;),
    non-root should be limited to verifying if contexts exist or have
    particular rights. Still, I might investigate this further as I'm
    intrigued about many of the pseudo files in &lt;code&gt;/sys/fs/selinux&lt;/code&gt; that
    I'm not fully sure yet what they deal with.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tmp_t&lt;/code&gt; should not be a major concern. Most (if not all) daemons and
    services that use temporary files have file transitions to their own
    type so that access to these files, even if it would be allowed by
    regular permissions, is still prohibited by SELinux&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lastlog_t&lt;/code&gt; is also a weird one, again because it shouldn't be
    writeable for anyone else but root accounts; if succesfull, an
    attacker can overwrite the lastlog information which might be used
    by some as a means for debugging who was logged on when (part
    of forensics).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given the information above, it is a bit sad to see that SELinux can't
protect PostgreSQL users from this particular vulnerability - most of
the "mitigation" (if any) is because the process runs as non-root to
begin with (which is another hint at users not to think SELinux is
sufficient to restrict the permissions of processes). But could it have
been different?&lt;/p&gt;
&lt;p&gt;In my opinion, yes, and I'll see if we can learn from it for the future.&lt;/p&gt;
&lt;p&gt;First of all, we should do more policy code auditing. It might not be
easy to remove policy rules generally, but we should at least try. I use
a small script that enables auditing (SELinux auditing, so &lt;em&gt;auditallow&lt;/em&gt;
statements) for the entire domain, and then selectively disables
auditing until I get no hits anymore. The remainder of &lt;em&gt;auditallow&lt;/em&gt;
statements warrant a closer look to see if they are still needed or not.
I'll get onto that in the next few days.&lt;/p&gt;
&lt;p&gt;Second, we might want to have service accounts use a different home
directory, where they do have the necessary search privileges for, but
no write privileges. Exploits that write stuff into a home directory
(hoping for a &lt;strong&gt;su postgresql -&lt;/strong&gt;) are then mitigated a bit.&lt;/p&gt;
&lt;p&gt;Third, we might want to look into separating the domains according to
the architecture of the service. This requires intimate knowledge of the
ins and outs of PostgreSQL and might even require PostgreSQL patching,
so is not something light. But if no patching is needed (such as when
all process launches are done using known file executions) we could have
a separate domain for the master process, server processes and perhaps
even the various subfunction processes (like the WAL writer, BG writer,
etc.). The Postfix service has such a more diverse (but also complex)
policy. Such a subdomain structure in the policy might reduce the risk
if the vulnerable process (I think this is the master process) does not
need to write to database files (as this is handled by other processes),
so no &lt;code&gt;postgresql_db_t&lt;/code&gt; write privileges.&lt;/p&gt;
&lt;p&gt;If others have ideas on how we can improve service security (for
instance through SELinux policy development) or knows of other exploits
related to this vulnerability that I didn't come across yet, please give
a comment on it below.&lt;/p&gt;</content><category term="Security"></category><category term="postgresql"></category><category term="selinux"></category><category term="vulnerability"></category></entry><entry><title>How far reaching vulnerabilities can go</title><link href="https://blog.siphos.be/2013/04/how-far-reaching-vulnerabilities-can-go/" rel="alternate"></link><published>2013-04-09T19:39:00+02:00</published><updated>2013-04-09T19:39:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2013-04-09:/2013/04/how-far-reaching-vulnerabilities-can-go/</id><summary type="html">&lt;p&gt;If you follow the news a bit, you know that PostgreSQL has had a
significant security vulnerability. The PostgreSQL team announced it up
front and communicated how they would deal with the vulnerability (which
basically comes down to saying that it is severe, that the public
repositories will be temporarily …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you follow the news a bit, you know that PostgreSQL has had a
significant security vulnerability. The PostgreSQL team announced it up
front and communicated how they would deal with the vulnerability (which
basically comes down to saying that it is severe, that the public
repositories will be temporarily frozen as developers add in the
necessary fixes and start building the necessary software for a new
release, and at the release moment give more details about the
vulnerability.&lt;/p&gt;
&lt;p&gt;The exploitability of the vulnerability was quickly identified, and we
know that compromises wouldn't take long. A &lt;a href="http://schemaverse.tumblr.com/post/47312545952/the-schemaverse-was-hacked"&gt;blog
post&lt;/a&gt;
from the schemaverse tells us that exploits won't take long (less than
24 hours) and due to the significance of the vulnerability, it cannot be
stressed enough that patching should really be part of the minimal
security requirements of any security-conscious organization. But
patching alone isn't the only thing to consider.&lt;/p&gt;
&lt;p&gt;The notice that PostgreSQL mentions also that restricting access to the
database through &lt;code&gt;pg_hba.conf&lt;/code&gt; isn't sufficient, as the vulnerable code
is executed before the &lt;code&gt;pg_hba.conf&lt;/code&gt; file is read. So one of the
mitigations for the vulnerability would be a firewall (hostbased or
network) that restricts access to the database so only trusted addresses
are allowed. I'm personally an advocate in favor of hostbased firewalls.&lt;/p&gt;
&lt;p&gt;But the thing that hits me the most, is the amount of applications that
use "embedded" postgresql database services in their product. If you
take part of a larger organization with a large portfolio of software
titles running in the data center, you'll undoubtedly have seen lists
(through network scans or otherwise) of systems that are running
PostgreSQL as part of the product installation (and not as a "managed"
database service). The HP GUIDManager or the NNMI components or the
Systems Insight Manager use embedded PostgreSQL services. The cloudera
manager can be easily set up with an "embedded" PostgreSQL (which
doesn't mean it isn't a full-fledged PostgreSQL, but rather that the
setup and management of the service is handled by the product instead of
by "your own" DBA team). Same with Servoy.&lt;/p&gt;
&lt;p&gt;I don't disagree with all products providing embedded database
platforms, and especially not with choosing for PostgreSQL which I
consider a very mature, stable and feature-rich (and not to be
forgotten, very active community) database platform. But I do hope that
these products take up their responsibility and release updated versions
or patches for their installations to their customers &lt;em&gt;very&lt;/em&gt; soon.&lt;/p&gt;
&lt;p&gt;Perhaps I should ask our security operational team to take a scan to
actively follow-up on these...&lt;/p&gt;</content><category term="Security"></category><category term="firewall"></category><category term="patching"></category><category term="postgresql"></category><category term="security"></category></entry><entry><title>Using stunnel for mutual authentication</title><link href="https://blog.siphos.be/2012/12/using-stunnel-for-mutual-authentication/" rel="alternate"></link><published>2012-12-08T14:24:00+01:00</published><updated>2012-12-08T14:24:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2012-12-08:/2012/12/using-stunnel-for-mutual-authentication/</id><summary type="html">&lt;p&gt;Sometimes services do not support SSL/TLS, or if they do, they do not
support using mutual authentication (i.e. requesting that the client
also provides a certificate which is trusted by the service). If that is
a requirement in your architecture, you can use &lt;strong&gt;stunnel&lt;/strong&gt; to provide
this additional …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sometimes services do not support SSL/TLS, or if they do, they do not
support using mutual authentication (i.e. requesting that the client
also provides a certificate which is trusted by the service). If that is
a requirement in your architecture, you can use &lt;strong&gt;stunnel&lt;/strong&gt; to provide
this additional SSL/TLS layer.&lt;/p&gt;
&lt;p&gt;As an example, I have a mail server running on localhost, and I want to
provide SSMTP services with mutual authentication on top of this
service, using stunnel. First of all, I provide two certificates and
private keys that are both signed by the same CA, and keep the CA
certificate close as well:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;client.key is the private key for the client&lt;/li&gt;
&lt;li&gt;client.pem is the certificate for the client (which contains the
    public key and CA signature)&lt;/li&gt;
&lt;li&gt;server.key and server.pem are the same but for the server&lt;/li&gt;
&lt;li&gt;root-genfic.crt is the certificate of the signing CA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First of all, we setup the stunnel, listening on 1465 (as 465 requires
the stunnel service to run as root, which I'd rather not) and fowarding
towards 127.0.0.1:25:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;cert = /etc/ssl/services/stunnel/server.pem
key = /etc/ssl/services/stunnel/server.key
setuid = stunnel
setgid = stunnel
pid = /var/run/stunnel/stunnel.pid
socket = l:TCP_NODELAY=1
socket = r:TCP_NODELAY=1
verify = 2 # This enables the mutual authentication
CAfile = /etc/ssl/certs/root-genfic.crt

[smtp]
accept = 1465
connect = 127.0.0.1:25
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To test out mutual authentication this way, I used the following
command-line snippet. The delays between the lines are because the mail
client is supposed to wait for the mail server to give its reply and if
not, the data gets lost. I'm sure this can be made easier (with netcat I
could just use "-i 1" to print a line with a one-second delay), but it
works ;-)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$  (sleep 1; echo &amp;quot;EHLO localdomain&amp;quot;; sleep 1; echo &amp;quot;MAIL FROM:remote@test.localdomain&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;sleep 1; echo "RCPT TO:user@localhost"; sleep 1; echo "DATA"; sleep 1; cat TEMPFILE) | &lt;br&gt;
   openssl s_client -connect 192.168.100.102:1465 -crlf -ign_eof -ssl3 -key client.key -cert client.pem&lt;/p&gt;
&lt;p&gt;The TEMPFILE file contains the email content (you know, Subject, From,
To, other headers, data, ...).&lt;/p&gt;
&lt;p&gt;If the provided certificate isn't trusted, then you'll find the
following in the log file (on Gentoo, thats /var/log/daemon.log by
default but you can setup logging in stunnel as well):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Dec  8 13:17:32 testsys stunnel: LOG7[20237:2766895953664]: Starting certificate verification: depth=0, /C=US/ST=California/L=Santa Barbara/O=SSL Server/OU=For Testing Purposes Only/CN=localhost/emailAddress=root@localhost
Dec  8 13:17:32 testsys stunnel: LOG4[20237:2766895953664]: CERT: Verification error: unable to get local issuer certificate
Dec  8 13:17:32 testsys stunnel: LOG4[20237:2766895953664]: Certificate check failed: depth=0, /C=US/ST=California/L=Santa Barbara/O=SSL Server/OU=For Testing Purposes Only/CN=localhost/emailAddress=root@localhost
Dec  8 13:17:32 testsys stunnel: LOG7[20237:2766895953664]: SSL alert (write): fatal: bad certificate
Dec  8 13:17:32 testsys stunnel: LOG3[20237:2766895953664]: SSL_accept: 140890B2: error:140890B2:SSL routines:SSL3_GET_CLIENT_CERTIFICATE:no certificate returned
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When a trusted certificate is shown, the connection goes through.&lt;/p&gt;
&lt;p&gt;Finally, if you not only want to validate if the certificate is trusted,
but also only want to accept a given number of certificates, you can set
the stunnel variable &lt;em&gt;verify&lt;/em&gt; to 3. If you set it to 4, it will not
check the CA and only allow a connection to go through if the presented
certificate is one in the stunnel trusted certificates.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Perimeter security testing</title><link href="https://blog.siphos.be/2012/08/perimeter-security-testing/" rel="alternate"></link><published>2012-08-28T22:47:00+02:00</published><updated>2012-08-28T22:47:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2012-08-28:/2012/08/perimeter-security-testing/</id><summary type="html">&lt;p&gt;I've been asked a few times how I would do perimeter security testing.
Personally, I'm not an offensive security guy, more a defensive one,
meaning I'm more about security-related defensive methods rather than
PEN testing of any kind. But still, even in a defensive position, having
a "view" on how …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been asked a few times how I would do perimeter security testing.
Personally, I'm not an offensive security guy, more a defensive one,
meaning I'm more about security-related defensive methods rather than
PEN testing of any kind. But still, even in a defensive position, having
a "view" on how to do security testing is important. For me, I would use
the following testing categorisation to look at IT architectures and see
how they would react against certain attacks. I'm calling this one about
&lt;em&gt;perimeter&lt;/em&gt; testing as I am interested here in remote attacks (or
differentiation), not local ones (which requires, in my opinion, a
different way of looking at things).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eggs and a basket&lt;/li&gt;
&lt;li&gt;Overhead testing&lt;/li&gt;
&lt;li&gt;Protocol insecurity or misuse&lt;/li&gt;
&lt;li&gt;Application insecurity or misuse&lt;/li&gt;
&lt;li&gt;Client insecurity&lt;/li&gt;
&lt;li&gt;Correlation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Eggs and a basket&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First of all, don't put all your eggs in the same basket. I would never
trust myself enough to say things are secure. Always see if you can't
benefit from other people's knowledge (or even other companies
knowledge). If you are doing testing to choose a specific
security-related technology, use analysis made by independent analysis
firms or organizations to further steer your choice. But make sure that
the organization is truely independent and doesn't give "reports" that
are heavily in favor of whomever asked for them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Overhead testing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most technologies you use to counter certain threats will incur some
overhead. This is true for application firewalls, network firewalls,
isolation technologies, confidentiality technologies, access controls
and more. You should set yourself a baseline of what you consider too
much overhead and what not.&lt;/p&gt;
&lt;p&gt;Overhead comes in many layers, so it is important to be able to perform
load testing based on real loads, not fake lab-specific situations.
Running one thousand clients with the same client certificate, same
hosts, same reaction times against one SSL resource has an entirely
different performance profile than running one thousand clients with
different certificates, using different encryption libraries (other
ciphers and such) and different speeds/reaction times (including things
like SSL handshake timings). And that's just one example.&lt;/p&gt;
&lt;p&gt;I always find it very important to be able to run load testing
regularly. I would even go as far as recommend organizations to run load
testing as a "business as usual" test, or at least allow your
technology-inspired teams to easily request such loads against their new
applications or technologies.&lt;/p&gt;
&lt;p&gt;But enough of that. Let's talk about attack methods (or categorisation).&lt;/p&gt;
&lt;p&gt;I tend to look first towards &lt;em&gt;protocol&lt;/em&gt; insecurity, then &lt;em&gt;application&lt;/em&gt;
insecurity and finally &lt;em&gt;client-level&lt;/em&gt; insecurity. Protocol insecurity is
primarily about knowing how the protocol works (or should work) and
finding ways to attack that. Some protocols are inherently insecure, and
introducing proper protection against these is extremely important as
the technology that implements the protocol might not be able to do that
itself. Then I look at application-specific insecurity, which is more
about knowing the application (vendor/product). And finally it is about
client insecurity (such as browser-based attacks, ActiveX component
attacks, and more).&lt;/p&gt;
&lt;p&gt;In each of these cases, I consider the following attack methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Denial-of-Service - what could be done to disable the protocol or
    service behind it completely or partially&lt;/li&gt;
&lt;li&gt;Out-of-order Execution - can the protocol or application be tricked
    into executing tasks when it isn't meant to, which most of the time
    leads to either information leakage or the next attack method&lt;/li&gt;
&lt;li&gt;Privilege escalation - to get more rights/privileges (or switch from
    unauthenticated to authenticated access)&lt;/li&gt;
&lt;li&gt;Remote command execution - executing whatever the attacker wants on
    the remote system&lt;/li&gt;
&lt;li&gt;Application switching/routing - updating the behavior of the
    application to become a service that can be used to further
    expose/explore the remote servers' environment&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Protocol insecurity or misuse&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Many protocols are inherently insecure. Good security solutions will
need to detect if a protocol is being used in a way that does not match
the behavior expected. And this goes beyond the standard TCP/IP
protocols and the application-level HTTP protocol. Consider SMTP and
VoIP-related protocols as well as a nice example.&lt;/p&gt;
&lt;p&gt;Denial of service attacks against TCP/IP are widely documented. Be it
the well-known SYN flooding, a &lt;a href="http://www-ece.rice.edu/networks/papers/lrdos.pdf"&gt;low-rate tcp-targeted
DoS&lt;/a&gt; or messing with
the TCP stack itself (like with the &lt;a href="http://support.microsoft.com/kb/2563894"&gt;Microsoft Windows TCP/IP Stack
Vulnerabilities&lt;/a&gt;), these
attacks can be easily evaluated against your architecture.&lt;/p&gt;
&lt;p&gt;With TCP/IP, I would generally also look at how the stacks present their
information. Can an attacker use &lt;a href="https://en.wikipedia.org/wiki/TCP_sequence_prediction_attack"&gt;TCP sequence prediction
attacks&lt;/a&gt;?
Can he get information on when is the most feasible period to launch an
attack (for instance from a reasonably stable TCP window size value
reading)? And how about TCP session hijacking?&lt;/p&gt;
&lt;p&gt;Or if we look at HTTP, can attacks such as
&lt;a href="http://ha.ckers.org/slowloris/"&gt;Slowloris&lt;/a&gt; or an &lt;a href="http://www.acunetix.com/blog/web-security-zone/articles/http-post-denial-service/"&gt;HTTP POST
DOS&lt;/a&gt;
attack bring down the service? And what if a user comes to a certain
page after an obscure redirection, where the attacker hopes that the
user authenticates against? Perhaps an attacker might hijack an HTTP
session, or force a user to use a non-secure connection.&lt;/p&gt;
&lt;p&gt;E-mail services too are particularly interesting to look at. Does it
expose information (settings, or account identification)? Does it accept
large time-outs (giving attackers time to just "play" with the service
using netcat/telnet)?&lt;/p&gt;
&lt;p&gt;And in case of VoIP, have you checked common &lt;a href="http://www.slideshare.net/null0x00/voip-vulnerabilities-and-attacks"&gt;voip-based
attacks&lt;/a&gt;
lately? VoIP is (imo) a complex set of protocols and whomever implements
it has to follow strict rules. I would be very surprised if this can't
be heavily influenced.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Application insecurity or misuse&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Of course, protocols are implemented by applications, and applications
have their own set of problems. And if you're running software that
isn't properly configured or up to date, you'll definitely need to take
a good read at my blog posting series on &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-1/"&gt;mitigating
risks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Consider Citrix for instance: a commonly found remote management
toolsuite (well yeah, Citrix offers a lot more, I'm not going to delve
into that right now). It has seen its share of vulnerabilities in the
past, like &lt;a href="http://support.citrix.com/article/CTX121172"&gt;DoS&lt;/a&gt;
vulnerabilities, &lt;a href="http://support.citrix.com/article/CTX133648"&gt;directory traversal or open
proxy&lt;/a&gt;, &lt;a href="http://www.vsecurity.com/resources/advisory/20101221-1/"&gt;command
execution&lt;/a&gt; and
more. And Citrix is far from an insecure platform.&lt;/p&gt;
&lt;p&gt;Just like with all other applications, it is extremely important to have
a good view / knowledge of each product you expose. Some applications
can even mimic other protocols (like
&lt;a href="http://wiki.nginx.org/Modules"&gt;Nginx&lt;/a&gt; handling HTTP, IMAP, POP3, SMTP,
WebDAV, ... which, if exploited by an attacker, can provide a new
fall-out base to work from.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Client insecurity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Finally, the last thing to consider is most likely the one most
difficult to manage: client insecurity. Especially with internet-facing
services, it is very hard to protect yourself from client systems that
are not properly protected. How to deal with user authentication if the
user could have a keystroke logger running in the background? A browser
is a commonly used application for service access, but what about things
like a Citrix client (especially if local drive mapping is enabled)?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Correlation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A good security system is integrated with the various security
technologies in place. An attacked that did discovery or even tried out
a few other attacks before should already alert most of your security
components, possibly even invoking a temporary countermeasure against
the users' location. It is not sufficient to block the IP address on the
webserver when the attacker tried an HTTP-based attack only to have him
try his luck on the next service that you expose...&lt;/p&gt;
&lt;p&gt;Now for each "category" I tend to look at the attack from a "hit and
run" aspect (exploitable with a single attack or burst), "build up"
(most of the slower attacks tend to be like this) or "evaded" (trying to
work around detection of the previous ones), and this for a single host,
a relayed host or distributed. All these factors combined give me enough
things to consider while evaluating an architecture (or security
technology implementation) for remote attacks.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Hardening the Linux kernel updates</title><link href="https://blog.siphos.be/2012/07/hardening-the-linux-kernel-updates/" rel="alternate"></link><published>2012-07-21T21:06:00+02:00</published><updated>2012-07-21T21:06:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2012-07-21:/2012/07/hardening-the-linux-kernel-updates/</id><summary type="html">&lt;p&gt;Thanks to a comment by Andy, the
&lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/kernel.html"&gt;guide&lt;/a&gt;
now has information about additional settings: stackprotector, read-only
data, restrict access to /dev/mem, disable /proc/kcore and restrict
kernel syslog (dmesg). One suggestion he made didn't make it to the
guide (about CONFIG_DEBUG_STACKOVERFLOW) since I can't find any
resources about the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Thanks to a comment by Andy, the
&lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/kernel.html"&gt;guide&lt;/a&gt;
now has information about additional settings: stackprotector, read-only
data, restrict access to /dev/mem, disable /proc/kcore and restrict
kernel syslog (dmesg). One suggestion he made didn't make it to the
guide (about CONFIG_DEBUG_STACKOVERFLOW) since I can't find any
resources about the setting on how it would made the system more secure
or more resilient against attacks.&lt;/p&gt;
&lt;p&gt;Underlyingly, the
&lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/scap-kernel-oval.txt"&gt;OVAL&lt;/a&gt;
now correctly identifies unset variables (it previously searched for "is
not set" strings in the kernel configuration, and now it searches for
the key entry definition and validates if it doesn't find it - e.g.
"CONFIG_PROC_KCORE=" - since that matches both the definition not
being there, or "# CONFIG_PROC_KCORE has not been set").&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Hardening the Linux kernel</title><link href="https://blog.siphos.be/2012/07/hardening-the-linux-kernel/" rel="alternate"></link><published>2012-07-20T22:05:00+02:00</published><updated>2012-07-20T22:05:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2012-07-20:/2012/07/hardening-the-linux-kernel/</id><summary type="html">&lt;p&gt;I have moved out the kernel configuration settings (and &lt;strong&gt;sysctl&lt;/strong&gt;
stuff) from the &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/gentoo.html"&gt;Hardening Gentoo Linux
benchmark&lt;/a&gt;
into its own &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/kernel.html"&gt;Hardening the Linux
kernel&lt;/a&gt;
guide. It covers some common hardening-related kernel configuration
entries (although I'm sure I'm missing a lot of them still) as well as
grSecurity and PaX settings …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have moved out the kernel configuration settings (and &lt;strong&gt;sysctl&lt;/strong&gt;
stuff) from the &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/gentoo.html"&gt;Hardening Gentoo Linux
benchmark&lt;/a&gt;
into its own &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/kernel.html"&gt;Hardening the Linux
kernel&lt;/a&gt;
guide. It covers some common hardening-related kernel configuration
entries (although I'm sure I'm missing a lot of them still) as well as
grSecurity and PaX settings (which is something the &lt;a href="http://hardened.gentoo.org"&gt;Gentoo
Hardened&lt;/a&gt; project works on), and finally the
system controls (sysctl) that are commonly suggested for a more secure
system.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/"&gt;overview of hardening
guides&lt;/a&gt; now
thus contains three guides: one for Gentoo, one for OpenSSH and one for
the kernel. These ones were definitions I already had in the past so
were "quickly" possible to write down. I'm going to look at BIND and
DHCP next.&lt;/p&gt;
&lt;p&gt;But simultaneously, I'm looking at &lt;a href="http://linux-ima.sourceforge.net/"&gt;Linux
IMA/EVM&lt;/a&gt; support in the hope I can
have this supported in Gentoo as well. Looks like a promising
technology, and if I can get it working, it'll definitely deserve its
place within Gentoo Hardened!&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Hardening OpenSSH</title><link href="https://blog.siphos.be/2012/07/hardening-openssh/" rel="alternate"></link><published>2012-07-18T22:20:00+02:00</published><updated>2012-07-18T22:20:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2012-07-18:/2012/07/hardening-openssh/</id><summary type="html">&lt;p&gt;A while ago I wrote about a &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/gentoo.html"&gt;Gentoo Security
Benchmark&lt;/a&gt;
which would talk about hardening a Gentoo Linux installation. Within
that document, I was documenting how to harden specific services as
well. However, I recently changed my mind and wanted to move the
hardening stuff for the services in separate …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A while ago I wrote about a &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/gentoo.html"&gt;Gentoo Security
Benchmark&lt;/a&gt;
which would talk about hardening a Gentoo Linux installation. Within
that document, I was documenting how to harden specific services as
well. However, I recently changed my mind and wanted to move the
hardening stuff for the services in separate documents.&lt;/p&gt;
&lt;p&gt;The first one is now finished - &lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/openssh.html"&gt;Hardening
OpenSSH&lt;/a&gt;
is a benchmark informing you how to potentially harden your SSH
installation further. It uses
&lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/openssh-xccdf.txt"&gt;XCCDF&lt;/a&gt;/&lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/openssh-oval.txt"&gt;OVAL&lt;/a&gt;
so that users of &lt;strong&gt;openscap&lt;/strong&gt; (and other compliant tools) can test their
system automatically, generating nice
&lt;a href="https://dev.gentoo.org/~swift/docs/security_benchmarks/openssh-report.html"&gt;reports&lt;/a&gt;
on the state of their SSH configuration.&lt;/p&gt;
&lt;p&gt;For now, the SSH stuff is also still part of the Gentoo document, but
I'll move that out soon and refer to this new document.&lt;/p&gt;
&lt;p&gt;Hardened Gentoo's purpose is to make Gentoo viable for highly secure,
high stability production server environments. Hence, hardening
documents&lt;br&gt;
should be one of its deliverables as well. So, dear users, do you think
it is wise for the Gentoo Hardened project to also focus on delivering
hardening guides for services? If so, I'm sure we can draft up others...&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Why both chroot and SELinux?</title><link href="https://blog.siphos.be/2012/04/why-both-chroot-and-selinux/" rel="alternate"></link><published>2012-04-15T09:41:00+02:00</published><updated>2012-04-15T09:41:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2012-04-15:/2012/04/why-both-chroot-and-selinux/</id><summary type="html">&lt;p&gt;In my &lt;a href="http://blog.siphos.be/2012/04/chrooted-bind-for-ipv6-with-selinux/"&gt;previous
post&lt;/a&gt;,
a very valid question was raised by Alexander E. Patrakov: why still use
chroot if you have SELinux?&lt;/p&gt;
&lt;p&gt;Both chroot (especially with the additional restrictions that grSecurity
enables on chroots that make it more difficult to break out of a chroot)
and SELinux try to isolate …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In my &lt;a href="http://blog.siphos.be/2012/04/chrooted-bind-for-ipv6-with-selinux/"&gt;previous
post&lt;/a&gt;,
a very valid question was raised by Alexander E. Patrakov: why still use
chroot if you have SELinux?&lt;/p&gt;
&lt;p&gt;Both chroot (especially with the additional restrictions that grSecurity
enables on chroots that make it more difficult to break out of a chroot)
and SELinux try to isolate an application so it only has access to those
resources it needs. Chroot does this on file-level basis (and a bit more
with grSecurity), SELinux on more general resources. However, things
that make SELinux strong (flexible and detailed policy language,
fine-grained authorizations) are also its weakness (consolidating files
into groups having the same file label), and chroot does have an
advantage on this.&lt;/p&gt;
&lt;p&gt;Suppose that a flaw exists in BIND through which an attacker can read
files on the host (through BIND). With SELinux, the domain in which BIND
runs is prohibited from accessing and reading files whose label is not
one of the labels that the policy thinks BIND should be able to read.
More specifically, the BIND policy in the reference policy (which is
what both Gentoo and RedHat base their policies on, and generally
policies are only enlarged, never really shrinked):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;etc_runtime_t (read) means access to the files in /etc that are
    modified at runtime (like mtab, profile.env, gentoo's /etc/env.d)&lt;/li&gt;
&lt;li&gt;named_var_run_t (read) is access to /var/run/bind and
    /var/run/named (and a few other related locations)&lt;/li&gt;
&lt;li&gt;named_checkconf_exec_t (read/execute) is access to read and
    execute /usr/sbin/named-checkconf&lt;/li&gt;
&lt;li&gt;named_conf_t (read) to read the BIND-related configuration files&lt;/li&gt;
&lt;li&gt;dnssec_t (read) to read the DNSSEC keyfiles&lt;/li&gt;
&lt;li&gt;locale_t (read) to access /etc/localtime, /usr/share/locale/*,
    /usr/share/zoneinfo/*&lt;/li&gt;
&lt;li&gt;etc_t (read) to read the general configuration files in /etc
    (including passwd, fstab, ...)&lt;/li&gt;
&lt;li&gt;proc_t (read), proc_net_t (read) and sysfs_t (read) to access
    those pseudo filesystems&lt;/li&gt;
&lt;li&gt;udev_tbl_t (read) to access /dev/.udev and /var/run/udev (but I
    have no idea yet why this is in)&lt;/li&gt;
&lt;li&gt;named_log_t (read/write) for the log files of BIND&lt;/li&gt;
&lt;li&gt;net_conf_t (read) to access /etc/hosts (including deny/allow),
    resolv.conf, ...&lt;/li&gt;
&lt;li&gt;named_exec_t (read/execute) the BIND executables&lt;/li&gt;
&lt;li&gt;named_zone_t (read) to access the zone files, also write access in
    case of slave system&lt;/li&gt;
&lt;li&gt;cert_t (read) to read certificate information&lt;/li&gt;
&lt;li&gt;named_cache_t (read/write) to access its cache&lt;/li&gt;
&lt;li&gt;named_tmp_t (read/write) to work with temporary files&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Isolation provided by SELinux is as powerful as the width of its
labeling. For instance, by giving the named daemon read access to /etc
files like passwd, fstab, group, hosts, resolv.conf and more, a
malicious user who can exploit this hypothetical vulnerability can
obtain information that might help him in his further attempts. By
chrooting BIND, the files placed in the chroot itself should not offer
the information he might be looking for (for instance, the passwd file,
if needed at all, is limited to just the named and root accounts, etc.)&lt;/p&gt;
&lt;p&gt;Chrooting, but not enabling SELinux, could lead to escalation. A chroot
cannot restrict what a process is allowed to do beyond the regular
access privileges that are given on the user. If a user can upload an
exploit through BIND and have BIND execute it, he can use this as an
attack vector for further activities. SELinux here prohibits BIND to
write stuff it can also execute (there is no write and execute privilege
defined here). It also ensures that the BIND daemon never exists his
security domain (transitioning towards another domain with perhaps other
privileges) as there are no transition rules from named_t to any other
domain.&lt;/p&gt;
&lt;p&gt;Another MAC system that would be better suited to fit both is
grSecurity's RBAC model. Iirc, it uses path definitions to say which
files are allowed to access and which not. The weakness SELinux here has
(aggregation into sets of files with the same label) doesn't exist for
grSecurity. This debate on path-based versus label-based access controls
have been going on for very long time now - just google it ;-)&lt;/p&gt;
&lt;p&gt;So, Alexander, in short: chroot further limits the SELinux-allowed
privileges to a more fine-grained set of file system resources
(files/directories).&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Mitigating risks, part 5 - application firewalls</title><link href="https://blog.siphos.be/2011/10/mitigating-risks-part-5-application-firewalls/" rel="alternate"></link><published>2011-10-05T23:38:00+02:00</published><updated>2011-10-05T23:38:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-10-05:/2011/10/mitigating-risks-part-5-application-firewalls/</id><summary type="html">&lt;p&gt;The last &lt;em&gt;isolation-related&lt;/em&gt; aspect on risk mitigation is called
&lt;strong&gt;application firewalls&lt;/strong&gt;. Like more "regular" firewalls, its purpose is
to be put in front of a service, controlling which data/connections get
through and which don't. But unlike these regular firewalls,
&lt;a href="https://en.wikipedia.org/wiki/Application_firewall"&gt;application
firewalls&lt;/a&gt; work on
higher-level protocols (like HTTP, FTP) that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The last &lt;em&gt;isolation-related&lt;/em&gt; aspect on risk mitigation is called
&lt;strong&gt;application firewalls&lt;/strong&gt;. Like more "regular" firewalls, its purpose is
to be put in front of a service, controlling which data/connections get
through and which don't. But unlike these regular firewalls,
&lt;a href="https://en.wikipedia.org/wiki/Application_firewall"&gt;application
firewalls&lt;/a&gt; work on
higher-level protocols (like HTTP, FTP) that deal with user data rather
than with connection routing. I'm going to call these firewalls "network
firewalls", although most modern network firewalls have some application
firewall functionality as well.&lt;/p&gt;
&lt;p&gt;The purpose and necessity of network firewalls is well known and
understood: make sure that the service is only accessible from the right
location, check if connections aren't abused (or too many connections
are made), etc. But what if the connection itself is valid? After all,
most abuse of services is not because they originate from the wrong
location or try to access the wrong service. Instead, such abuse comes
from valid access to the application, but with less kosher intentions.
So what can application firewalls do in this case?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Because they perform inspection of the data that is transferred
    itself, application firewalls can &lt;strong&gt;detect malicious data
    fragments&lt;/strong&gt; or attempts to abuse the service. These detection rules
    can be based on general, heuristic rules (well-known examples are
    detection rules for cross-site scripting attacks (XSS) or
    SQL Injection) but can also be very specific to a
    particular application.&lt;/li&gt;
&lt;li&gt;Because all data is transferred through the firewall and the
    firewall has knowledge of the application itself, these firewalls
    offer &lt;strong&gt;advanced auditing features&lt;/strong&gt; since they can detect
    authentication steps, user data, application-specific transactions
    and more.&lt;/li&gt;
&lt;li&gt;With knowledge of the users' session and
    behavior (application-level) and origin (network level), application
    firewalls can &lt;strong&gt;detect and prevent unauthorized sessions&lt;/strong&gt;, such as
    the case with session hijacking or even man-in-the-middle attacks
    (based on behavior detection)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Implementing an application firewall however doesn't only mean that you
improve access controls on it. It has other advantages that make
application firewalls an important part in many architectures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If all service access is forced through the application firewall
    (for instance through an IP filter on the service that only allows
    connections from the application firewalls) you can implement rules
    that &lt;strong&gt;deter known attacks/vulnerabilities&lt;/strong&gt; without needing to fix
    the code itself (or if fixing is possible, lower the time pressure).
    For instance, for Apache-based services, such an application
    firewall could detect or even change the &lt;code&gt;Range:&lt;/code&gt; header on
    malicious requests to lower the impact of this potentially nasty DoS
    vulnerability&lt;/li&gt;
&lt;li&gt;Depending on the complexity, some &lt;strong&gt;functional application bug
    fixing&lt;/strong&gt; might even be possible. For instance changing content types
    on requests/replies (HTTP), adding a domain on an FTP accounts'
    login statement, ...&lt;/li&gt;
&lt;li&gt;Many application firewalls (or gateways) offer proxy functionality
    which might &lt;strong&gt;improve response times&lt;/strong&gt;. This is not a sure-given,
    since most applications are session-aware so the advantage is only
    for session-agnostic requests (be it static content or specific SQL
    statements in case of a database firewall). But also in case of
    session-aware statements can an improvement be found. Consider a
    database firewall which translates SQL statements from an
    unsupported application towards better defined statements (for
    instance using proper indexes or materialized views).&lt;/li&gt;
&lt;li&gt;In some cases, you might even be able to upgrade a backend of an
    unsupported application (which previously required an outdated
    version of that database) by translating the backend requests when
    they are incompatible with the new backend version. So you can
    &lt;strong&gt;improve integration&lt;/strong&gt; or &lt;strong&gt;support unsupported upgrades&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;In case of risk reduction, application firewalls also allow you to
    move a service elsewhere (even in the &lt;strong&gt;public cloud&lt;/strong&gt;) and still
    keep the access under control.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, it would be TGTBT (Too Good To Be True) if there isn't an
(important) downside: &lt;em&gt;maintaining the application firewall is a
daunting task&lt;/em&gt;. Because of its flexibility, you'll need deep knowledge
in the application firewall administration and development, keep track
of all rules you have (and why you have them), do lots and lots of
testing on each rule (since it might affect the functioning of the
application) and still be aware that subtle differences introduced by
the application firewall rules can pop up unexpectedly. Also,
integrating an application firewall is another service between your
customer and his service, which might influence performance but also
makes the underlying architecture more complex. Finally, you'll need to
consider that an application firewall requires lots of resources
(CPU/memory), especially when it needs to perform SSL/TLS termination.
Oh, and they're often expensive too.&lt;/p&gt;
&lt;p&gt;Still, even with these downsides, application firewalls are an important
part of the service isolation strategy, which is a key aspect in the
&lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-1/"&gt;risk mitigation
strategy&lt;/a&gt; which
this series started with. We've focused on three now: &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-2-service-isolation/"&gt;service
isolation&lt;/a&gt;
(network-wise), process isolation (through &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-4-mandatory-access-control/"&gt;mandatory access
control&lt;/a&gt;)
and now access isolation through application firewalls. And with proper
&lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-3-hardening/"&gt;hardening&lt;/a&gt;
in place, I believe that you have done all you can do to reduce the
risks when running unsupported software (apart from upgrading it or
switching towards supported software).&lt;/p&gt;
&lt;p&gt;If you have other ideas that benefit risk mitigation, with specific
focus on unsupported software, I would be glad to hear about them.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Mitigating risks, part 4 - Mandatory Access Control</title><link href="https://blog.siphos.be/2011/09/mitigating-risks-part-4-mandatory-access-control/" rel="alternate"></link><published>2011-09-23T20:16:00+02:00</published><updated>2011-09-23T20:16:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-09-23:/2011/09/mitigating-risks-part-4-mandatory-access-control/</id><summary type="html">&lt;p&gt;I've talked about &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-2-service-isolation/"&gt;service
isolation&lt;/a&gt;
earlier and the risks that it helps to mitigate. However, many
applications still run as highly privileged accounts, or can be abused
to execute more functions than intended. Service isolation doesn't help
there, and system hardening can only go that far. The additional
countermeasures that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've talked about &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-2-service-isolation/"&gt;service
isolation&lt;/a&gt;
earlier and the risks that it helps to mitigate. However, many
applications still run as highly privileged accounts, or can be abused
to execute more functions than intended. Service isolation doesn't help
there, and system hardening can only go that far. The additional
countermeasures that you can take are application firewalls and
mandatory access control. And now you know what part 5 will talk about
;-)&lt;/p&gt;
&lt;p&gt;Standard access control on most popular operating systems is based on a
limited set of privileges (such as read, write and execute) on a limited
scale (user, group, everyone else). Recent developments are showing an
increase in the privilege flexibility, with the advent of &lt;a href="http://www.gentoo.org/proj/en/hardened/capabilities.xml"&gt;manageable
capabilities&lt;/a&gt;
(Linux/Unix) or &lt;a href="http://technet.microsoft.com/en-us/windowsserver/bb310732"&gt;Group
Policies&lt;/a&gt;
(Windows). However, these still lack some important features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users are still able to &lt;strong&gt;delegate their privilege&lt;/strong&gt; to others. A
    user with read access on a particular file can copy that file to a
    public readable location so others can read it as well. Privileges
    on his own files and directories are fully manageable by the owner.
    For our risk mitigation approach on unsupported software, that means
    that a vulnerability might be exploited so that the service
    "leaks" information. It is especially important in an attack that
    uses a sequence of vulnerabilities (such as in an &lt;a href="https://secure.wikimedia.org/wikipedia/en/wiki/Advanced_persistent_threat"&gt;advanced
    persistent
    threat&lt;/a&gt;)
    where low-risk vulnerabilities can be combined into a
    high-risk exploit.&lt;/li&gt;
&lt;li&gt;Privileges are still &lt;strong&gt;user-level privileges&lt;/strong&gt; (including technical
    account users). In case of running services, this almost always
    means that the process has more privileges than it requires. Some
    software titles allow for dropping capabilities when not
    needed anymore. Most however are oblivious of the rights
    they possess. Abuse of the service (which includes use of features
    that the service offers but are not allowed policy-wise by
    the organization) cannot be prevented if
    &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-3-hardening/"&gt;hardening&lt;/a&gt;
    doesn't disable it.&lt;/li&gt;
&lt;li&gt;Privileges are &lt;strong&gt;managed by many actors&lt;/strong&gt; (such as the
    system administrators) and are not that easy to audit. Privilege
    denials are often not audited, causing issues to only come up when
    they occur, rather then when the attempt to provoke issues
    is started. In many cases, a malicious (or "playful, inventive")
    user starts with investigating and trying out long before a way is
    found to abuse the service.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In case of a mandatory access control system, a security administrator
is responsible for writing and managing a security policy which is
&lt;strong&gt;enforced by the operating system&lt;/strong&gt; (well, higher level enforcement
would be even better, but is currently not realistic). Once enforced,
the policy ensures that privileges are not delegated (unless allowed).
Also, in most MAC systems, the policy allows for a much &lt;strong&gt;more detailed
privilege granularity&lt;/strong&gt;. And recent server operating systems have
support for MAC - I personally work with
&lt;a href="http://hardened.gentoo.org/selinux"&gt;SELinux&lt;/a&gt; for the (GNU/)Linux
operating system.&lt;/p&gt;
&lt;p&gt;But this more granular flexibility in privileges comes with some costs.
First of all, it becomes much more &lt;strong&gt;complex to manage the policy&lt;/strong&gt;.
You'll need highly experienced administrators to work with a MAC-enabled
system. Second, a MAC model has a &lt;strong&gt;negative influence on performance&lt;/strong&gt;
since the system has to check many more accesses and access rules. To
make MAC-enabled systems workable, operating systems offer a &lt;em&gt;default
policy&lt;/em&gt; which already covers many services. Also, developers on the MAC
technology are continuously safe-guarding performance - I personally do
not notice a performance degradation when using SELinux, and more
realistic benchmarks suggest that the impact of SELinux is between 3%
and 12% depending on the policy level.&lt;/p&gt;
&lt;p&gt;But what does that mean towards the initial &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-1"&gt;risk
list&lt;/a&gt; that I
identified in the beginning of this article series? Well, directly, very
little: mandatory access control in this case is about reducing the
impact of security vulnerabilities (and abuse of the service). It will
not help you out in other ways. However, there are other things to gain
from a mandatory access control than just threat reduction.&lt;/p&gt;
&lt;p&gt;An advantage is - again - that you get to &lt;strong&gt;know your application&lt;/strong&gt;
well, especially if you had to write a security policy for it. Since you
need to define what files it can access, which kind of accesses it is
allowed to do, which commands it can execute, etc, it will give you
insight in how the application operates. Bugs in the application might
be solved faster and you'll definitely learn more about how the
application is integrated. Another one is that most mandatory access
control systems have much more &lt;strong&gt;detailed auditing&lt;/strong&gt; capabilities.
Attempts to abuse the service will result in denials which are detected
and on which you can then take proper action.&lt;/p&gt;
&lt;p&gt;Taking a higher-level look at mandatory access control will show you
that, in case of risk mitigation, it is much more like service
isolation, but then on the operating system level. You isolate the
processes, governing the accesses they are allowed to do.&lt;/p&gt;
&lt;p&gt;But the one main issue - active exploits on the application service -
cannot be hindered by neither service isolation (since the service is
still accessible), hardening (although it might help) or mandatory
access control (which reduces the actions an exploit can do). To make
sure that vulnerabilities are less likely to be exploited, I'll talk
about &lt;em&gt;application firewalls&lt;/em&gt; in the next post.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Mitigating risks, part 3 - hardening</title><link href="https://blog.siphos.be/2011/09/mitigating-risks-part-3-hardening/" rel="alternate"></link><published>2011-09-13T22:46:00+02:00</published><updated>2011-09-13T22:46:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-09-13:/2011/09/mitigating-risks-part-3-hardening/</id><summary type="html">&lt;p&gt;While I'm writing this post, my neighbor is shouting. He's shouting so
hard, that I was almost writing with CAPS on to make sure you could read
me. But don't worry, he's not fighting - it is how he expresses his
(positive) feelings about his religion.&lt;/p&gt;
&lt;p&gt;Security is, for some, also …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While I'm writing this post, my neighbor is shouting. He's shouting so
hard, that I was almost writing with CAPS on to make sure you could read
me. But don't worry, he's not fighting - it is how he expresses his
(positive) feelings about his religion.&lt;/p&gt;
&lt;p&gt;Security is, for some, also a religion. They see risks and
vulnerabilities and what not everywhere. They're always thinking every
system in the world is or will be hacked in the near future and are
frantically trying to secure every service they are running - and more.
But security is also a real-life issue. If you take a look at the
compromised
&lt;a href="http://www.globalsign.com/company/press/090611-security-response.html"&gt;GlobalSign&lt;/a&gt;
website (who mentions that the website is an isolated one - as &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-2-service-isolation/"&gt;I
described
earlier&lt;/a&gt;)
I hope that you look at security as being a &lt;em&gt;functional&lt;/em&gt; requirement in
architecturing and design (and not a non-functional one as many
frameworks suggest).&lt;/p&gt;
&lt;p&gt;And as you can see from the example, isolating services is not
sufficient to prevent a successful exploit of an insecure or unsupported
software (the reason why I started with this series). One additional
measure that you can take is &lt;strong&gt;hardening&lt;/strong&gt; the server and service.&lt;/p&gt;
&lt;p&gt;The act of hardening a server and service is to configure the system so
that it is as secure as possible, based on configuration entries. Many
vendors and projects offer a security guide (like the &lt;a href="http://www.gentoo.org/doc/en/security/security-handbook.xml"&gt;Gentoo Security
Handbook&lt;/a&gt;
or the &lt;a href="https://docs.fedoraproject.org/en-US/Fedora/16/html/Security_Guide/"&gt;Fedora Security
Guide&lt;/a&gt;)
although most of them add this as part of their standard administrative
documents (like the &lt;a href="http://www.postgresql.org/docs/current/static/runtime.html"&gt;PostgreSQL "Server Setup and
Operation"&lt;/a&gt;
chapter).&lt;/p&gt;
&lt;p&gt;But for some reason, you'll find that default installations - even when
following the instructions of the vendor - are not as secure as you want
it to be. As a matter of fact, if you come in contact with auditors,
you'll probably fail any audit if you use a default installation. To
help administrators to secure their services, you will find lots of
third party sites offering advice on securing the operating system and
the services running on it. These guides are what you will need to
"harden" your system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.owasp.org/index.php/Main_Page"&gt;OWASP&lt;/a&gt;, which stands for
    Open Web Application Security Project,
    &lt;a href="https://www.owasp.org/index.php/OWASP_Backend_Security_Project"&gt;hosts&lt;/a&gt;
    some hardening guides and suggestions together with test scenarios.
    For front-end application servers (mostly web application servers)
    you will find lots of interesting resources in the OWASP site (and
    surrounding community).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.google.com"&gt;Google&lt;/a&gt; is probably the best resource for
    finding hardening guides for your operating system or service. Just
    look for "hardening foo" and you will be reading for a week.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cisecurity.org/"&gt;CISecurity&lt;/a&gt;, or "Center for Internet
    Security", is another one with a larger portfolio on
    hardening guides. Not only does it offer these guides (which it
    calls "benchmarks"), but organizations can also become a member and
    as such benefit from tooling that CISecurity supports for the
    validation of benchmarks (i.e. test if the system/deployment is
    compliant towards a particular benchmark). It does that by
    developing the benchmarks in a open specification called &lt;strong&gt;OVAL&lt;/strong&gt;
    (the &lt;em&gt;Open Vulnerability and Assessment Language&lt;/em&gt;) and &lt;strong&gt;XCCDF&lt;/strong&gt;
    (&lt;em&gt;XML Configuration Checklist Data Format&lt;/em&gt;). And CISecurity is not
    the only one there.&lt;/li&gt;
&lt;li&gt;Another such resource is the &lt;a href="http://web.nvd.nist.gov/view/ncp/repository"&gt;National Vulnerability
    Database&lt;/a&gt; (national for
    US residents, that is ;-) There you can find and download the
    OVAL/XCCDF resources for various software titles and
    operating systems. But as you can imagine from the abbreviations,
    the resources are XML files which are not made to be read by humans.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although you can use the tool(s) that CISecurity offers, another
possibility is to use
&lt;a href="http://www.open-scap.org/page/Main_Page"&gt;Open-SCAP&lt;/a&gt;, an open source
framework for handling SCAP, OVAL, XCCDF and other such open
specifications on a system. Its
&lt;a href="http://www.open-scap.org/page/Documentation"&gt;documentation&lt;/a&gt; offers a
first glance at what it can support.&lt;/p&gt;
&lt;p&gt;However, this brings on he disadvantages of hardening services...&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hardening a system and its services is a &lt;em&gt;time consuming&lt;/em&gt; job. Its
    only purpose is to reduce the impact of exploited vulnerabilities
    and reduce the "attack surface" so that exploits on unused functions
    are not possible.&lt;/li&gt;
&lt;li&gt;Hardening a system and its services &lt;em&gt;can impact the service&lt;/em&gt;. Make
    it too tight, and it might not behave anymore like you want it to.&lt;/li&gt;
&lt;li&gt;Also, since there are many, many resources "out there" on hardening,
    you will have to &lt;em&gt;manage your hardening rules&lt;/em&gt;, document them
    for yourself. It is also advisable to document the rules you are not
    implementing, if not just for future's sake.&lt;/li&gt;
&lt;li&gt;The hardening guides also require quite some &lt;em&gt;expertise on the
    service&lt;/em&gt;. If you are not experienced with the service but you need
    to harden it, you can be lucky and just implement what is suggested
    and hope for the best, but usually you will need to dive deeper in
    the subject and make (tough) choices.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although specifications like SCAP exist to help you in your hardening
exercises, these are still difficult to manage (do &lt;em&gt;not&lt;/em&gt; try to write
OVAL/SCAP/XCCDF content in your favorite text editor). Its adoption
however by Fedora and RedHat is showing a positive effect on the tools
surrounding this specification. I will be writing about SCAP, OVAL and
XCCDF later since I too see good use of it in organizations (or even
free software projects).&lt;/p&gt;
&lt;p&gt;Does that mean that hardening is not beneficial? On the contrary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You &lt;strong&gt;gain lots of knowledge&lt;/strong&gt; in the matter, and also forces you to
    think about integration aspects. Since you are responsible for the
    service (or the damage that could be made if the service
    is exploited) being knowledgeable is definitely a good thing.&lt;/li&gt;
&lt;li&gt;A considerable amount of vulnerabilities that are and will be
    reported on the service (check &lt;a href="http://www.cvedetails.com"&gt;CVE
    details&lt;/a&gt; to find out about publicly known
    vulnerabilities, documented in the CVE specification) will not have
    their effect on a well hardened service. Or put another way, you
    will &lt;strong&gt;reduce the number of real vulnerabilities&lt;/strong&gt; in your service.
    You will not be able to exclude all vulnerabilities, but the
    projected number is high - a fully hardened Windows or Linux system
    can mitigate up to 90% of the exploits on the operating system. It
    will considerably reduce the risks that you and your organization
    are taking.&lt;/li&gt;
&lt;li&gt;A well defined hardening guide will also offer the means to
    &lt;strong&gt;automatically audit&lt;/strong&gt; or check if the &lt;strong&gt;system is still
    compliant&lt;/strong&gt; to the hardening setup you envisioned. Scheduled
    regularly, this will ensure that your configurations are not
    drifting away, back to a more vulnerable setup, for whatever reason.&lt;/li&gt;
&lt;li&gt;By removing the functions that the service should not offer, you
    make sure that the use of the service is per the
    organizations' guidelines. (Internal) abuse of the service is made
    more difficult, so users are forced to take the regular way. Unlike
    service isolation, which allows you to keep track of data/service
    flows, hardening makes sure that &lt;strong&gt;side-functionality is not used&lt;/strong&gt;
    without your consent. Or to put it more blunt, "Yes I know Oracle DB
    can be used to schedule tasks on the operating system, but no,
    you're not allowed to use that function".&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And who knows, perhaps by optimizing the configuration, it might run
faster with a lower resource footprint ;-) If it does, that's perfect,
since the next topic on risk mitigation will have a negative influence
on performance: mandatory access control.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Mitigating risks, part 2 - service isolation</title><link href="https://blog.siphos.be/2011/09/mitigating-risks-part-2-service-isolation/" rel="alternate"></link><published>2011-09-09T23:12:00+02:00</published><updated>2011-09-09T23:12:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-09-09:/2011/09/mitigating-risks-part-2-service-isolation/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Internet: absolute communication, absolute isolation&lt;br&gt;
 \~Paul Carvel&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The quote might be ripped out of its context completely, since it wasn't
made when talking about risks and the assurance you might need to get in
order to reduce risks. But it does give a nice introduction to the
second part of …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Internet: absolute communication, absolute isolation&lt;br&gt;
 \~Paul Carvel&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The quote might be ripped out of its context completely, since it wasn't
made when talking about risks and the assurance you might need to get in
order to reduce risks. But it does give a nice introduction to the
second part of this article series on &lt;em&gt;risk mitigation&lt;/em&gt;. After all, if
the unsupported software is offering services to the Internet, you
really want to govern the communication and isolate the service.&lt;/p&gt;
&lt;p&gt;When you are dealing with a product or software that is unsupported (be
it that it will not get any patches and updates from its authors or
vendor, or there is no time/budget to support the environment properly),
it is in my opinion wise to isolate the service from the rest. My &lt;a href="http://blog.siphos.be/2011/09/mitigating-risks-part-1/"&gt;first
post&lt;/a&gt; on the
matter gave a high-level introduction on the risks that you might be
taking when you run unsupported (or out-of-support) systems. Service
isolation helps in reducing the risks that &lt;em&gt;others&lt;/em&gt; have when you run
such software on a shared infrastructure (like in the same network or
even data centre).&lt;/p&gt;
&lt;p&gt;By isolating the unsupported service from the rest, you create a sort-of
quarantine environment where sudden mishaps are shielded from
interfering with other systems. It provides &lt;strong&gt;insurance for others&lt;/strong&gt;,
knowing that their (supported) services cannot be influenced or
jeopardized by issues with the unsupported ones. And if these services
need to interact with the isolated service, the interface used is known
and much more manageable (think about a well-defined TCP connection
versus local communication or even Inter-Process Communication). But it
goes beyond just providing insurance for others.&lt;/p&gt;
&lt;p&gt;Isolation forces you to &lt;strong&gt;learn about the application&lt;/strong&gt; and its
interaction with other services. It is this phase that makes it
extremely important in an environment, because not knowing how an
application works, behaves or interacts creates more problems later when
you need to debug issues, troubleshoot performance problems and more.
Integration failures, as described in my previous post, can only be
dealt with swiftly if you know how the service integrates with others.&lt;/p&gt;
&lt;p&gt;Another advantage of proper service isolation is that you can fix its
dependencies more easily. Remember that I talked about upgrade
difficulties, where a necessary upgrade for one component impacted the
functionalities of the other (unsupported) component? With good
isolation, the &lt;strong&gt;dependencies are more manageable&lt;/strong&gt; and controllable.
Not only are (sub)component upgrades easier to schedule, it is also a
lot easier to provide fall-back scenario's in case problems occur. After
all, the isolated service is the only user so you have little to fear if
you need to roll-back a change.&lt;/p&gt;
&lt;p&gt;But what is proper service isolation?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First of all, it means that you focus on running the (unsupported)
    software alone on an operating system instance. &lt;em&gt;Do not run other
    services on the same OS&lt;/em&gt;, not even if they too are unsupported. The
    only exception here is if the other services are tightly integrated
    with your service and cannot be installed on a separate OS. But
    usually, full service isolation is possible.&lt;/li&gt;
&lt;li&gt;Next, &lt;em&gt;strip the operating system&lt;/em&gt; so it only runs what you need for
    managing the service. Put primary focus on services that are
    accepting incoming connections ("listening") and secondary focus on
    allowed outgoing protocols/sessions (and the tools that
    initiate them).&lt;/li&gt;
&lt;li&gt;See if you can &lt;em&gt;virtualize the environment&lt;/em&gt;. In most cases, the
    service does not require many resources so it would be a waste
    running it on a dedicated system. However, in my opinion, a much
    better reason for virtualization is hardware abstraction. Sure, all
    operating systems tell you that they have some sort of Hardware
    Abstraction Layer in them and that they can deal with hardware
    changes without you noticing it. But if you are an administrator,
    you know this is only partially true. Virtualization offers the
    advantage that the underlying hardware is virtual and can remain the
    same, even if you move the virtualized system to a much more
    powerful host. Another advantage is that you might be able to
    offload certain necessary services from the OS (like backup) to the
    host (snapshotting).&lt;/li&gt;
&lt;li&gt;Shield the operating system, network-wise, from other systems. Yes,
    that means putting &lt;em&gt;a firewall BEFORE the operating system guest&lt;/em&gt;
    (and definitely not on the OS) which governs all traffic coming in
    and out of the environment. Only allow connections that are legit.
    If your organization has a huge network to manage, they might work
    with network segment filtering instead of IP-level filtering. See if
    you can get an exception to that - managing the rules should not
    give too much overhead since the system, being unsupported and all,
    is a lot less likely to get many connectivity updates.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But before finishing off, a hint about stripping an operating system.
Stripping is much more than just removing services that are not used. It
also means that you look for services that are needed, and see if you
can externalize them. Common examples here are logging (send your logs
to a remote system rather than keeping them local), e-mail (use simple
"direct-out" mail) and backup (use a locally scheduled backup tool, or
even offload to the host in virtualized systems), but many others exist.&lt;/p&gt;
&lt;p&gt;Of course, service isolation is not unknown to most people. If you run a
large(r) network with Internet-facing services, you probably isolate
those in a DMZ environment. That is quite frankly (also) for the same
"risk mitigation" reason. In case of a security breach, service
unavailability or otherwise, you want to reduce the risk that this fault
spreads to other systems (be it getting to internal documents or putting
more services down).&lt;/p&gt;
&lt;p&gt;Another aspect administrators do with systems in their DMZ is &lt;em&gt;system
hardening&lt;/em&gt;, which I will talk about in the third part.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Mitigating risks, part 1</title><link href="https://blog.siphos.be/2011/09/mitigating-risks-part-1/" rel="alternate"></link><published>2011-09-05T22:05:00+02:00</published><updated>2011-09-05T22:05:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-09-05:/2011/09/mitigating-risks-part-1/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We are running Foobar 2.0 on Tomcat 4. We know that Tomcat 4 isn't
supported, but hey - our (internal) customer is happy that the Foobar
application works and would like to keep it that way. Upgrading to
Tomcat 5 or higher is not possible - Foobar 2.0 only works …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;We are running Foobar 2.0 on Tomcat 4. We know that Tomcat 4 isn't
supported, but hey - our (internal) customer is happy that the Foobar
application works and would like to keep it that way. Upgrading to
Tomcat 5 or higher is not possible - Foobar 2.0 only works on Tomcat
4. If we want to use a higher Tomcat version, we need to upgrade the
application which costs a lot of money (which our (internal) customer
doesn't want to pay) and requires lots of testing as it is a
non-trivial upgrade. So... what can an IT department do to mitigate
the risks here?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is not a hypothetical example (well, apart from the software titles
used) for many organizations. Be it the application itself, its
middleware, back-end or operating system: often you'll face an
end-of-support deadline without the means to upgrade the application
(because of budgetary issues, unwillingness of the responsible
department or no alternative). Whatever the reason, you as an IT
department have the responsibility to mitigate the risks involved with
running out-of-support software (and communicate risks to all parties
that are affected by it). So what are your options?&lt;/p&gt;
&lt;p&gt;In this series of posts, I'll cover a set of risk mitigation strategies
that might help you reduce the issues that come up from running
out-of-support software. But first, what are those risks?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Security patches&lt;/strong&gt;. It is the first risk that the operations
    department will say when they have to deal with
    unsupported software. Well, the risk isn't the security patches, but
    the result made by the lack of it. Software tends to have bugs. Some
    of these bugs can result in inappropriate functionality, such as
    granting access to unauthorized people or even executing (unwanted)
    commands on the server. Sounds improbable? &lt;a href="http://cvedetails.com/cve/CVE-2011-3190/"&gt;Guess
    again&lt;/a&gt;. Especially when
    running out-of-support software this becomes a nightmare to manage,
    because security patches are not created anymore, and newly
    discovered vulnerabilities might still affect older versions - even
    when the vulnerabilities do not mention the older versions anymore.
    And the worst thing is that you &lt;em&gt;might not even detect it&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Functional bugs&lt;/strong&gt;. If your customer tries something out and the
    application barfs, then there is little you can do to fix this.
    Either you dive in the code yourself (good luck with that) or you
    hope that a workaround exists. Getting a functional bug fix is not
    that feasible. Also, do not think that functional bugs will not pop
    up anymore "because the application has been running fine
    for years". A change on the system (update of the java runtime,
    kernel upgrade, update on a particular library) might be enough to
    trigger it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-functional bugs&lt;/strong&gt;. The application starts dragging down? You
    notice inflated response times? Can the application only deal with
    10 concurrent users, but your customer just hired 2 additional
    employees? Too bad. You might be able to work around this by
    duplicating the application and putting a load balancer in front of
    it, but with stateful applications that isn't always that easy to&lt;br&gt;
    accomplish. Forget about service level agreements when the software
    is unsupported. You can't guarantee them anymore.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Legal requirements&lt;/strong&gt;. You might not know it, but many institutions
    are governed by specific IT requirements. Especially the financial
    sector (with the recent crisis and all) is and will get more and
    more regulatory compliance requests, and the IT infrastructure will
    not be spared. If you run unsupported software, you might be
    ignoring particular requirements that you have.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upgrade difficulties&lt;/strong&gt;. Eventually you will need to upgrade. If
    the software you are upgrading from is unsupported, chances are very
    low that a good, flexible (and cost-efficient) upgrade
    trajectory exists. Migration scripts will probably not work and
    consultancy will fail. Anyone have experience with upgrading from
    Oracle 7.3 to Oracle 11g?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration failures&lt;/strong&gt;. Most applications are integrated in a
    larger architecture. Applications probably get authorization feeds
    or send out events to other components. As the external services
    that the application interacts with get updated, their interfaces
    update with them. And eventually you will get into a situation where
    the integration suddenly fails. I've seen an application use
    HTTP/1.0 whereas its external services suddenly only
    supported HTTP/1.1. Have fun explaining that to your customer (who
    might not even know that HTTP is a protocol).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Customer support&lt;/strong&gt;. If you use an internal help desk, then you
    might be able to educate them with troubleshooting the (unsupported)
    software. But if the help desk is external, you'll probably be
    facing a "No" after a while - or a nice additional fee.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of these risks not only affect the product itself, but all other
products / softwares that are installed on the server (or even on the
network). If you ever face the request to continue supporting Foobar 2.0
on an unsupported Tomcat, now you have a checklist that you can tell
your (requesting) customer about the risks he is introducing - and don't
forget to tell the other customers about the risks they will be taking
as well then.&lt;/p&gt;
&lt;p&gt;But I promised that I will be talking about risk mitigation... so just
hold on for part 2 -- "service isolation".&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>checksec kernel security</title><link href="https://blog.siphos.be/2011/07/checksec-kernel-security/" rel="alternate"></link><published>2011-07-24T00:18:00+02:00</published><updated>2011-07-24T00:18:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-07-24:/2011/07/checksec-kernel-security/</id><summary type="html">&lt;p&gt;I have
&lt;a href="http://blog.siphos.be/2011/07/high-level-explanation-on-some-binary-executable-security/"&gt;blogged&lt;/a&gt;
about &lt;a href="http://www.trapkit.de/tools/checksec.html"&gt;checksec.sh&lt;/a&gt; earlier
before. Jono, one of the #gentoo-hardened IRC-members, kindly pointed
me to its &lt;code&gt;--kernel&lt;/code&gt; option. So I feel obliged to give its options a
stab as well. So, here goes the next batch of OPE-style (One Paragraph
Explanations).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~# checksec.sh --kernel
* Kernel protection information …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;I have
&lt;a href="http://blog.siphos.be/2011/07/high-level-explanation-on-some-binary-executable-security/"&gt;blogged&lt;/a&gt;
about &lt;a href="http://www.trapkit.de/tools/checksec.html"&gt;checksec.sh&lt;/a&gt; earlier
before. Jono, one of the #gentoo-hardened IRC-members, kindly pointed
me to its &lt;code&gt;--kernel&lt;/code&gt; option. So I feel obliged to give its options a
stab as well. So, here goes the next batch of OPE-style (One Paragraph
Explanations).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~# checksec.sh --kernel
* Kernel protection information:

  Description - List the status of kernel protection mechanisms. Rather than
  inspect kernel mechanisms that may aid in the prevention of exploitation of
  userspace processes, this option lists the status of kernel configuration
  options that harden the kernel itself against attack.

  Kernel config: /proc/config.gz

  GCC stack protector support:            Enabled
  Strict user copy checks:                Enabled
  Enforce read-only kernel data:          Disabled
  Restrict /dev/mem access:               Enabled
  Restrict /dev/kmem access:              Enabled

* grsecurity / PaX: Custom GRKERNSEC

  Non-executable kernel pages:            Enabled
  Prevent userspace pointer deref:        Disabled
  Prevent kobject refcount overflow:      Enabled
  Bounds check heap object copies:        Enabled
  Disable writing to kmem/mem/port:       Enabled
  Disable privileged I/O:                 Enabled
  Harden module auto-loading:             Enabled
  Hide kernel symbols:                    Enabled

* Kernel Heap Hardening: No KERNHEAP

  The KERNHEAP hardening patchset is available here:
    https://www.subreption.com/kernheap/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In-kernel &lt;strong&gt;GCC stack protector support&lt;/strong&gt; is the same as the &lt;strong&gt;Canary&lt;/strong&gt;
explanation I gave earlier, but now for the kernel code. Memory used by
the stack (which contains both function variables as well as return
addresses) is "interleaved" with specific data (canaries) which are
checked before using a return address that is on the stack. If the
canary doesn't match, you'll see a nice kernel panic. This is to prevent
buffer overflows that might influence the in-kernel activity flow or
overwrite data.&lt;/p&gt;
&lt;p&gt;When talking about &lt;strong&gt;Strict user copy checks&lt;/strong&gt;, one can compare this
with the &lt;strong&gt;FORTIFY_SOURCE&lt;/strong&gt; explanation given earlier. Although not the
same implementation-wise (since the latter is gcc/glibc bound, whereas
the Linux kernel does not use glibc) this too enables the compiler to
detect function calls with variable length data arguments to an extend
that it can predict the (should-be) length of the argument. If this is
the case, the function is switched with a(nother in-kernel) function
that either continues the call, or break in case of a length mismatch.
This is to prevent buffer overflows that might corrupt the stack (or
other data locations).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Enforce read-only kernel data&lt;/strong&gt; marks specific kernel data sections as
read-only to prevent accidental (or malicious) manipulations.&lt;/p&gt;
&lt;p&gt;When selecting &lt;strong&gt;Restrict /dev/mem access&lt;/strong&gt;, the kernel does not allow
applications (even those running as root) to access all of memory.
Instead, they are only allowed to see device-mapped memory (and their
own process memory). The same goes for &lt;strong&gt;Restrict /dev/kmem access&lt;/strong&gt;,
which is specifically for kernel memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Non-executable kernel pages&lt;/strong&gt; is similar to the &lt;strong&gt;NX&lt;/strong&gt; explanation
given earlier. It makes sure that pages marked as holding data can not
contain executable code (and will as such never be "jumped" in) and
pages marked as holding code will never be written to.&lt;/p&gt;
&lt;p&gt;To explain &lt;strong&gt;Prevent userspace pointer deref&lt;/strong&gt;, first you need to
understand the difference between a &lt;em&gt;userland address&lt;/em&gt; and a &lt;em&gt;kernel
address&lt;/em&gt;. Each application holds its own, private virtual address space.
Part of that virtual address space is "reserved" for most of the kernel
data (in other words, the kernel data is available in each process'
virtual address space), the rest is for the application. When
interaction with the kernel occurs, a userland address is given to the
kernel, which needs to translate it to a proper address (and treat it as
data). With &lt;strong&gt;Prevent userspace pointer deref&lt;/strong&gt;, specific checks are
made to ensure that the kernel doesn't directly use userspace pointers,
because that could be exploited by (malicious) software to trick the
kernel into doing things it shouldn't.&lt;/p&gt;
&lt;p&gt;Reference counters in the Linux kernel are used to track users of
specific objects or resources. A "popular" way to mistreat reference
counters (or any counter per se) is to increment them that much until
they overflow and wrap around, setting the counter to zero (or a
negative number), leading to unexpected results (such as freeing memory
that is in use). The &lt;strong&gt;Prevent kobject refcount overflow&lt;/strong&gt; detects this
for kobject resources and ensures that no wrap-around happens.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Bounds check heap object copies&lt;/strong&gt; checks if particular memory
copies use memory fragments within proper bounds. If the memory copy is
for a fragment that crosses that bound (for instance because the
fragment is too large) the copy fails. This offers some support against
overflows, similar to (but not the same as) the use of the stack
protector mentioned above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disable writing to kmem/mem/port&lt;/strong&gt; is similar to the &lt;strong&gt;Restrict
/dev/(k)mem access&lt;/strong&gt; settings, plus disable &lt;code&gt;/dev/port&lt;/code&gt; from being
opened.&lt;/p&gt;
&lt;p&gt;By selecting &lt;strong&gt;Disable privileged I/O&lt;/strong&gt;, access to the kernel through
functions like ioperm and iopl is prohibited. These functions are
sometimes used by applications that need direct device access, like
Xorg, but if you do not have such applications, it is wise to disable
privileged I/O access. If not, any vulnerability in such an application
might result in malicious code tampering with your devices.&lt;/p&gt;
&lt;p&gt;When &lt;strong&gt;Harden module auto-loading&lt;/strong&gt; is set, processes that do not run as
root will not be able to have particular kernel modules auto-loaded.
Although this seems strange, it isn't. Suppose you have an application
that wants to perform some IPv6 actions. Such applications can call
&lt;code&gt;request_module&lt;/code&gt; to ask the Linux kernel to load in a particular
service. If the kernel supports IPv6 through a module, then it will load
IPv6 support (you might have seen traces in your logs about &lt;code&gt;net-pf-10&lt;/code&gt;
- well, that's the IPv6 support). You can disable auto-loading
completely, but that might not be what you want. With this setting
enabled, auto-loading is supported but only for root-running
applications.&lt;/p&gt;
&lt;p&gt;The added security of &lt;strong&gt;Hide kernel symbols&lt;/strong&gt; is not to prevent
activities, but to prevent information to be leaked and (ab)used by
malicious users. Kernel symbols are string representations of functions
or variables that the kernel offers to kernel users (such as kernel
modules and drivers). This is needed because the location of these
functions/variables in memory cannot be provided in advance (this is no
different from symbols used as explained in the &lt;strong&gt;RELRO&lt;/strong&gt; security
setting in my previous posting). By hiding these symbols from any user
without sufficiently high privileges (and limit the exposure for high
privileged process to well-known locations so these too can be protected
by other means) it is far more difficult for malicious users to find out
about available functions/variables on your system.&lt;/p&gt;
&lt;p&gt;Finally, &lt;strong&gt;Kernel Heap Hardening&lt;/strong&gt; enhances the in-kernel dynamic memory
allocator with additional hardening features (double-free protection,
use-after-free protection, ...). It tries to ensure proper use of the
allocated memory segments and protect against improper access.&lt;/p&gt;
&lt;p&gt;From reading all this, you probably imagine why this isn't all enabled
by default. Well, many of the settings have implications on how the
system behaves. Some restrict functionalities to the root user only
(making it sometimes less user-friendly), some disable functionalities
that are needed (like the I/O access) or are (ab)used (like the user
space pointer deref which is used by many virtualization solutions)
while others add some additional overhead (the more you check, the
longer an action takes before it completes).&lt;/p&gt;
&lt;p&gt;To help users select the proper settings, Gentoo Hardened tries to
differentiate settings based on &lt;em&gt;workstation&lt;/em&gt; and &lt;em&gt;virtualization&lt;/em&gt;
usage. So you get most security settings for "No Workstation, No
Virtualization" and less for each of those you enable. But of course,
like always, Gentoo supports custom settings too so you don't have to
follow the differentiation we suggest ;-)&lt;/p&gt;
&lt;p&gt;Find something incorrect in the above paragraphs? Or too much
sales-speak and too little explanation? Give me a shout (and prove me
wrong) ;-)&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>High level explanation on some binary executable security</title><link href="https://blog.siphos.be/2011/07/high-level-explanation-on-some-binary-executable-security/" rel="alternate"></link><published>2011-07-15T22:01:00+02:00</published><updated>2011-07-15T22:01:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-07-15:/2011/07/high-level-explanation-on-some-binary-executable-security/</id><summary type="html">&lt;p&gt;One very important functionality offered by &lt;a href="http://hardened.gentoo.org"&gt;Gentoo
Hardened&lt;/a&gt; is a specific toolchain (compiler,
libraries and more) that contains patches to make the built binaries a
bit more protected from certain vulnerabilities. Explaining all those in
detail is too much for a simple blog post like this, but some time ago …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One very important functionality offered by &lt;a href="http://hardened.gentoo.org"&gt;Gentoo
Hardened&lt;/a&gt; is a specific toolchain (compiler,
libraries and more) that contains patches to make the built binaries a
bit more protected from certain vulnerabilities. Explaining all those in
detail is too much for a simple blog post like this, but some time ago
the friendly folks of the Gentoo Hardened project told be about a script
called &lt;a href="http://www.trapkit.de/tools/checksec.html"&gt;checksec.sh&lt;/a&gt; that
displays a few of those protections on a binary.&lt;/p&gt;
&lt;p&gt;So what can I find out of such a run? Let me show you the output on two
binaries here:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ checksec.sh --file /opt/skype/skype
RELRO           STACK CANARY      NX            PIE                     FILE
No RELRO        Canary found      NX disabled   No PIE                  /opt/skype/skype

~$ checksec.sh --file /bin/bash
RELRO           STACK CANARY      NX            PIE                     FILE
Full RELRO      Canary found      NX enabled    PIE enabled             /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It even comes with pretty colors (the "No RELRO" is red whereas "Full
RELRO" is green). But beyond interpreting those colors (which should be
obvious for the non-colorblind), what does that all mean? Well, let me
try to explain them in one-paragraph entries (yes, I like such
challenges ;-) Note that, if a protection is not found, then it probably
means that the application was not built with this protection (the skype
example, since this is a binary from Skype\^WMicrosoft, versus bash
which is built by the Gentoo Hardened toolchain).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RELRO&lt;/strong&gt; stands for &lt;em&gt;Relocation Read-Only&lt;/em&gt;, meaning that the headers in
your binary, which need to be writable during startup of the application
(to allow the dynamic linker to load and link stuff like shared
libraries) are marked as read-only when the linker is done doing its
magic (but before the application itself is launched). The difference
between &lt;strong&gt;Partial RELRO&lt;/strong&gt; and &lt;strong&gt;Full RELRO&lt;/strong&gt; is that the Global Offset
Table (and Procedure Linkage Table) which act as kind-of
process-specific lookup tables for symbols (names that need to point to
locations elsewhere in the application or even in loaded shared
libraries) are marked read-only too in the &lt;strong&gt;Full RELRO&lt;/strong&gt;. Downside of
this is that lazy binding (only resolving those symbols the first time
you hit them, making applications start a bit faster) is not possible
anymore.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;Canary&lt;/strong&gt; is a certain value put on the stack (memory where function
local variables are also stored) and validated before that function is
left again. Leaving a function means that the "previous" address (i.e.
the location in the application right before the function was called) is
retrieved from this stack and jumped to (well, the part right after that
address - we do not want an endless loop do we?). If the &lt;strong&gt;canary&lt;/strong&gt;
value is not correct, then the stack might have been overwritten /
corrupted (for instance by writing more stuff in the local variable than
allowed - called &lt;em&gt;buffer overflow&lt;/em&gt;) so the application is immediately
stopped.&lt;/p&gt;
&lt;p&gt;The abbreviation &lt;strong&gt;NX&lt;/strong&gt; stands for non-execute or non-executable
segment. It means that the application, when loaded in memory, does not
allow any of its segments to be both writable and executable. The idea
here is that writable memory should never be executed (as it can be
manipulated) and vice versa. Having &lt;strong&gt;NX enabled&lt;/strong&gt; would be good.&lt;/p&gt;
&lt;p&gt;The last abbreviation is &lt;strong&gt;PIE&lt;/strong&gt;, meaning &lt;em&gt;Position Independent
Executable&lt;/em&gt;. A &lt;strong&gt;No PIE&lt;/strong&gt; application tells the loader which virtual
address it should use (and keeps its memory layout quite static). Hence,
attacks against this application know up-front how the virtual memory
for this application is (partially) organized. Combined with in-kernel
ASLR (&lt;em&gt;Address Space Layout Randomization&lt;/em&gt;, which Gentoo's
hardened-sources of course support) PIE applications have a more diverge
memory organization, making attacks that rely on the memory structure
more difficult.&lt;/p&gt;
&lt;p&gt;But hold on, the checksec.sh application also supports detection for
&lt;code&gt;FORTIFY_SOURCE&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ checksec.sh --fortify-file /opt/skype/skype
 * FORTIFY_SOURCE support available (libc)    : Yes
* Binary compiled with FORTIFY_SOURCE support: Yes

 ------ EXECUTABLE-FILE ------- . -------- LIBC --------
 FORTIFY-able library functions | Checked function names
 -------------------------------------------------------
 printf                         | __printf_chk
...
SUMMARY:

* Number of checked functions in libc                : 75
* Total number of library functions in the executable: 2468
* Number of FORTIFY-able functions in the executable : 25
* Number of checked functions in the executable      : 0
* Number of unchecked functions in the executable    : 25
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the given example, my system does support &lt;code&gt;FORTIFY_SOURCE&lt;/code&gt; and the
binary is supposedly built with this support as well, but the checks
return that out of the 25 functions identified as &lt;code&gt;FORTIFY&lt;/code&gt;-able, none
of them were successfully verified as using a &lt;code&gt;FORTIFY&lt;/code&gt;-ed library call.
It goes without saying that for the /bin/bash binary, this yielded a bit
more good results (12 out of 30 verified).&lt;/p&gt;
&lt;p&gt;Again, what is &lt;strong&gt;FORTIFY_SOURCE&lt;/strong&gt;? Well, when using &lt;code&gt;FORTIFY_SOURCE&lt;/code&gt;,
the compiler will try to intelligently read the code it is compiling /
building. When it sees a C-library function call against a variable
whose size it can deduce (like a fixed-size array - it is more
intelligent than this btw) it will replace the call with a &lt;code&gt;FORTIFY&lt;/code&gt;'ed
function call, passing on the maximum size for the variable. If this
special function call notices that the variable is being overwritten
beyond its boundaries, it forces the application to quit immediately.
Note that not all function calls that can be fortified are fortified as
that depends on the intelligence of the compiler (and if it is realistic
to get the maximum size).&lt;/p&gt;
&lt;p&gt;If you do not agree with the explanation above, please comment... and
try to explain it in a single paragraph without going too detailed (i.e.
do not assume people are capable of writing their own compiler just for
fun).&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 3.0</title><link href="https://blog.siphos.be/2011/04/cvechecker-3-0/" rel="alternate"></link><published>2011-04-12T22:47:00+02:00</published><updated>2011-04-12T22:47:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-04-12:/2011/04/cvechecker-3-0/</id><summary type="html">&lt;p&gt;I'm pleased to announce the immediate availability of &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker
3.0&lt;/a&gt;. It contains two major feature
enhancements: watchlists and MySQL support.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;watchlists&lt;/em&gt; allow cvechecker to track and report on CVEs for software
that cvechecker didn't detect on the system (or perhaps even isn't
installed on the system). You can use …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm pleased to announce the immediate availability of &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker
3.0&lt;/a&gt;. It contains two major feature
enhancements: watchlists and MySQL support.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;watchlists&lt;/em&gt; allow cvechecker to track and report on CVEs for software
that cvechecker didn't detect on the system (or perhaps even isn't
installed on the system). You can use watchlists to stay informed of
potential vulnerabilities in software used at work on servers where you
are not allowed (or do not want) to run cvechecker on. To use
watchlists, create a text file containing the CPE identifiers for the
software that you want to watch out for, and add it to the database:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;~$ cat watchlist.txt
cpe:/a:microsoft:excel:2003:::

~$ cvechecker -d -w watchlist.txt
Adding CPE entries
  - Added watch for cpe:/a:microsoft:excel:2003:::
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The second major feature is support for MySQL. This is the first
server-oriented RDBMS that cvechecker supports (earlier versions worked
with sqlite only) although sqlite support remains available as well. I
hope to extend the number of supported databases in the future (say
PostgreSQL, Oracle, SQL Server, ...). With support for server RDBMSes
came of course the requirement that multiple cvechecker clients are able
to use the same server (as the CVE and CPE data itself can be shared).
With the 3.0 release, this is supported as each client now "adds" to the
data both his hostname as well as an (optional) user defined value
(which can be anything you like). If unset, this user value is set to
the hostname, but you can use things like the systems' serial ID or
asset ID.&lt;/p&gt;
&lt;p&gt;I'm hoping all users have fun with it - I know I have while writing it.
Feedback, remarks, feature requests, bugs and other criticism is always
very much appreciated.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker updates</title><link href="https://blog.siphos.be/2011/03/cvechecker-updates/" rel="alternate"></link><published>2011-03-27T22:20:00+02:00</published><updated>2011-03-27T22:20:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-03-27:/2011/03/cvechecker-updates/</id><summary type="html">&lt;p&gt;The in-svn version of cvechecker has seen quite a few changes in the
last few days. I'm adding support for MySQL to it. This support will be
added in three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;support the same features as cvechecker currently does using sqlite&lt;/li&gt;
&lt;li&gt;streamline the database code so that duplicate code in …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;The in-svn version of cvechecker has seen quite a few changes in the
last few days. I'm adding support for MySQL to it. This support will be
added in three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;support the same features as cvechecker currently does using sqlite&lt;/li&gt;
&lt;li&gt;streamline the database code so that duplicate code in the sqlite
    implementation and mysql implementation is removed&lt;/li&gt;
&lt;li&gt;support multi-node systems with a single master database&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The latter is something I've been meaning to implement for quite some
time: have a single system dedicated to download and store the latest
CVE entries in the database (as well as CPE definitions) whereas several
systems can use the database by storing their own system information and
getting a mapping from that information against the CVE database. Even
more so, it would allow you to query the database asking on which
systems a particular software was detected, or which systems still have
vulnerable software installed.&lt;/p&gt;
&lt;p&gt;When the MySQL support is implemented, I'm going to work a bit on the
&lt;code&gt;versions.dat&lt;/code&gt; file, because it doesn't really support many services
currently. I'm going to use it against my "virtual network" (a
combination of KVM guests running bind (master/slave), ldap
(multi-master), postfix, apache, squirrelmail, courier, postgresql,
mysql and more) and enhance it so that it detects all those components
as well.&lt;/p&gt;
&lt;p&gt;Oh, btw, I had a request to include support for just telling cvechecker
which components/software to look for (rather than it scanning the files
and deducing it from regular expressions and the like). The in-svn
version supports it, so it will definitely be part of the 3.0 release.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker update</title><link href="https://blog.siphos.be/2011/02/cvechecker-update/" rel="alternate"></link><published>2011-02-19T16:31:00+01:00</published><updated>2011-02-19T16:31:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2011-02-19:/2011/02/cvechecker-update/</id><summary type="html">&lt;p&gt;A while ago, I got the request to enhance
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; with support for
providing a list of installed software (or software you want to watch
over with cvechecker) even if cvechecker isn't able to detect that
software on your system. I've implemented this and it is currently
available in the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A while ago, I got the request to enhance
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; with support for
providing a list of installed software (or software you want to watch
over with cvechecker) even if cvechecker isn't able to detect that
software on your system. I've implemented this and it is currently
available in the SVN repository. The next release of cvechecker will
support this, but I'm hoping to add support for other databases with it
as well (currently, it uses a local sqlite database but I'm hoping to
support at least MySQL and postgresql too).&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 2.0 released</title><link href="https://blog.siphos.be/2010/12/cvechecker-2-0-released/" rel="alternate"></link><published>2010-12-01T22:29:00+01:00</published><updated>2010-12-01T22:29:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-12-01:/2010/12/cvechecker-2-0-released/</id><summary type="html">&lt;p&gt;Okay, enough play - time for a new release. Since &lt;strong&gt;cvechecker 1.0&lt;/strong&gt; was
released, a few important changes have been made to the &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker
tools&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can now tell cvechecker to only check newly added files, or
    remove a set of files from its internal database. Previously, you
    had to …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Okay, enough play - time for a new release. Since &lt;strong&gt;cvechecker 1.0&lt;/strong&gt; was
released, a few important changes have been made to the &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker
tools&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can now tell cvechecker to only check newly added files, or
    remove a set of files from its internal database. Previously, you
    had to have cvechecker scan the entire system again.&lt;/li&gt;
&lt;li&gt;cvechecker can now also report if vulnerabilities have been found in
    software versions that are higher than the version you currently
    have installed. This can help you find seriously outdated software,
    but also help you identify possible vulnerabilities if the CVE
    itself doesn't contain all vulnerable versions, just the "latest"
    vulnerable version.&lt;/li&gt;
&lt;li&gt;The toolset now contains a command called &lt;strong&gt;cverules&lt;/strong&gt; which, on a
    Gentoo system, will attempt to generate version matching rules for
    software that is currently not detected by cvechecker yet. Very
    useful as I myself cannot install every possible software on my
    system to enhance the version matching rules. If you want to help
    out, run the &lt;strong&gt;cverules&lt;/strong&gt; command and send me the output.&lt;/li&gt;
&lt;li&gt;Some needed performance enhancements have been added as well&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One thing I wanted to include as well was a tool that validates
&lt;strong&gt;cvechecker&lt;/strong&gt; output against the distribution security information.
Some distributions patch software (to fix a vulnerability) rather than
ask the user to upgrade to a non-vulnerable software. The cvechecker
tools often cannot differentiate between the vulnerable and
non-vulnerable binaries (as they both mention the same version), but
often you can check against some meta data files of the distribution if
and which CVEs have been resolved in which versions of a distribution
package.&lt;/p&gt;
&lt;p&gt;The cvechecker tarball contains a script (see the &lt;code&gt;scripts/&lt;/code&gt; folder for
&lt;strong&gt;cvepkgcheck_gentoo&lt;/strong&gt;) for Gentoo that tries to get this information
from the GLSAs, but it is far from ready. I should try setting up a KVM
instance with an "old" Gentoo installation just to validate if the
command works, but even if it does, I'm not happy with how it is
written. Seems to me a lot of trouble, and if it cannot be done simply,
I'm afraid I'm doing it wrong ;-)&lt;/p&gt;
&lt;p&gt;Anyhow, I hope you enjoy version 2.0 of cvechecker.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Helping with version detection rules in cvechecker</title><link href="https://blog.siphos.be/2010/11/helping-with-version-detection-rules-in-cvechecker/" rel="alternate"></link><published>2010-11-27T17:59:00+01:00</published><updated>2010-11-27T17:59:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-11-27:/2010/11/helping-with-version-detection-rules-in-cvechecker/</id><summary type="html">&lt;p&gt;The new development snapshot, available from the &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker project
site&lt;/a&gt;, contains a helper script that
returns potential version detection rules for your system if the current
cvechecker database doesn't detect your software. The script is
currently available for Gentoo (called &lt;strong&gt;cverules_gentoo&lt;/strong&gt;) but other
distributions can be easily added. The actual …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The new development snapshot, available from the &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker project
site&lt;/a&gt;, contains a helper script that
returns potential version detection rules for your system if the current
cvechecker database doesn't detect your software. The script is
currently available for Gentoo (called &lt;strong&gt;cverules_gentoo&lt;/strong&gt;) but other
distributions can be easily added. The actual logic for detection is
distribution-agnostic (the script &lt;strong&gt;cvegenversdat&lt;/strong&gt;) so it shouldn't be
too much of a problem for other distributions to be supported as well.&lt;/p&gt;
&lt;p&gt;Note that the script isn't very fast (it's not intended to be) nor has a
very high accuracy rate. After all, it does use generic regular
expressions to try. The idea is that deployments on systems that have
software I don't have on my system can help me with the development of
the version detection rules by sending me the output of the helper
script.&lt;/p&gt;
&lt;p&gt;Next up: tool to auto-generate (part of) the acknowledgements file for
reporting purposes - getting information from distribution-specific
information. Once that is in, I'll tag it version 2.0 of cvechecker.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Delta processing in cvechecker</title><link href="https://blog.siphos.be/2010/11/delta-processing-in-cvechecker/" rel="alternate"></link><published>2010-11-02T00:30:00+01:00</published><updated>2010-11-02T00:30:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-11-02:/2010/11/delta-processing-in-cvechecker/</id><summary type="html">&lt;p&gt;The &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; application will
support delta file processing as well as higher version matching with
its next release. The functionality is currently in version control and
I still have to work out quite a few things before they can go live, but
the functionality is there.&lt;/p&gt;
&lt;p&gt;Now why would these …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; application will
support delta file processing as well as higher version matching with
its next release. The functionality is currently in version control and
I still have to work out quite a few things before they can go live, but
the functionality is there.&lt;/p&gt;
&lt;p&gt;Now why would these functions be interesting?&lt;/p&gt;
&lt;p&gt;Well, first of all, by supporting &lt;strong&gt;delta file processing&lt;/strong&gt; I am able to
use &lt;strong&gt;cvechecker&lt;/strong&gt; with Portage' hooks. Every time a package is
unmerged, &lt;strong&gt;cvechecker&lt;/strong&gt; will remove the files from its database (so
that it doesn't get picked up in vulnerability reports anymore).
Similarly, every time a package is emerged, the files are stored in the
database. There is no need to perform a full system scan every time the
system has been updated.&lt;/p&gt;
&lt;p&gt;Second, being able to report on &lt;strong&gt;higher version vulnerabilities&lt;/strong&gt; the
tool can now also trap potential issues with reports that do not contain
the exact version as detected by &lt;strong&gt;cvechecker&lt;/strong&gt; but &lt;em&gt;can&lt;/em&gt; be relevant.
For instance, a version detection of &lt;code&gt;Linux 2.6.35-hardened-r1&lt;/code&gt; might
otherwise not be noticed (for instance because no CVE is reported on the
hardened-r1 release) yet a CVE report on &lt;code&gt;2.6.35&lt;/code&gt; or even &lt;code&gt;2.6.36-rc4&lt;/code&gt;
might be of interest. By using the higher version reporting, you'll be
notified of this as well. Same goes for vulnerability reports on an
entire branch (say &lt;code&gt;Python 2.4&lt;/code&gt;), especially when those branches are not
actively being developed anymore (so the vulnerability remains). And
another benefit is that you might be informed about higher versions of
particular software being available ;-)&lt;/p&gt;
&lt;p&gt;Now, a very quick warning before everybody cheers and does the penguin
dance: enabling higher version reports will give you &lt;em&gt;lots&lt;/em&gt; of false
hits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First of all, detecting if a version is higher than another version
    isn't easy. The tool is able to put &lt;code&gt;0.9.8 - 0.9.8a - 0.9.8b&lt;/code&gt; in the
    right order, as well as &lt;code&gt;0.5.1_alpha - 0.5.1_beta - 0.5.1&lt;/code&gt;, but the
    same algorithm will make &lt;code&gt;2.6.35-hardened-r1&lt;/code&gt; be less than &lt;code&gt;2.6.35&lt;/code&gt;,
    and a secure &lt;code&gt;0.9.8&lt;/code&gt; version will be seen vulnerable when
    &lt;code&gt;1.0.0_alpha&lt;/code&gt; has a vulnerability.&lt;/li&gt;
&lt;li&gt;Second of all, official CVE entries don't always provide a good
    version match themselves. For instance,
    &lt;a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2008-4609"&gt;CVE-2008-4609&lt;/a&gt;
    has been configured that &lt;code&gt;Linux Kernel 390&lt;/code&gt; and &lt;code&gt;Linux Kernel 3.25&lt;/code&gt;
    (I know those are not correct version numbers - my point exactly)
    are vulnerable. So yes, &lt;code&gt;390&lt;/code&gt; is (a lot) higher than &lt;code&gt;2.6.35&lt;/code&gt;...&lt;/li&gt;
&lt;li&gt;Third, many tools use parallel development branches. Take Python for
    instance: even when version 2.6.5 would have no vulnerabilities and
    2.7 or 3.2 alpha releases do, it will still report the 2.6.5 one as
    having a potential vulnerability. This seems to give (for me
    at least) the most false positives of all.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I still don't know how to deal with this huge amount of false positives
- comments are always welcome.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Risk identification</title><link href="https://blog.siphos.be/2010/10/risk-identification/" rel="alternate"></link><published>2010-10-14T20:18:00+02:00</published><updated>2010-10-14T20:18:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-10-14:/2010/10/risk-identification/</id><summary type="html">&lt;p&gt;Risk identification is a difficult subject. Analysts need it to defend
mitigation strategies or to suggest investments. Yet risk identification
is often a subjective method, especially in the IT industry. How do you
give a number on a certain risk? When do you believe that that number
exceeds a threshold …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Risk identification is a difficult subject. Analysts need it to defend
mitigation strategies or to suggest investments. Yet risk identification
is often a subjective method, especially in the IT industry. How do you
give a number on a certain risk? When do you believe that that number
exceeds a threshold? Because of the ambiguous definition of risks, it is
often overlooked or substituted with impact analysis.&lt;/p&gt;
&lt;p&gt;Now impact analysis is not much better, but it is easier to comprehend.
Impact analysis describes what happens when something has occurred. It
doesn't state how often it can occur, or what the chances are of the
event to occur, but gives an estimation on how big the impact would be
when it occurs. Most of the time one describes an impact with financial
loss. The highest impact a company has is that its survival is
threatened. If you're a simple shop and you don't take an insurance on
your stock, the impact of a fire or explosion in your shop might be that
you're put out of business. If you do have insurance, your impact is
more limited.&lt;/p&gt;
&lt;p&gt;In the majority of cases, impact analysis is more straightforward.&lt;/p&gt;
&lt;p&gt;IT risks are a prime example of difficult exercises. Quantifying the IT
risks that a company is taking is difficult. In this post, I'm
introducing a more straightforward method - even if it isn't fail-safe,
it might still give some interesting sights on the matter. It is of
course not something I invented myself (there's enough information on
the internet about risk analysis or risk identification), merely a
combination of several methods and ideas which I find useful (and
decided to write up about).&lt;/p&gt;
&lt;p&gt;The method identifies a risk within four levels: low, medium, high and
very high. To get inside a level, it uses two metrics: &lt;em&gt;impact analysis&lt;/em&gt;
which we've discussed before, and &lt;em&gt;chance of occurrence&lt;/em&gt;. The latter is
the most difficult to identify, but let's first show how to map the two
onto the risk level:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;chance of occurrence
   ^
 4 +  M  M  VH VH
 3 +  M  M  VH VH
 2 +  L  L  H  H
 1 +  L  L  H  H
   x--+--+--+--+--&amp;gt; impact analysis
      1  2  3  4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As you can see, I give each axis four values, going from low (low
impact, or low probability) onto high. The resulting point lays within
one of four quadrants - Low, Medium, High or Very High. I identify an
event as having a high(er) risk when its probability is low but impact
high, whereas an event that has a high probability but low impact is
considered to be less of a risk: when something with a somewhat low(er)
impact occurs, you should still have some breathing space to make sure
it won't happen again (or find a way to reduce the impact) whereas an
occurrence of something with a high(er) impact will most likely leave
you hurt, fragile and licking your wounds.&lt;/p&gt;
&lt;p&gt;So, how to measure the chance of occurrence of an event? Well, let's do
this in two stages: do an initial assessment, and then elevate the
chance using particular checks. Within IT, an often described threat is
the threat of someone trying to achieve personal gain (financial or
public) from the system(s). Note that, for every possible threat, one
will need to make a risk identification - you can't just say that a
system has a risk. It is always a particular threat which is assigned a
risk. So how large is the chance of such a "hack" attempt occurring?&lt;/p&gt;
&lt;p&gt;First, how "wide" is the access vector towards your system? Can the
entire world (read: Internet) access the system (level = 4), is it
everyone in the company (level = 3), everyone within an affiliated
department (in most cases it means "IT department", level = 2) or
limited to a very small set of people (level = 1)?&lt;/p&gt;
&lt;p&gt;Second, if one of the people identified earlier would want to perform
malicious activity with eye on personal gain (financial or PR), would he
succeed by his own (level + 1) or would he need at least one accomplice?&lt;/p&gt;
&lt;p&gt;Third, if the activity was performed, would it be traceable to the
person or not (if not: level + 1)?&lt;/p&gt;
&lt;p&gt;As an example (purely hypothetical): read access to the access logs of a
web application server which contains HTTP session information (logging
of SESSIONID) as well as username (authentication) and origin (IP
address) as well as other information. The threat: using this
information to hijack an active session.&lt;/p&gt;
&lt;p&gt;First, if a hijack would be successful, the impact would be considered a
level-3 (with 1 being low and 4 being very high): the company might
suffer huge financial losses or PR would be a difficult beast to tame
(because the application is an internal stock application with features
to perform financial operations). But how high is the chance of
occurrence?&lt;/p&gt;
&lt;p&gt;Well, say that the log files themselves can only be read by IT staff
(level = 2), but that someone of the IT staff cannot hijack the session
easily with this information alone as he would either require firewall
changes (for instance because the application can only be reached
through trusted middleware components) or have access to the machine the
user is working on, and such changes or access require more than a
single person in the situation. Also, if he did, audit trails would lead
the changes (firewall changes or machine access) to the person. As a
result, the chance of this event occurring given the circumstances is
considered a level 2. At the quadrant, this would yield a level of
"High". The risk of occurrence is relatively low, but the impact is too
high to ever consider this a "Medium" or "Low".&lt;/p&gt;
&lt;p&gt;Now if we were to reduce the risk, we could focus on lowering the chance
of occurrence (only few people access to the given information - say
keep SESSIONID information in a separate, inaccessible logfile only to
be used for general, automated metric collection - after all, if there's
no point in keeping track of SESSIONID's, they wouldn't be logged
anyhow). This is a lot easier to accomplish than to try and lower the
impact analysis. On the other hand, if the impact analysis could be
lowered (say by requesting a stronger authentication method for
validating particular steps within the application, such as approvals) a
session hijack would give less impact - say level 2 or even 1. In that
case, the current risk would be lowered from "High" to "Low".&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 1.0 released</title><link href="https://blog.siphos.be/2010/10/cvechecker-1-0-released/" rel="alternate"></link><published>2010-10-01T21:34:00+02:00</published><updated>2010-10-01T21:34:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-10-01:/2010/10/cvechecker-1-0-released/</id><summary type="html">&lt;p&gt;With only a few small bugfixes between this release and the previous
one, &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker 1.0&lt;/a&gt; has finally
been released. It runs fine on my few systems and I have not gotten any
bugreports from other users anymore. It can definitely need more rules
to identify installed software (those rules …&lt;/p&gt;</summary><content type="html">&lt;p&gt;With only a few small bugfixes between this release and the previous
one, &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker 1.0&lt;/a&gt; has finally
been released. It runs fine on my few systems and I have not gotten any
bugreports from other users anymore. It can definitely need more rules
to identify installed software (those rules are released separately)
which is what I will focus on the few upcoming weeks. Once that has been
accomplished, I will start with the alpha releases for the 2.0 series
using the &lt;a href="http://cvechecker.sourceforge.net/docs/featurerequests.html"&gt;feature
requests&lt;/a&gt;
as a guideline.&lt;/p&gt;
&lt;p&gt;I plan on maintaining the earlier versions of cvechecker for two
consecutive releases - one including small functional enhancements (as
long as they can be applied on the development release and the stable
release easily) and one just for security and bug fixes.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 0.6 released</title><link href="https://blog.siphos.be/2010/09/cvechecker-0-6-released/" rel="alternate"></link><published>2010-09-08T21:41:00+02:00</published><updated>2010-09-08T21:41:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-09-08:/2010/09/cvechecker-0-6-released/</id><summary type="html">&lt;p&gt;This release makes me quite happy, because it resolves one major PITA I
had (performance), but you know how things go. If it works fine for the
developer, it's probably an abomination for the rest of the world.
Anyhow, &lt;a href="http://cvechecker.sf.net"&gt;cvechecker&lt;/a&gt; version 0.6 is now
available. It improves reporting performance …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This release makes me quite happy, because it resolves one major PITA I
had (performance), but you know how things go. If it works fine for the
developer, it's probably an abomination for the rest of the world.
Anyhow, &lt;a href="http://cvechecker.sf.net"&gt;cvechecker&lt;/a&gt; version 0.6 is now
available. It improves reporting performance tremendously if your sqlite
library is sufficiently up-to-date, now supports reporting on found
software (regardless if it matches a CVE entry or not) and adds quite a
few bug fixes along the way.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 0.5 released</title><link href="https://blog.siphos.be/2010/09/cvechecker-0-5-released/" rel="alternate"></link><published>2010-09-02T00:57:00+02:00</published><updated>2010-09-02T00:57:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-09-02:/2010/09/cvechecker-0-5-released/</id><summary type="html">&lt;p&gt;A new intermediate release of
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; is now released. The
tool is reported to build properly on NetBSD and FreeBSD as well
(although much user experience there is still welcome), introduces a
&lt;strong&gt;cvereport&lt;/strong&gt; command (&lt;a href="http://cvechecker.sourceforge.net/example/report.html"&gt;example
output&lt;/a&gt;), has
lowered its initial dependency requirements and &lt;strong&gt;pullcves&lt;/strong&gt; now only
loads the CVE XML …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A new intermediate release of
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; is now released. The
tool is reported to build properly on NetBSD and FreeBSD as well
(although much user experience there is still welcome), introduces a
&lt;strong&gt;cvereport&lt;/strong&gt; command (&lt;a href="http://cvechecker.sourceforge.net/example/report.html"&gt;example
output&lt;/a&gt;), has
lowered its initial dependency requirements and &lt;strong&gt;pullcves&lt;/strong&gt; now only
loads the CVE XML changes in the database, rather than iterating across
all CVE XML entries.&lt;/p&gt;
&lt;p&gt;Many thanks to Nigel Horne for his continuous testing/hammering on the
tool.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 0.4 released</title><link href="https://blog.siphos.be/2010/08/cvechecker-0-4-released/" rel="alternate"></link><published>2010-08-25T23:55:00+02:00</published><updated>2010-08-25T23:55:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-08-25:/2010/08/cvechecker-0-4-released/</id><summary type="html">&lt;p&gt;Albeit with less updates than 0.3 had, &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker
0.4&lt;/a&gt; brings in internal project files
reorganization (more to the liking of the GNU autoconf/automake
standards - I think), fixes a databaseleak (instead of memoryleak ;-)
bug and introduces a teenie weenie bit more intelligent pullcves command
(with multiple return code …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Albeit with less updates than 0.3 had, &lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker
0.4&lt;/a&gt; brings in internal project files
reorganization (more to the liking of the GNU autoconf/automake
standards - I think), fixes a databaseleak (instead of memoryleak ;-)
bug and introduces a teenie weenie bit more intelligent pullcves command
(with multiple return code behavior to improve automation efforts) as
was mentioned in the feature request list. All documentation is also
updated and a pullcves manual page has been added.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker userguide</title><link href="https://blog.siphos.be/2010/08/cvechecker-userguide/" rel="alternate"></link><published>2010-08-22T17:37:00+02:00</published><updated>2010-08-22T17:37:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-08-22:/2010/08/cvechecker-userguide/</id><content type="html">&lt;p&gt;Just a quick note, I've created and uploaded the &lt;a href="http://cvechecker.sourceforge.net/documentation.html"&gt;cvechecker
userguide&lt;/a&gt;.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 0.3 released</title><link href="https://blog.siphos.be/2010/08/cvechecker-0-3-released/" rel="alternate"></link><published>2010-08-20T22:15:00+02:00</published><updated>2010-08-20T22:15:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-08-20:/2010/08/cvechecker-0-3-released/</id><content type="html">&lt;p&gt;Time for a new intermediate
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt; release, so here it is.
Changes include (beyond the usual bugfixes) different CSV output (with
some sort of version support) so that it can be easily used for
reporting purposes, removal of debugging/verbose items and added example
files for reporting.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 0.2 released</title><link href="https://blog.siphos.be/2010/08/cvechecker-0-2-released/" rel="alternate"></link><published>2010-08-16T21:35:00+02:00</published><updated>2010-08-16T21:35:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-08-16:/2010/08/cvechecker-0-2-released/</id><summary type="html">&lt;p&gt;I've made version 0.2 available of
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt;. It fixes some build
warnings and also supports the normal "make install" step. The
&lt;strong&gt;pullcves&lt;/strong&gt; command now also pulls in the latest &lt;code&gt;versions.dat&lt;/code&gt; file.
Special thanks to Per Andersson for reporting that the &lt;code&gt;./configure&lt;/code&gt;
didn't fail if sqlite3 or libconfig wasn't …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've made version 0.2 available of
&lt;a href="http://cvechecker.sourceforge.net"&gt;cvechecker&lt;/a&gt;. It fixes some build
warnings and also supports the normal "make install" step. The
&lt;strong&gt;pullcves&lt;/strong&gt; command now also pulls in the latest &lt;code&gt;versions.dat&lt;/code&gt; file.
Special thanks to Per Andersson for reporting that the &lt;code&gt;./configure&lt;/code&gt;
didn't fail if sqlite3 or libconfig wasn't available - that should be
fixed now as well.&lt;/p&gt;
&lt;p&gt;In my &lt;a href="http://github.com/sjvermeu/gentoo.overlay"&gt;Gentoo overlay&lt;/a&gt;,
&lt;code&gt;cvechecker-0.2.ebuild&lt;/code&gt; has been put available. Thanks there to
webkiller71 for helping out with a more sane approach to
&lt;code&gt;cvechecker-0.1.ebuild&lt;/code&gt; - I hope I didn't screw up his changes in 0.2
too much ;-)&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker 0.1 released</title><link href="https://blog.siphos.be/2010/08/cvechecker-0-1-released/" rel="alternate"></link><published>2010-08-14T22:03:00+02:00</published><updated>2010-08-14T22:03:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-08-14:/2010/08/cvechecker-0-1-released/</id><summary type="html">&lt;p&gt;cvechecker &lt;a href="https://sourceforge.net/projects/cvechecker/files/"&gt;version
0.1&lt;/a&gt; is out. This is
the first publicly available development release, so it's still far from
production-ready yet. However, it is usable so it can now be publicly
analyzed to remove all icky bugs and such. I'm not planning (m)any new
features (apart from the reporting …&lt;/p&gt;</summary><content type="html">&lt;p&gt;cvechecker &lt;a href="https://sourceforge.net/projects/cvechecker/files/"&gt;version
0.1&lt;/a&gt; is out. This is
the first publicly available development release, so it's still far from
production-ready yet. However, it is usable so it can now be publicly
analyzed to remove all icky bugs and such. I'm not planning (m)any new
features (apart from the reporting script as mentioned on the tools'
&lt;a href="http://cvechecker.sourceforge.net"&gt;homepage&lt;/a&gt;) before the first general
available release, but any request will be gladly documented and taken
in scope in future versions.&lt;/p&gt;
&lt;p&gt;What is cvechecker? Well, it is a tool that strives to scan your system
for installed software. For each software it detects, it attempts to
discover which version you have. This information is stored in a local
database. The tool then matches this information with the (publicly
available) CVE data (security vulnerability information). If a CVE entry
mentions the software/version you have, the tool will report this to
you.&lt;/p&gt;
&lt;p&gt;Who needs cvechecker? Noone needs it, but it can be interesting
nevertheless. Users that install lots of software themselves and don't
use the Linux distribution's package manager might benefit from this as
the tool will then help them verify if a security update is needed or
not. Users of &lt;a href="http://www.linuxfromscratch.org"&gt;LinuxFromScratch&lt;/a&gt; can do
some security validation tests on their installations. Developers of
particular packages (or even tools) can use the tool to be notified when
one of their software's has a CVE (which most likely results in a new
version of the software to be made available).&lt;/p&gt;
&lt;p&gt;Who needs cvechecker? No, this is not a duplicate paragraph - cvechecker
needs input. Most of the work goes in detecting the available software
and version. The method cvechecker uses is very rudimentary: run a
(predefined) regular expression against the file (which is parsed with
the &lt;strong&gt;strings&lt;/strong&gt; command as this command understands ELF structures) and
if the expression matches, it will extract the version (which is found
using the expressions' groups) and store this in the database. The rules
are defined in the &lt;code&gt;versions.dat&lt;/code&gt; file (also available from
&lt;a href="https://sourceforge.net/projects/cvechecker/files/"&gt;sourceforge&lt;/a&gt;), but
this file is currently microscopicly filled - so lots and lots of
additional rules need to be added. I'll be adding more and more rules as
I encounter them (or have immediate need for), but I can definitely use
additional help here.&lt;/p&gt;
&lt;p&gt;If you are interested in enhancing the &lt;code&gt;versions.dat&lt;/code&gt; file, check out
the cvechecker manual page - it describes the format and how it is used
as well as some examples.&lt;/p&gt;
&lt;p&gt;And yes, an ebuild is available in my
&lt;a href="http://github.com/sjvermeu/gentoo.overlay"&gt;overlay&lt;/a&gt;, but I'm no ebuild
developer (it's just easy to have them so Portage can track it) and the
ebuild is butt-ugly (and probably also violates all QA policies).&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>Linux Sea sources online, cvechecker still in development</title><link href="https://blog.siphos.be/2010/07/linux-sea-sources-online-cvechecker-still-in-development/" rel="alternate"></link><published>2010-07-23T20:59:00+02:00</published><updated>2010-07-23T20:59:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-07-23:/2010/07/linux-sea-sources-online-cvechecker-still-in-development/</id><summary type="html">&lt;p&gt;First of all, I've put the sources for &lt;a href="http://swift.siphos.be/linux_sea"&gt;Linux
Sea&lt;/a&gt; online at
&lt;a href="http://github.com/sjvermeu/Linux-Sea"&gt;GitHub&lt;/a&gt;. Not only does that
safeguard any latest changes from not hitting my backup in time before
my laptop dies (it's terminal, but I can't let him go yet ;-) but it
also allows people who want to help …&lt;/p&gt;</summary><content type="html">&lt;p&gt;First of all, I've put the sources for &lt;a href="http://swift.siphos.be/linux_sea"&gt;Linux
Sea&lt;/a&gt; online at
&lt;a href="http://github.com/sjvermeu/Linux-Sea"&gt;GitHub&lt;/a&gt;. Not only does that
safeguard any latest changes from not hitting my backup in time before
my laptop dies (it's terminal, but I can't let him go yet ;-) but it
also allows people who want to help with it (or translate it) to pull in
the sources.&lt;/p&gt;
&lt;p&gt;Note that it is still not finished (no spelling and grammar check done
yet, still need to add some exercises, etc); once it is, I will tag the
sources appropriately.&lt;/p&gt;
&lt;p&gt;On the &lt;a href="http://cvechecker.sf.net"&gt;cvechecker&lt;/a&gt; state, it is also still
under development, but progress is going nicely. Most of the work now is
in updating the &lt;code&gt;versions.dat&lt;/code&gt; file with information on how to obtain
the current version of a package/tool. It is an easy activity - most of
the work is in finding out how CVE entries would label a tool (what
vendor and product name would be chosen) and because I am too lazy, I am
currently only adding those that already have CVE entries assigned to
them (so I can just take a look at the correct values).&lt;/p&gt;
&lt;p&gt;It is also my first attempt at using autotools. Quite some overkill for
such a small project, but why not. At least it allows me to try to do
some new things here ;-)&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>cvechecker in development mode</title><link href="https://blog.siphos.be/2010/07/cvechecker-in-development-mode/" rel="alternate"></link><published>2010-07-12T20:31:00+02:00</published><updated>2010-07-12T20:31:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-07-12:/2010/07/cvechecker-in-development-mode/</id><summary type="html">&lt;p&gt;A while ago I had the idea to create a simple tool that checks the CVE
database against my current system. It would allow me to check if my
system is somewhat up to date (no pending security vulnerabilities), but
also to get an automated overview of the various software …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A while ago I had the idea to create a simple tool that checks the CVE
database against my current system. It would allow me to check if my
system is somewhat up to date (no pending security vulnerabilities), but
also to get an automated overview of the various software packages (and
versions) using a distribution-agnostic method.&lt;/p&gt;
&lt;p&gt;So I started coding. The idea is to have a tool which can interprete CVE
data, gather current version information from the system and match the
CVEs against these versions and report the results to me.&lt;/p&gt;
&lt;p&gt;I have created a &lt;a href="http://cvechecker.sourceforge.net"&gt;sourceforge&lt;/a&gt;
project to host the source code and preliminary documentation for the
tool. Although the tool runs, it is still far from finished. On the
site, you can check out the progress of the development (there's a first
todo-list on the main page).&lt;/p&gt;
&lt;p&gt;Do you think this is a good idea? I'd be happy to hear it.&lt;/p&gt;</content><category term="Security"></category></entry><entry><title>OVAL, SCAP, CVE, CPE, ...</title><link href="https://blog.siphos.be/2010/06/oval-scap-cve-cpe/" rel="alternate"></link><published>2010-06-05T15:13:00+02:00</published><updated>2010-06-05T15:13:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2010-06-05:/2010/06/oval-scap-cve-cpe/</id><summary type="html">&lt;p&gt;For a personal &lt;abbr title="Proof Of Concept"&gt;POC&lt;/abbr&gt; I wanted to see
if it is possible to generate, based on the collection of CVE entries
publicly available, a report informing a system administrator about
possible vulnerabilities. Nothing fancy, just based upon versions.&lt;/p&gt;
&lt;p&gt;A simple example: tool detects Perl, acquires installed Perl version,
then matches …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For a personal &lt;abbr title="Proof Of Concept"&gt;POC&lt;/abbr&gt; I wanted to see
if it is possible to generate, based on the collection of CVE entries
publicly available, a report informing a system administrator about
possible vulnerabilities. Nothing fancy, just based upon versions.&lt;/p&gt;
&lt;p&gt;A simple example: tool detects Perl, acquires installed Perl version,
then matches the collection of CVE entries against this Perl version. If
at least one CVE is found, report it. The idea is then to make this as
generic as possible (not specific for an operating system or Linux
distribution), so not use a package version but really the tool version
(or library version).&lt;/p&gt;
&lt;p&gt;Of course, whenever I am planning such minor POCs, I search the Internet
for possible existing tools (just like &lt;a href="http://www.kev009.com/wp/2010/05/but-first-write-no-code/"&gt;kev009 describes - "But First,
Write No
Code"&lt;/a&gt;). And
I found out that there are already quite some "foundation components"
available...&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://cpe.mitre.org"&gt;CPE&lt;/a&gt; is a structured way of naming software
    (vendor, title, version ...)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://oval.mitre.org"&gt;OVAL&lt;/a&gt; is a method for performing structured
    tests (like regular expression matches in text) for reporting
    purposes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Many more of these efforts are linked through the Mitre sites. The above
two are the most important ones though - it seems that it might be
possible to use OVAL to describe the tests I wanted for the POC.&lt;/p&gt;
&lt;p&gt;To be continued...&lt;/p&gt;</content><category term="Security"></category></entry></feed>