<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Simplicity is a form of art... - cloud</title><link href="https://blog.siphos.be/" rel="alternate"></link><link href="https://blog.siphos.be/tag/cloud/feed/atom.xml" rel="self"></link><id>https://blog.siphos.be/</id><updated>2021-11-08T20:00:00+01:00</updated><entry><title>Hybrid cloud can be very complex</title><link href="https://blog.siphos.be/2021/11/hybrid-cloud-can-be-very-complex/" rel="alternate"></link><published>2021-11-08T20:00:00+01:00</published><updated>2021-11-08T20:00:00+01:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-11-08:/2021/11/hybrid-cloud-can-be-very-complex/</id><summary type="html">&lt;p&gt;I am not an advocate for hybrid cloud architectures. Or at least, not the
definition for hybrid cloud that assumes one (cloud or on premise) environment
is just an extension of another (cloud or on premise) environment. While such
architectures seem to be simple and fruitful - you can easily add some capacity
in the other environment to handle burst load - they are a complex beast to
tame.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I am not an advocate for hybrid cloud architectures. Or at least, not the
definition for hybrid cloud that assumes one (cloud or on premise) environment
is just an extension of another (cloud or on premise) environment. While such
architectures seem to be simple and fruitful - you can easily add some capacity
in the other environment to handle burst load - they are a complex beast to
tame.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Hybrid cloud complexity starts with the definition&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first thing that I've already learned is not to use "hybrid cloud" without
defining what I mean. And if somebody else uses it (or a research article), I
will frantically try to get a definition on what the person or article implies
with the term.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/overview/what-is-hybrid-cloud-computing/"&gt;Microsoft&lt;/a&gt;
for instance defines hybrid cloud as "a computing environment that combines an
on-premises datacenter with a public cloud, allowing data and applications to
be shared between them."&lt;/p&gt;
&lt;p&gt;This definition isn't unambiguous. What does Microsoft mean with "sharing"? If
I expose an application and/or its data through APIs that are shielded and
independently managed in each environment, and allow for interaction between
those APIs, does that still entail a hybrid cloud architecture? Because if that
is the case, then I want to know what other cloud interaction architectures
Microsoft thinks exist besides hybrid cloud.&lt;/p&gt;
&lt;p&gt;I do think that the intention of Microsoft's definition is that the cloud
hosting environments are considered as "similar enough" to the on premise
environment, and managed in the same way (some cloud specifics
notwithstanding), as inspired by their claim that hybrid cloud allow
"businesses [to] use the cloud to instantly scale capacity up or down to handle
excess capacity" and that organizations using hybrid cloud architectures "are
able to use many of the same security mreasures that they use in their existing
on-premises infrastructure".&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.gartner.com/en/information-technology/glossary/hybrid-cloud-computing"&gt;Gartner&lt;/a&gt;
defines hybrid cloud computing as "policy-based and coordinated service
provisioning, use and management across a mixture of internal and external
cloud services." That doesn't narrow things down, and in &lt;a href="https://www.gartner.com/document/3956442"&gt;(paywalled) research
articles&lt;/a&gt;, Gartner does express that
"hybrid cloud is a vague term that does not allow enough granularity for
implementation planning by cloud and infrastructure professionals".&lt;/p&gt;
&lt;p&gt;&lt;a href="https://go.forrester.com/blogs/13-08-02-cloud_management_in_a_hybrid_cloud_world/"&gt;Forrester&lt;/a&gt;
follows a definition that is very generic, as "a cloud service connected to any
other corporate resource" makes it a hybrid cloud service. Regardless of how it
is infrastructurally or application-wise integrated.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.ibm.com/cloud/learn/hybrid-cloud"&gt;IBM&lt;/a&gt; declares hybrid cloud as
"integrates public cloud services, private cloud services and on-premises
infrastructure and provides orchestration, management and application
portability across all three. The result is a single, unified and flexible
distributed computing environment [...]"&lt;/p&gt;
&lt;p&gt;This definition does seem to imply an architecture that considers all hosting
environments as infrastructurally equal (as they see the sum of all
environments as a single, unified environment).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud"&gt;Wikipedia&lt;/a&gt;
mentions that hybrid cloud "is a composition of a public cloud and a private
environment [...] that remain distinct entities but are bound together,
offering the benefits of multiple deployment models." Such a definition leaves
the implementation details open, as it boils down to any architecture where you
mix such hosting environments.&lt;/p&gt;
&lt;p&gt;For me, a &lt;strong&gt;hybrid cloud on infrastructure level&lt;/strong&gt; implies that the different
environments are similarly or equally managed, using the same processes,
principles and most often even tooling, and that application teams have little
impact on where their application (or application components) are hosted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The promise of hybrid cloud towards business&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When business decision makers hear (or are confronted with) hybrid cloud, they
are often told that it a perfect way to deal with capacity management. Whereas
a pure on-premise deployment model requires you to purchase and deploy enough
capacity to deal with your maximum workload (and even more, if you need to
consider disaster recovery situations), a hybrid cloud could simply "add more
resources as needed, without requiring the application to be refactored for
cloud-native or cloud hosting".&lt;/p&gt;
&lt;p&gt;Let's make this more tangible with an example: a simple ticket sales service,
which consists out of a website (frontend) and an API (which is backend-alike).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ticket sales service overview" src="https://blog.siphos.be/images/202111/hybridcloud-ticketsales-overview.png"&gt;&lt;/p&gt;
&lt;p&gt;The company that manages this ticket sales application is currently fully
on-premise, with a simple deployment model where the front and backend are
hosted on a web application hosting cluster (which could be a Kubernetes
cluster), and the backend also uses a database.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ticket sales high level infrastructure" src="https://blog.siphos.be/images/202111/hybridcloud-ticketsales-hlinfra.png"&gt;&lt;/p&gt;
&lt;p&gt;Ticket sales are seasonally bound, and often ticket sales platforms are
services offered to the specific events. Suppose a major event wants to sell
its tickets through this ticket sale application, and you are afraid that the
website part will not be able to deal with the load, then you could use a
hybrid cloud setup to enable bursting on the front-end side.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ticket sales high level bursting" src="https://blog.siphos.be/images/202111/hybridcloud-ticketsales-burstfrontend.png"&gt;&lt;/p&gt;
&lt;p&gt;Of course, this is just one of many target architectures that might solve the
capacity challenge, and there is no reason to believe the API itself wouldn't
be overloaded as well. But let's stick to this simple example.&lt;/p&gt;
&lt;p&gt;From a business perspective, this all sounds very fun and promising. There
seems to be no initial investment needed, and the capacity of the cloud is
limitless, not?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Network investments needed for such hybrid cloud&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, as always, the devil is in the details. If we were to pursue this
architecture, we need to have the public cloud and the on premise environment
properly connected. You don't want to use regular Internet access, because the
intention is to see these environments as a single, unified environment, and
you don't open up your internal systems directly to the Internet either do you?&lt;/p&gt;
&lt;p&gt;So you need to architect the public cloud usage to be as private as possible,
and then connect that environment with your on premise network, preferably
through a high speed private link. Sure, you can use VPN over internet, but
with a private link you have more guarantees on the latency for instance, and
for many cloud environments such private link interactions are also bringing
benefits for data ingress/egress (cheaper for you). They also generally have
better SLAs (although larger environments will have very high internet-related
SLAs) and do not require the same security protection measures (like anti-DDoS
protection).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ticket sales network connectivity" src="https://blog.siphos.be/images/202111/hybridcloud-ticketsales-connectivity.png"&gt;&lt;/p&gt;
&lt;p&gt;In the design, we assume that the end users still first go through your on
premise environment, as the perimeter protections you have in place for
instance still need to apply. Perimeter protections are not just simple
firewall capabilities. It includes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;anti-DDoS measures&lt;/li&gt;
&lt;li&gt;context gathering for, and applying coarse-grained access controls&lt;/li&gt;
&lt;li&gt;intrusion detection and prevention&lt;/li&gt;
&lt;li&gt;anti-malware protection&lt;/li&gt;
&lt;li&gt;application attack prevention&lt;/li&gt;
&lt;li&gt;network traffic filtering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A perimeter is meant to act as a first line of defense. However, when
integrating networks from external sites, you still need some protection
measures applied (shown as external site protection in the diagram), as you are
handing off some ownership to other parties and thus want to have some
safeguards in place.&lt;/p&gt;
&lt;p&gt;Because we still have all traffic through the perimeter, burst loads can still
jeopardize the service offering itself. If the perimeter, internet line, or the
load balancer that spreads the load across the frontends is saturated, then
your service will go down. The hybrid cloud setup used in this example wont
help out here.&lt;/p&gt;
&lt;p&gt;Second, the high speed private link will need to be able to deal with not only
the load of the user to the frontend (and back), but also between the frontend
and backend. And if you were to support bursting the backend application to the
public cloud as well, then it needs to deal with the load between this
application and the database.&lt;/p&gt;
&lt;p&gt;The link is also often not something you set up yourself between you and the
public cloud. You will need intermediate parties to support this, as often this
first requires you to have private links to certain larger networks, and then
have this larger network set up a private link to the point of presence where
you want to 'attach' to that public cloud environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Management complexity rises with hybrid cloud&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The investments do not stop just at the network connectivity. You will need to
look into managing the web application (such as deployment and releases),
servers (bootstrapping, updating, maintaining), and other network areas.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hybrid cloud management complexity" src="https://blog.siphos.be/images/202111/hybridcloud-ticketsales-management.png"&gt;&lt;/p&gt;
&lt;p&gt;Let's start with the web application management. Your existing management
systems will now need to deal with the public cloud as well. Your application
needs to be deployed on multiple clusters, and you will need to reconfigure the
load balancers in front to know where these clusters are. Unlike the
pre-installed environments on premise, public cloud is more dynamic (you want
to use it for bursting after all), so the target IP addresses might change (or
you set up fixed IP addresses, but that costs money even when you don't use
them).&lt;/p&gt;
&lt;p&gt;You will need to deal with deployments that can succeed left and fail right, or
vice-versa. While this is not impossible to deal with, the current way of
working might not support that yet because, you know, you never had to deal
with it.&lt;/p&gt;
&lt;p&gt;What about tracking performance and user experience? Your application
management suite might not know about public cloud setups yet, and once
included, it might find that there is latency impact. But can you just use this
APM suite in the public cloud? Perhaps your company has a site license which
does not include other locations. Or it requires per-node licenses, and require
each node to be assigned a license for 30 days at least. In case of burst
situations, you might only have these systems up for a few hours, and with the
next action, these will be new nodes with new licenses.&lt;/p&gt;
&lt;p&gt;Also on the server management level you might find many obstacles. Your on
premise system might use a certain hypervisor integration (e.g. using VMware
vCenter API) which you don't have in the public cloud. So you need to adapt the
management system anyway, which means you need to develop your management
systems to create a hybrid cloud, rather than reap the benefits of hybrid cloud
directly.&lt;/p&gt;
&lt;p&gt;Your servers might use many control systems that have the same licensing issues
as mentioned earlier. Or they are latency-bound, causing either reachability
issues, or requiring you to adapt the infrastructure architecture of these
management systems to be aware of the public cloud.&lt;/p&gt;
&lt;p&gt;Also on network management level it isn't just about connectivity. Your
firewall management might not see the public cloud firewalls automatically (or
doesn't support it), or your current network design doesn't allow for the
bursting of network environments (subnets) in a sufficient dynamic manner.&lt;/p&gt;
&lt;p&gt;The more you consider this hybrid cloud situation, the more you find out that
you will need to revisit all management, support and control systems for this
setup. And you know what is hard to do in an IT environment? Reassessing &lt;em&gt;all&lt;/em&gt;
management, support and control systems. You are effectively redesigning your
entire IT environment, and that is exactly what the promise of "hybrid cloud"
wanted to take away. Or at least, the promise that is done to certain decision
makers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vendors know that it is complex (and are happy because of it)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most of the IT vendors that are related to the management, support and control
of your infrastructure, will say that management in hybrid cloud is hard: &lt;a href="https://www.redhat.com/en/blog/operating-hybrid-architecture-and-managing-complexity"&gt;Red
Hat&lt;/a&gt;
for instance mentions in its container-related article that "Saying that
Kubernetes makes it possible to build a cross-environment management layer
doesn't mean it's easy". &lt;a href="https://blogs.arubanetworks.com/solutions/easing-the-complexity-of-hybrid-cloud/"&gt;Aruba
Networks&lt;/a&gt;
(part of PHE) mentions that "the major drawback is complex management of these
platforms". Consulting firms concur as well, with for instance David Linthicum,
Chief Cloud Strategy Officer of Deloitte Consulting, mentioning in &lt;a href="https://techbeacon.com/enterprise-it/4-things-you-need-know-about-managing-complex-hybrid-clouds"&gt;4 things
you need to know about managing complex hybrid
clouds&lt;/a&gt;
that "hybrid clouds are usually complex, hard to build, and hard to manage".&lt;/p&gt;
&lt;p&gt;Of course, IT vendors will be happy to tell you that it is hard (and for once I
concur), because they will then follow up with how their shiny tool supports
hybrid cloud much better than your existing ones. IT vendors know that an
infrastructural hybrid cloud means a redesign of (many parts of) your IT
architecture, so there is big money involved.&lt;/p&gt;
&lt;p&gt;Hence, it is important that hybrid cloud endeavours are assessed completely,
and that your business decision makers hold off with the decision until the
full scope of this exercise is known (or at least, you have a decent ballpark
estimate on the impact, not just financially, but also time-to-market). &lt;/p&gt;
&lt;p&gt;So, what are all the areas you need to consider? That's difficult to state, but
hopefully the list below can help you out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How are your servers bootstrapped (initial deployment)? Can this interact
  with the cloud APIs to do the same in the cloud, or will you need to adapt
  your processes?&lt;/li&gt;
&lt;li&gt;Once your server is bootstrapped, how do you add software, libraries and
  other artefacts to it?&lt;/li&gt;
&lt;li&gt;What security services do you need on your systems? Anti-malware? Behavior
  analytics? Intrusion detection and prevention? Privileged access management
  utilities? &lt;/li&gt;
&lt;li&gt;How do your engineers and administrators follow-up on the systems? Monitoring
  approaches? Application performance management? Trace capabilities? Logging?&lt;/li&gt;
&lt;li&gt;Are there any control systems in place that manage the infrastructure? Are
  these control systems latency-sensitive?&lt;/li&gt;
&lt;li&gt;How do you deal with applicative releases? If you have CI/CD infrastructure
  in place, how would it deal with a burst environment? Does it have any
  dynamical detection capabilities?&lt;/li&gt;
&lt;li&gt;Can your support systems deal with more ephemeral infrastructure (capacity that
  is added for a few hours and then removed again)?&lt;/li&gt;
&lt;li&gt;Can your processes deal with ephemeral infrastructure?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perhaps your current environment is already capable of dealing with such hybrid
clouds. While the situations I am confronted with at work support my view that
we need to apply a different 'hybrid' approach than the 'seamless
infrastructure' one (I like to see the environments progress more
independently, gradually move towards a &lt;a href="https://www.nist.gov/publications/zero-trust-architecture"&gt;zero
trust&lt;/a&gt; model), I do
believe that such hybrid cloud setups can work in certain situations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions and feedback&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you do come across an intention declaration to move to a hybrid cloud (which
follows the infrastructural 'seamless' setup as implied in this post), make
sure you inform the stakeholders of the consequences. Show that a majority of
management, support and control systels are not designed nor capable of dealing
with this bursting out-of-the-box, and that this will require a significant IT
investment which might not be visible to the decision maker currently.&lt;/p&gt;
&lt;p&gt;If you have the time and resources, try to already build up the arguments for
it by focusing on your management, support and control systems, validating how
ready they would be, and what types of investments would be needed. Compare
this with a setup where the infrastructure side of the hybrid cloud still uses
separate environments, and where you manage each environment using the
strengths of that environment.&lt;/p&gt;
&lt;p&gt;Feedback? Comments? Don't hesitate to &lt;a href="mailto:sven.vermeulen@siphos.be"&gt;drop me an
email&lt;/a&gt;, or join the &lt;a href="https://twitter.com/infrainsight/status/1457745672304840709"&gt;discussion on
Twitter&lt;/a&gt;.&lt;/p&gt;</content><category term="Architecture"></category><category term="hybrid"></category><category term="cloud"></category></entry><entry><title>Scale is a cloud threat</title><link href="https://blog.siphos.be/2021/09/scale-is-a-cloud-threat/" rel="alternate"></link><published>2021-09-28T17:00:00+02:00</published><updated>2021-09-28T17:00:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-09-28:/2021/09/scale-is-a-cloud-threat/</id><summary type="html">&lt;p&gt;Not that long ago, a vulnerability was found in &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/"&gt;Microsoft Azure Cosmos
DB&lt;/a&gt;, a NoSQL SaaS database
within the Microsoft Azure cloud. The vulnerability, which is dubbed
&lt;a href="https://chaosdb.wiz.io/"&gt;ChaosDB&lt;/a&gt; by the &lt;a href="https://twitter.com/wiz_io"&gt;Wiz Research
Team&lt;/a&gt;, uses a vulnerability or misconfiguration in
the &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks"&gt;Jupyter Notebook
feature&lt;/a&gt;
within Cosmos DB. This vulnerability allowed an attacker to gain access to
other's Cosmos DB credentials. Not long thereafter, a second vulnerability
dubbed
&lt;a href="https://www.wiz.io/blog/omigod-critical-vulnerabilities-in-omi-azure"&gt;OMIGOD&lt;/a&gt;
showed that cloud security is not as simple as some vendors like you to believe.&lt;/p&gt;
&lt;p&gt;These vulnerabilities are a good example of how scale is a cloud threat. Companies
that do not have enough experience with public cloud might not assume this in
their threat models.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Not that long ago, a vulnerability was found in &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/"&gt;Microsoft Azure Cosmos
DB&lt;/a&gt;, a NoSQL SaaS database
within the Microsoft Azure cloud. The vulnerability, which is dubbed
&lt;a href="https://chaosdb.wiz.io/"&gt;ChaosDB&lt;/a&gt; by the &lt;a href="https://twitter.com/wiz_io"&gt;Wiz Research
Team&lt;/a&gt;, uses a vulnerability or misconfiguration in
the &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks"&gt;Jupyter Notebook
feature&lt;/a&gt;
within Cosmos DB. This vulnerability allowed an attacker to gain access to
other's Cosmos DB credentials. Not long thereafter, a second vulnerability
dubbed
&lt;a href="https://www.wiz.io/blog/omigod-critical-vulnerabilities-in-omi-azure"&gt;OMIGOD&lt;/a&gt;
showed that cloud security is not as simple as some vendors like you to believe.&lt;/p&gt;
&lt;p&gt;These vulnerabilities are a good example of how scale is a cloud threat. Companies
that do not have enough experience with public cloud might not assume this in
their threat models.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Perimeter controls and isolation domains&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before tackling the scale of a cloud service, let's consider an on premise
service. Services that run on premise for a company are often built up
specifically for that company, and have no relationship with other customers of
the same service. Taking the NoSQL example, companies can perfectly run NoSQL
database services on premise that have no internet presence. Moreover, these
services are also often not directly exposed to the internet.&lt;/p&gt;
&lt;p&gt;Running services within your own premises reduces the likelihood that attackers
exploit vulnerabilities of that service. Attackers that are not particularly
eyeballing your company might not know you have that service on premise. Even if
they do know, having proper protections in place should prevent direct access to
those services.&lt;/p&gt;
&lt;p&gt;&lt;img alt="On premise services" src="https://blog.siphos.be/images/202109/cloud-scale-on-premise.png"&gt;&lt;/p&gt;
&lt;p&gt;Some situations do require services to expose themselves to the internet. This
exposure increases the &lt;em&gt;attack surface&lt;/em&gt; for the service significantly.
However, these services are still part of a rather isolated deployment that I
call an &lt;strong&gt;isolation domain&lt;/strong&gt;: a logical aggregation of services that share
one or more integrations and interactions, broadening the scope of
potential vulnerabilities and misconfigurations.&lt;/p&gt;
&lt;p&gt;Separate isolation domains imply that vulnerabilities or misconfigurations
that rely on information from the domain cannot spread. This is not the same as
separate deployments or environments, as those often do share certain
integrations. For instance, all NoSQL databases within a company might use that
company's identity provider for federated authentication. But NoSQL databases
exposed to the internet from two completely different companies are often in
separate isolation domains.&lt;/p&gt;
&lt;p&gt;The Cosmos DB vulnerability exploited the fact that all Cosmos DB deployments
are part of the same isolation domain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perimeter and isolation domain challenges for public cloud&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Public cloud platform services, like Cosmos DB, are often lacking these two
attributes: they have different perimeter protections in place, and share the
same isolation domain.&lt;/p&gt;
&lt;p&gt;I do not want to imply that public cloud providers do not provide perimeter
protections against their services. They most definitely do, but the scope of
the perimeter is different from what a company would apply. Whereas a company
gains some measurable security by hiding services or ensuring those services are
not reachable from unauthorized contexts, public cloud platform services need to
be easily accessible for the public cloud to become successful. Security
paradigms like &lt;a href="https://www.nist.gov/publications/zero-trust-architecture"&gt;Zero
Trust&lt;/a&gt; are needed to
raise the security posture of these services. Companies that are building
solutions within the public cloud will find that this requires a different
mindset, and that these environments are not comparable with the traditional
on-premise designs.&lt;/p&gt;
&lt;p&gt;For the Cosmos DB vulnerability, the FAQ mentions that instances that are not
internet facing are still somewhat impacted (as the credentials could have been
leaked) but accessing the database (by using the credentials) will not be
possible without additional vulnerabilities or misconfigurations being
addressed. This is comparable to an administrator password leakage for your
properly isolated on-premise database: while your database might not be
immediately accessible by attackers, you're still going to change the password
as soon as possible to prevent it from being used in later attacks.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Public cloud platform services" src="https://blog.siphos.be/images/202109/cloud-scale-public-cloud.png"&gt;&lt;/p&gt;
&lt;p&gt;The isolation domain is a bigger hurdle to take though, as this is almost always
by design. Platform services always share interactions or integrations across
all the customers of the public cloud. Even though you have your own logical
deployment (or even ask for your own physical deployment), the main interface to
access your service is shared. The service you use to authenticate users or
systems is shared (even when it will eventually use federated authentication to
your own identity provider, the initial service is still the same).&lt;/p&gt;
&lt;p&gt;This shared isolation domain makes each public cloud service a fantastic target
for attackers (and luckily also security researchers). Exploits might not just
reveal data or insights from one customer, but from thousands of customers all
over the world. And the bigger the cloud provider, the bigger the impact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shared control planes also imply sharing the isolation domain&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This problem of using a shared isolation domain is not restricted to public
cloud platform services only. Even on premise deployments that use a public
control plane are taking part in the same isolation domain as all other
customers of the same service.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Control plane also implies sharing isolation domains" src="https://blog.siphos.be/images/202109/cloud-scale-control-plane.png"&gt;&lt;/p&gt;
&lt;p&gt;Suppose you set up a big data platform on premise, but use your vendor's SaaS
service as a control plane to manage this big data platform. This SaaS service
is also used by the other customers of that vendor, so your deployment is part
of the same isolation domain.&lt;/p&gt;
&lt;p&gt;While such setups have benefits (such as using the same control plane for
multiple deployments across different environments and even hosting setups, and
not having to manage and maintain the control services yourself) they do
increase the risk exposure in a not dissimilar fashion from the pure public
cloud services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to tackle these concerns&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Knowing about these increased risks (reachability/exposure, and the shared
isolation domain) is the foremost important part that this article wants to
address. Once these risks are considered, companies can start taking
precautions. I've mentioned the zero trust model as a way to address the
reachability/exposure risk. To address the shared isolation domain, reducing the
impact of a successful exploit can be done through proper architecture and
design that uses the "it is not if, but when" principle for cyberattacks.&lt;/p&gt;
&lt;p&gt;For instance, the data within the databases can use application-level encryption
(meaning the encryption is not done by or through the database, but by the
front-end application that interacts with the database) to reduce the impact of
data leakage through such vulnerabilities. Proper data governance processes
should also be in place to remove any data that is no longer needed on that
database. Active security validations on log data should exist to detect
deviating access patterns, and access controls should be in place to prevent
unauthorized access even from succesfully authenticated users or systems.&lt;/p&gt;
&lt;p&gt;In the Cosmos DB case, the vulnerability was possible through a selectable
feature: deployments that do not have the Jupyter Notebook feature active would
not leak the credentials. Hence, proper configuration management of services and
disabling features that are not going to be used is paramount for cloud
services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If architects are sufficiently aware of the added risks of public cloud
services, they can properly balance these risks against the benefits of the
public cloud, and make appropriate adjustments to the architecture and design of
the solutions. The main challenge here is to make sure this awareness is raised,
and that this awareness is not only reaching the architects, but also the
engineers and other stakeholders. If not, architects risk that they will be seen
as "innovation inhibitors" if they would recommend changes and improvements to
tackle these risks.&lt;/p&gt;
&lt;p&gt;Feedback? Comments? Don't hesitate to &lt;a href="mailto:sven.vermeulen@siphos.be"&gt;drop me an
email&lt;/a&gt;, or join the &lt;a href="https://twitter.com/infrainsight/status/1442867880639401989"&gt;discussion on
Twitter&lt;/a&gt;.&lt;/p&gt;</content><category term="Architecture"></category><category term="cloud"></category><category term="vulnerability"></category></entry><entry><title>Disaster recovery in the public cloud</title><link href="https://blog.siphos.be/2021/07/disaster-recovery-in-the-public-cloud/" rel="alternate"></link><published>2021-07-30T20:00:00+02:00</published><updated>2021-07-30T20:00:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-07-30:/2021/07/disaster-recovery-in-the-public-cloud/</id><summary type="html">&lt;p&gt;The public cloud is a different beast than an on-premise environment, and that
also reflects itself on how we (should) look at the processes that are
actively steering infrastructure designs and architecture. One of these
is the business continuity, severe incident handling, and the
hopefully-never-to-occur disaster recovery. When building up procedures
for handling disasters (&lt;a href="https://en.wikipedia.org/wiki/Disaster_recovery"&gt;DRP = Disaster Recovery Procedure or Disaster 
Recover Planning&lt;/a&gt;),
it is important to keep in mind what these are about.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;The public cloud is a different beast than an on-premise environment, and that
also reflects itself on how we (should) look at the processes that are
actively steering infrastructure designs and architecture. One of these
is the business continuity, severe incident handling, and the
hopefully-never-to-occur disaster recovery. When building up procedures
for handling disasters (&lt;a href="https://en.wikipedia.org/wiki/Disaster_recovery"&gt;DRP = Disaster Recovery Procedure or Disaster 
Recover Planning&lt;/a&gt;),
it is important to keep in mind what these are about.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;What is a disaster&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Disasters are major incidents that have wide-ranging consequences to the
regular operations of the business. What entails a disaster can be different
between organizations, although they are commonly tied to the size of the
infrastructure and the organizational and infrastructural maturity. I'll get
back to the size dependency later when covering public cloud.&lt;/p&gt;
&lt;p&gt;A small organization that only has a few systems can declare a
disaster when all those systems are unreachable because their network
provider's line is interrupted. A larger organization probably has
redundancy of the network in place to mitigate that threat. And even
without the redundancy, organizations might just not depend that much
on those services.&lt;/p&gt;
&lt;p&gt;The larger the environment becomes though, the more the business depends
on the well-being of the services. And while I can only hope that high
availability, resiliency and appropriate redundancy are taken into account
as well, there are always threats that could jeopardize the availability
of services.&lt;/p&gt;
&lt;p&gt;When the problem at hand is specific to one or a manageable set of services,
then taking appropriate action to remediate that threat is generally not a
disaster. It can be a severe incident, but in general it is taken up
by the organization as an incident with a sufficiently small yet
efficient and well organized coordination: the teams involved are 
low in numbers, and the coordination can be done accurately.&lt;/p&gt;
&lt;p&gt;However, when the problem is significant or has a very wide scope, then
depending on the standard incident coordination will be insufficient. You
need to coordinate across too many teams, make sure communication is done
correctly, business is continuously involved/consulted, and most of all - 
you want to make sure that the organization doesn't independently try
to resolve issues when they don't have a full view on the situation
themselves.&lt;/p&gt;
&lt;p&gt;The latter is a major reason in my opinion why a DRP is so important
to have (the plan/procedure, not an actual disaster). If there is no
proper, well-aligned plan of action, teams will try to get in touch
with other teams, polluting communication and only getting incomplete
information. They might take action that other teams should know about
(but won't) or are heavily impacted by (e.g. because they are at that
time trying to do activities themselves). It can make the situation
much worse.&lt;/p&gt;
&lt;p&gt;Because we have to make a distinction between incident management
and disaster management, an organization has to formally declare
a problem as a disaster, and communicate that singular fact ("we
are now in disaster mode") so that all teams know how to respond: 
according to the Disaster Recovery Plan (DRP).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disasters are not just 'force majeure'&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Disasters aren't extraordinary events or circumstances beyond the
control of the organization. Depending on the business needs, you
might very well take precautionary actions against situations you've
never encountered before and will never encounter. We've recently had
a disastrous weather in Belgium (and other countries in Western Europe)
with floods happening in large areas. But that doesn't mean that
for an organization a flood event will trigger a disaster declaration
within a company (the disastrous weather was a disaster from a
human side, with several dozen deaths and millions of damage, so it
feels somewhat incorrect to consider the threat from a theoretical
standpoint here).&lt;/p&gt;
&lt;p&gt;If you're located in a flood-sensitive environment, you can still take
precautionary actions and assess what to do in case of a flood event. 
Depending on the actions taken, a flood event (threat) will not manifest
into availability concerns, data and infrastructure destruction, people
unavailability, etc. It is only when the threat itself turns into an
unforeseen (or non-remediated) situation that we speak of a disaster.&lt;/p&gt;
&lt;p&gt;This is why disasters depend on organizations, and how risk averse
the organization (and business) is. Some businesses might not want to
take precautionary actions against situations that in the past only
occur once every 100 years, especially if the investment they would
have to do is too significant compared to the losses they might have.&lt;/p&gt;
&lt;p&gt;Common disaster threats (sometimes also called catastrophic events)
that I'm used to evaluate from an infrastructure point of view, with a
company that has four strategic data centers, multiple headquarter
locations and a high risk averse setting (considering the financial
market it plays in) are cyberattacks, local but significant infrastructure
disruptions (data center failures or destruction), people-oriented
threats (targetting key personnel), critical provider outages,
disgruntled employees, and so forth. Searching for risk matrices
online can give you some interesting pointers, such as the European
Commission's &lt;a href="https://ec.europa.eu/echo/sites/default/files/swd_2017_176_overview_of_risks_2.pdf"&gt;Overview of Natural and Man-made Disaster Risks the
European Union may
face&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Public cloud related events&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In case of public cloud, the catastrophic events that might occur are
different, and it would be wrong to just consider the same events and
with the same action plan. A prime example, and the one I really want
people to focus on, is regional outages.&lt;/p&gt;
&lt;p&gt;If your current company considers region-wide failures (for
instance because you have two data centers but within the same
region) more from a reactive point of view rather than preventive
(e.g. the DRP in case of region-wide failures is to approach
the reconstruction within the region whenever possible, rather
than fail over to a different region), it might feel the same about
public cloud region failures.&lt;/p&gt;
&lt;p&gt;That would be wrong though. Whereas it is likely that a region-wide
failure for a company is not going to happen in its lifetime, a public
cloud provider is so much more massive in size, that the likelihood
of region-wide failures is higher. If you do a quick search for
region-wide failures in AWS or Azure, you'll find plenty of examples.
And while the failures themselves might be considered 'incidents' from
the public cloud provider point of view, they might be disasters for
the companies/customers that rely on them.&lt;/p&gt;
&lt;p&gt;For me, tackling disaster recovery when dealing with public cloud strongly
focuses on region failures and (coordinated) recovery from region failures.
Beyond region failures, I also strongly recommend to look into the dependencies
that the public cloud consumption has with services outside of the public cloud.
Some of these dependencies might also play a role in certain catastrophic
events. Say that you depend on Azure AD for your authentication and
authorization, and Microsoft is suddenly facing not just a world-wide
Azure AD outage, but also has to explain to you that they cannot restore its
data.&lt;/p&gt;
&lt;p&gt;Preparing for disasters is about preparing for multiple possible catastrophic
events, and in case of public cloud, you're required to think at massive scales.
And that includes designing for region-wide failures as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Impact of public cloud disasters to the organization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Generally, if your organization has a decent maturity in dealing with disaster
recovery planning, they will be using Service Level Agreements with the
business to help decide what to do in case of disasters. Important
non-functionals that are included here are RTO (Recovery Time Objective), RPO
(Recovery Point Objective), and MTD (Maximum Tolerable Downtime). There are
others possibly listed in the SLA as well, but let me focus on these three.
If you want to learn more about contigency planning in general, I recommend
to go through the &lt;a href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-34r1.pdf"&gt;NIST Special Publication 800-34 Rev.1, "Contingency Planning
Guide for Federal Informatino
Systems"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With the RTO, we represent the time it is allowed to take to recover a service
to the point that it functions again. This might include with reduced capacity
or performance degradation. The RTO can be expressed in hours, days, weeks
or other arbitrary value. It is a disaster-oriented value, not availability!
As long as no disaster is declared, the RTO is not considered.&lt;/p&gt;
&lt;p&gt;The RPO identifies how much data loss is acceptable by the business in case of
a disaster. Again, this is disaster-oriented: the business can very well take
extra-ordinary steps to ensure full transactional consistency outside of 
disaster situations, yet allow for a "previous day" RPO in case of a disaster.&lt;/p&gt;
&lt;p&gt;The MTD is most often declared not on a single service, but at business service
level, and explains how long unavailability of that service is tolerated before
it seriously impacts the survivability of the business. It is related to the
RTO, as most services will have an RTO that is more strict/lower value than the
overall MTD, whereas the MTD is near non-negotiable.&lt;/p&gt;
&lt;p&gt;Now, what does public cloud disasters have to do with this? Well, in theory
nothing, as this model and process of capturing business requirements is quite
sensible and maps out perfectly as well. However (and here's the culprit),
an organization that sets up new services on a frequent basis might get
accustomed to certain values, and these values might not be as easy to approach
in a public cloud environment. Furthermore, the organization might not be
accustomed to different disaster scenario's for the SLA: having different sets
of RTO/RPO depending on the category of disaster.&lt;/p&gt;
&lt;p&gt;Let's get back to the region-wide disasters. A company might have decided not
to have region-wide proactive measures in place, and fixate their SLA
non-functionals on local disasters: a data center failure is considered a threat
that still requires proactive measures, whereas regional failures are treated
differently.  The organization decides to only have one SLA set defined, and
includes RTO and RPO values based on the current, local threat matrix. They
might decide that a majority of applications or services has a RPO of "last
transaction", meaning the data has to be fully restored at the latest situation
in case of a disaster.&lt;/p&gt;
&lt;p&gt;This generally implies synchronous replication as an infrastructural
solution. If the organization is used to having this method available (for
instance through SAN replication, cluster technologies, database recovery,
etc.) then they won't sweat at all if the next dozen services all require
the same RPO.&lt;/p&gt;
&lt;p&gt;But now comes the public cloud, and a strong point of attention is region-wide
failures. Doing synchronous replication across regions is not a proper tactic
(as it implies significant performance degradation) and especially not sensible
to do at the same scale as with local replication (e.g. between availability
zones in the same region). Now you have to tell your business that this RPO
value is not easily attainable in the public cloud. The public cloud, which
solves all the wonders in the world. The public cloud, which has more maturity
on operations than your own company. Yet you can't deliver the same SLA?&lt;/p&gt;
&lt;p&gt;Apples and pears. The disasters are different, so your offering might be
different. Of course, you should explain that your 'on premise' disaster
scenarios do not include region-wide failures, and that if you include
the same scenarios for 'on premise' that that RPO value would not be
attainable on premise either.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The public cloud provides many capabilities, and has to deal with a
significantly larger environment than companies are used to. This also means
that disasters that are considered 'extremely unlikely' are now 'likely' (given
the massive scale of the public cloud), and that the threats you have to
consider while dealing with disaster recovery have to be re-visited for public
cloud enabled scenarios.&lt;/p&gt;
&lt;p&gt;My recommendation is to tackle the disaster-oriented non-functional requirements
by categorizing the disasters and having different requirements based on the
disaster at hand. Mature your cloud endeavours so that regional outages
are not a problem anymore (moving them away from the 'disaster' board), and 
properly map all dependencies you have through the public cloud exercises so
that you can build up a good view on what possible threats exist that would
require a well-coordinated approach to tackle the event.&lt;/p&gt;</content><category term="Architecture"></category><category term="architecture"></category><category term="cloud"></category><category term="DRP"></category></entry><entry><title>Not sure if TOSCA will grow further</title><link href="https://blog.siphos.be/2021/06/not-sure-if-TOSCA-will-grow-further/" rel="alternate"></link><published>2021-06-30T14:30:00+02:00</published><updated>2021-06-30T14:30:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-06-30:/2021/06/not-sure-if-TOSCA-will-grow-further/</id><summary type="html">&lt;p&gt;TOSCA is an OASIS open standard, and is an abbreviation for &lt;em&gt;Topology and
Orchestration Specification for Cloud Applications&lt;/em&gt;. It provides a
domain-specific language to describe how an application should be deployed
in the cloud (the topology), which and how many resources it needs, as well
as tasks to run when certain events occur (the orchestration). When I
initially came across this standard, I was (and still am) interested
in how far this goes. The promise of declaring an application (and even
bundling the necessary application artefacts) within a single asset and
then using this asset to deploy on whatever cloud is very appealing to
an architect. Especially in organizations that have a multi-cloud
strategy.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;TOSCA is an OASIS open standard, and is an abbreviation for &lt;em&gt;Topology and
Orchestration Specification for Cloud Applications&lt;/em&gt;. It provides a
domain-specific language to describe how an application should be deployed
in the cloud (the topology), which and how many resources it needs, as well
as tasks to run when certain events occur (the orchestration). When I
initially came across this standard, I was (and still am) interested
in how far this goes. The promise of declaring an application (and even
bundling the necessary application artefacts) within a single asset and
then using this asset to deploy on whatever cloud is very appealing to
an architect. Especially in organizations that have a multi-cloud
strategy.&lt;/p&gt;


&lt;p&gt;But while I do see some adoption of TOSCA, I get the feeling that it is
struggling with its position against the various infrastructure-as-code
(IaC) frameworks that are out there. While many of these frameworks do
not inherently support the abstraction that TOSCA has, it is not all that
hard to apply similar principles and use those frameworks to facilitate
multi-cloud deployments.&lt;/p&gt;
&lt;p&gt;Before considering the infrastructural value of TOSCA further, let's
see what TOSCA is about first.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simplifying and abstracting cloud deployments&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TOSCA offers a model where you can declare how an application should be
hosted in the cloud, or in a cloud-native environment (like a Kubernetes
cluster). For instance, you might want to describe a certain document
management system, which has a web application front-end deployed on 
a farm of web application servers with a load balancer in front of it,
a backend processing system, a database system and a document storage
system. With TOSCA, you can define these structural elements with their
resource requirements.&lt;/p&gt;
&lt;p&gt;For instance, for the database system, we could declare that it has to
be a PostgreSQL database system with a certain administration password,
and within the database system we define two databases with their
own user roles:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;topology_template:
  ...
  node_templates:
    db_server:
      type: tosca.nodes.Compute
      ...
    postgresql:
      type: tosca.nodes.DBMS.PostgreSQL
      properties:
        root_password: &amp;quot;...&amp;quot;
      requirements:
        host: db_server
    db_filemeta:
      type: tosca.nodes.Database.PostgreSQL
      properties:
        name: db_filemeta
        user: fmusr
        password: &amp;quot;...&amp;quot;
      artifacts:
        db_content:
          file: files/file_server_metadata.txt
          type: tosca.artifacts.File
      requirements:
        - host: postgresql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The parameters can, and should be further parameterized. TOSCA supports
declaring inputs that are provided upon deployment so you can safely
publicize the TOSCA structure without putting passwords in there
for instance. Furthermore, TOSCA allows you to add scripts to execute
when a resource is created, which is a common requirement for database
systems.&lt;/p&gt;
&lt;p&gt;But that's not all. Within TOSCA, you then further define the relationship
between the different systems (nodes), including connectivity requirements.
Connections can then be further aligned with virtual networks to model
the network design of the application.&lt;/p&gt;
&lt;p&gt;One of the major benefits of TOSCA is that it also provides abstraction on
the requirements. While the above example explicitly pushes for a PostgreSQL
database hosted on a specific compute server, we could also declare that we
need a database management system, or for the network part we need firewall
capabilities. The TOSCA interpreter, when mapping the model to the target
cloud environment, can then either suggest or pick the technology service
itself. The TOSCA model can then have different actions depending on the
selected technology. For the database for instance, it would have different
deployment scripts.&lt;/p&gt;
&lt;p&gt;The last major benefit that I would like to point out are the workflow
and policy capabilities of TOSCA. You can declare how for instance a 
backup process should look like, or how to cleanly stop and start the
application. You can even model how a rolling upgrade of the application
or database could be handled.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is not just theoretical&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Standards can often be purely theoretical, with one or a few reference
implementations out there. That is not the case with TOSCA. While reading
up on TOSCA, it became clear that it has a strong focus on Network
Functions Virtualization (NFV), a term used to denote the shift
from appliance-driven networking capabilities towards an environment
that has a multitude of solutions running in virtual environments, and
where the infrastructure adopts to this virtualized situation with
(for network) virtual routers, firewalls, etc. Another standards body,
namely the European Telecommunications Standards Institute (ETSI), seems
to be the driving force behind the NFV architecture.&lt;/p&gt;
&lt;p&gt;TOSCA has a simple profile for NFV, which aligns with ETSI's NFV and 
ensures that TOSCA parsers that support this profile can easily be used
to set up and manage solutions in virtualized environments (and thus
also cloud environments). The amount of online information about TOSCA
with respect to the NFV side is large, although still in my opinion
strongly vendor-oriented (products that support TOSCA) and standards-oriented
(talks about how well it fits). On TOSCA's &lt;a href="https://www.oasis-open.org/tosca-implementation-stories/"&gt;implementation stories&lt;/a&gt;
page, two of the three non-vendor stories are within the telco industry.&lt;/p&gt;
&lt;p&gt;There are a few vendors that heavily promote
TOSCA: &lt;a href="https://cloudify.co/"&gt;Cloudify&lt;/a&gt; and &lt;a href="https://designer.otc-service.com"&gt;Ubicity&lt;/a&gt;
offer multi-cloud orchestrators that are TOSCA-based. Many vendors, 
including the incumbent network technology vendors like Cisco and Nokia,
embrace TOSCA NFV. But most information from practical TOSCA usage out
there is in open source solutions. The list of &lt;a href="https://github.com/oasis-open/tosca-community-contributions/wiki/Known-TOSCA-Implementations"&gt;known TOSCA implementations&lt;/a&gt;
mentions plenty of open source products. One of the solutions that I
am considering of playing around with is &lt;a href="https://turandot.puccini.cloud/"&gt;turandot&lt;/a&gt;,
which uses TOSCA to compose and orchestrate Kubernetes workloads.&lt;/p&gt;
&lt;p&gt;As an infrastructure architect, TOSCA could be a nice way of putting
initial designs into practice: after designing solutions in a language
like ArchiMate, which is in general not 'executable', the next step could
be to move the deployment specifications into TOSCA and have the next
phases of the project use and enhance the TOSCA definition. But that
easily brings me to what I consider to be shortcomings of the current
situation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inhibitors for growth potential&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are a number of issues I have with the current state of TOSCA.&lt;/p&gt;
&lt;p&gt;TOSCA's ecosystem &lt;em&gt;seems&lt;/em&gt; to be lacking sufficient visualization support.
I did come across &lt;a href="https://projects.eclipse.org/projects/soa.winery"&gt;Winery&lt;/a&gt;
but that seems to be it. I would really like to see a solution that reads
TOSCA and generates an architectural overview. For instance, for the
example I started this blog with, something like the following:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Visualization of a deployment" src="https://blog.siphos.be/images/202106/tosca-archimate.png"&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, my impression is that TOSCA is strongly and mostly Infrastructure
as a Service (IaaS) oriented. The company I currently work for strongly
focuses on platform services, managed cloud services rather than the
more traditional infrastructure services where we would still have to do
the blunt of the management ourselves. Can TOSCA still play a role
in solutions that are fully using platform services? Perhaps the answer
here is "no", as those managed services are often very cloud-vendor specific,
but that isn't always the case, and can often also be tackled using the
abstraction and implementation specifics that TOSCA supports.&lt;/p&gt;
&lt;p&gt;I also have to rely too much on impressions. While the TOSCA ecosystem
has plenty of open source solutions out there, I find it hard to get
tangible examples: TOSCA definitions of larger-scale definitions that
not only show an initial setup, but are actively maintained to show
maintenance evolution of the solution. If TOSCA is so great for vendors
to have a cloud-independent approach, why do I find it hard to find
vendors that expose TOSCA files? If the adoption of TOSCA stops
at the standards bodies and too few vendors, then it is not likely
to grow much further.&lt;/p&gt;
&lt;p&gt;TOSCA orchestration engines often are in direct competition with
general IaC orchestration like Terraform. Cloudify has a post that
&lt;a href="https://cloudify.co/blog/terraform-vs-cloudify/"&gt;compares Terraform with their solution&lt;/a&gt;
but doesn't look into how Terraform is generally used in CI/CD
processes that join Terraform with the other services that create a
decent end-to-end orchestration for cloud deployments. For Kubernetes,
it competes with Helm and the likes - not fully, as TOSCA has other 
benefits of course, but if you compare how quickly Helm is taking
the lead in Kubernetes you can understand the struggle that TOSCA in
my opinion has.&lt;/p&gt;
&lt;p&gt;Another inhibitor is TOSCA's name. If you search for information on
TOSCA, you need to exclude &lt;a href="https://www.tricentis.com/resources/tricentis-tosca-overview/"&gt;Tricentis'&lt;/a&gt;
continuous testing platform, the &lt;a href="https://en.wikipedia.org/wiki/Tosca"&gt;1900's Opera&lt;/a&gt;,
and several other projects, films, and other entities that use the same
name. You'll need to explicitly mention OASIS and/or cloud as well if
you want to find decent articles about TOSCA, knowing well that there
can be pages out there that are missed because of it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While I appreciate the value TOSCA brings, I feel that it might not grow
to its fullest potential. I hope to be wrong of course, and I would
like to see big vendors publish their reference architecture TOSCA material
so that large-scale solutions are shown to be manageable using TOSCA and
that solution architects do not need to reinvent the wheel over and
over again, as well as link architecture with the more operations
side of things.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To learn more about TOSCA, there are a few resources that I would recommend
here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=tosca"&gt;OASIS TOSCA Technical Committee&lt;/a&gt;
  has a number of resources linked. The &lt;a href="https://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.3/os/TOSCA-Simple-Profile-YAML-v1.3-os.pdf"&gt;TOSCA Simple Profile in YAML Version 1.3&lt;/a&gt;
  PDF is a good read which gradually explains the structure of a TOSCA YAML
  file with plenty of examples.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.etsi.org/technologies/nfv"&gt;Network Functions Virtualisation (NFV)&lt;/a&gt;
  is the ETSI site on NFV. Given the focus on NFV that I find around when
  looking at TOSCA (and is even referenced on this page) understanding what
  NFV is about clarifies a bit more how valuable TOSCA is/can be in this
  environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=NHYRESmE6uA"&gt;OCB: AMA on TOSCA the Topology and Orchestration Specification for Cloud Applications - Tal Liron&lt;/a&gt;
  is an hour-long briefing that covers TOSCA not only in theory but also applies
  it in practice, and covers some of the new features that are coming up.&lt;/li&gt;
&lt;/ul&gt;</content><category term="Architecture"></category><category term="architecture"></category><category term="cloud"></category><category term="TOSCA"></category><category term="OASIS"></category><category term="topology"></category><category term="orchestration"></category><category term="infrastructure"></category><category term="IaC"></category><category term="NFV"></category></entry><entry><title>Integrating or customizing SaaS within your own cloud environment</title><link href="https://blog.siphos.be/2021/06/integrating-or-customizing-SaaS-within-your-own-cloud-environment/" rel="alternate"></link><published>2021-06-23T15:10:00+02:00</published><updated>2021-06-23T15:10:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-06-23:/2021/06/integrating-or-customizing-SaaS-within-your-own-cloud-environment/</id><summary type="html">&lt;p&gt;Software as a Service (SaaS) solutions are often a quick way to get new
capabilities into an organization’s portfolio. Smaller SaaS solutions are
simple, web-based solutions which barely integrate with the organization’s
other solutions, besides the identity and access management (which is often
handled by federated authentication).&lt;/p&gt;
&lt;p&gt;More complex or intermediate solutions require more integration focus, and
a whole new market of Integration Platform as a Service (iPaaS) solutions
came up to facilitate cross-cloud integrations. But even without the iPaaS
offerings, integrations are often a mandatory part to leverage the benefits
of the newly activated SaaS solution.&lt;/p&gt;
&lt;p&gt;In this post I want to bring some thoughts on the integrations that might be
needed to support customizing a SaaS solution.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Software as a Service (SaaS) solutions are often a quick way to get new
capabilities into an organization’s portfolio. Smaller SaaS solutions are
simple, web-based solutions which barely integrate with the organization’s
other solutions, besides the identity and access management (which is often
handled by federated authentication).&lt;/p&gt;
&lt;p&gt;More complex or intermediate solutions require more integration focus, and
a whole new market of Integration Platform as a Service (iPaaS) solutions
came up to facilitate cross-cloud integrations. But even without the iPaaS
offerings, integrations are often a mandatory part to leverage the benefits
of the newly activated SaaS solution.&lt;/p&gt;
&lt;p&gt;In this post I want to bring some thoughts on the integrations that might be
needed to support customizing a SaaS solution.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Integrations versus customizations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are plenty of ways to integrate solutions in a larger ecosystem. Most
integrations focus on data integration (file transfers mostly) and service
integration (using APIs or Enterprise Service Bus solutions), although many
other creative methods are used to facilitate the integration of a SaaS
within the organization’s portfolio.&lt;/p&gt;
&lt;p&gt;This creativity, in my opinion, often transforms into customization of a SaaS
solution rather than an integration approach. SaaS services are being extended
with new, customized functionality, but in a way that we’re no longer thinking
about integrating this customization with the SaaS, but injecting the SaaS
with closely tied services. And SaaS providers are often happy to support
this, as it binds the customer to their solution.&lt;/p&gt;
&lt;p&gt;Now, customizations are not integrations, and integrations are not
customizations. If you customize a SaaS offering, then you still need an
integration between the custom development and the SaaS offering. Sometimes
this integration is as simple as uploading the customization into the SaaS
and the SaaS does the rest. Or the customization is a completely separate
application service, which integrates over managed APIs with the SaaS. Or you
use an intermediate solution that bridges the two solutions.&lt;/p&gt;
&lt;p&gt;While many integrations are possible, I feel that there are a few integration
approaches that are in most cases just wrong. One of these is linking the
SaaS within your own private solution (network or cloud).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don’t just extend a SaaS environment into your own&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I don’t believe that it is wise to just extend a SaaS environment into your
own, even when the SaaS provider enables this. Services like VPC peering,
which can be used to link your VPC with the SaaS provider’s VPC, are easy
ways to do so, but applying it without adjusting the architecture for it
makes your long-term maintainability and security more challenging. How
do you ensure that the SaaS does not abuse this link? How do you ensure
that you don’t accidentally leak information to the SaaS? How do you ensure
high availability and resiliency is retained?&lt;/p&gt;
&lt;p&gt;In traditional architectures, we would have these provider’s locations
considered as a separate network, and introduce the appropriate controls
(like those offered by application firewalls, reverse proxies, etc.) in
between the business application and the third party. This would often be
facilitated by the network operations teams, and governed through more
centralized environments.&lt;/p&gt;
&lt;p&gt;In cloud environments, architectures can be completely different, and
individual applications might pick integration architectures that are more
fruitful for them, without considering the larger environment. If the DevOps
teams that manage the solution architecture are mature, then they too will
consider the various non-functionals that play a role with such integrations.
But if the experience is lacking, setting up direct extensions towards the
SaaS might seem to be a quick and valid solution.&lt;/p&gt;
&lt;p&gt;Some areas that I would focus on when such integrations are requested, are
(in no particular order):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Impact of the integration to the deployment architecture of the solution,
  considering the availability zones and region concepts used within the
  solution&lt;/li&gt;
&lt;li&gt;Authentication of the integration at various levels (not just
  authentication based on the identity being used)&lt;/li&gt;
&lt;li&gt;Isolation of the integration, ensuring that no other parties are impacted
  by the integration&lt;/li&gt;
&lt;li&gt;Filtering capabilities on network and application level&lt;/li&gt;
&lt;li&gt;Logging and metrics to get visibility on the integration, its usage, the
  volumes sent over, etc.&lt;/li&gt;
&lt;li&gt;Resilience in case of temporary failures (be it through buffering
  mechanisms, or asynchronous integrations)&lt;/li&gt;
&lt;li&gt;Registration of the integration in the enterprise architecture, so that
  assessments, vendor relationship, and other processes are aware of the
  integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When properly tackled, then services like AWS PrivateLink of course do
have a role to play. But it isn’t to just link one solution with another
and be done with it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Granting SaaS providers limited access to your resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Another approach that I see happening is to grant a SaaS provider
administrative access to your own resources. Just like with extending SaaS
environments, I feel that this is not something to apply by default and has
to be carefully assessed. For some SaaS solutions, this is part of their
selling proposal, and is something you know up front. But not all SaaS
solutions are equally obvious in this requirement.&lt;/p&gt;
&lt;p&gt;Some organizations might not have their cloud architecture, account structure
and the like designed to enable SaaS providers to get administrative access
to (some) resources. If the current architectures focus on highly integrated
accounts and solutions, then granting a SaaS administrative access might
jeopardize the security and stability of your overall architecture.&lt;/p&gt;
&lt;p&gt;Furthermore, granting a third party access to your resources also has
implications on accountability. If a SaaS has access to storage within your
account, it could accidentally manipulate data it shouldn’t have access to,
upload another customer’s data on your storage (or vice-versa), or due to a
cyber incident upload toxic data to your account. The provider might also
inadvertently access the data in an economically unfriendly way.&lt;/p&gt;
&lt;p&gt;Using such access patterns should be carefully designed. While you can
often not implement specific IT or security measures on the solution design,
it might be possible to use separate accounts for instance, focusing on
the integration between your ‘core’ solutions and this intermediate one
to ensure a secure and resilient setup, while optimizing cost management
for this intermediate account. You can even consider putting such accounts
under a different tree in the organization structure and apply restrictive
policies such as through AWS’ Service Control Policies (SCP).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Creating solutions that link with third parties requires thought and
design. Cloud providers make it a lot easier to change and apply connections
and integrations, but that does not make the architectural work that
precedes it less obvious - on the contrary.&lt;/p&gt;
&lt;p&gt;Customizations with SaaS providers still need to be carefully assessed
and integrated, with attention on the non-functionals such as resilience,
availability, security and the like.&lt;/p&gt;
&lt;p&gt;If the SaaS provider needs access to your own resources, carefully assess
how fine-grained this can be implemented and how the accountability is
assigned. See if an intermediate account can be used where both you and
the SaaS provider have administrative access to, while keeping the rest
of the organization’s data and solutions elsewhere.&lt;/p&gt;</content><category term="Architecture"></category><category term="architecture"></category><category term="cloud"></category><category term="SaaS"></category><category term="integration"></category><category term="customization"></category></entry></feed>