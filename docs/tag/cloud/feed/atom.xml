<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Simplicity is a form of art... - cloud</title><link href="https://blog.siphos.be/" rel="alternate"></link><link href="https://blog.siphos.be/tag/cloud/feed/atom.xml" rel="self"></link><id>https://blog.siphos.be/</id><updated>2021-09-28T17:00:00+02:00</updated><subtitle></subtitle><entry><title>Scale is a cloud threat</title><link href="https://blog.siphos.be/2021/09/scale-is-a-cloud-threat/" rel="alternate"></link><published>2021-09-28T17:00:00+02:00</published><updated>2021-09-28T17:00:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-09-28:/2021/09/scale-is-a-cloud-threat/</id><summary type="html">&lt;p&gt;Not that long ago, a vulnerability was found in &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/"&gt;Microsoft Azure Cosmos
DB&lt;/a&gt;, a NoSQL SaaS database
within the Microsoft Azure cloud. The vulnerability, which is dubbed
&lt;a href="https://chaosdb.wiz.io/"&gt;ChaosDB&lt;/a&gt; by the &lt;a href="https://twitter.com/wiz_io"&gt;Wiz Research
Team&lt;/a&gt;, uses a vulnerability or misconfiguration in
the &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks"&gt;Jupyter Notebook
feature&lt;/a&gt;
within Cosmos DB. This vulnerability allowed an attacker to gain access to
other's Cosmos DB credentials. Not long thereafter, a second vulnerability
dubbed
&lt;a href="https://www.wiz.io/blog/omigod-critical-vulnerabilities-in-omi-azure"&gt;OMIGOD&lt;/a&gt;
showed that cloud security is not as simple as some vendors like you to believe.&lt;/p&gt;
&lt;p&gt;These vulnerabilities are a good example of how scale is a cloud threat. Companies
that do not have enough experience with public cloud might not assume this in
their threat models.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Not that long ago, a vulnerability was found in &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/"&gt;Microsoft Azure Cosmos
DB&lt;/a&gt;, a NoSQL SaaS database
within the Microsoft Azure cloud. The vulnerability, which is dubbed
&lt;a href="https://chaosdb.wiz.io/"&gt;ChaosDB&lt;/a&gt; by the &lt;a href="https://twitter.com/wiz_io"&gt;Wiz Research
Team&lt;/a&gt;, uses a vulnerability or misconfiguration in
the &lt;a href="https://docs.microsoft.com/en-us/azure/cosmos-db/cosmosdb-jupyter-notebooks"&gt;Jupyter Notebook
feature&lt;/a&gt;
within Cosmos DB. This vulnerability allowed an attacker to gain access to
other's Cosmos DB credentials. Not long thereafter, a second vulnerability
dubbed
&lt;a href="https://www.wiz.io/blog/omigod-critical-vulnerabilities-in-omi-azure"&gt;OMIGOD&lt;/a&gt;
showed that cloud security is not as simple as some vendors like you to believe.&lt;/p&gt;
&lt;p&gt;These vulnerabilities are a good example of how scale is a cloud threat. Companies
that do not have enough experience with public cloud might not assume this in
their threat models.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Perimeter controls and isolation domains&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before tackling the scale of a cloud service, let's consider an on premise
service. Services that run on premise for a company are often built up
specifically for that company, and have no relationship with other customers of
the same service. Taking the NoSQL example, companies can perfectly run NoSQL
database services on premise that have no internet presence. Moreover, these
services are also often not directly exposed to the internet.&lt;/p&gt;
&lt;p&gt;Running services within your own premises reduces the likelihood that attackers
exploit vulnerabilities of that service. Attackers that are not particularly
eyeballing your company might not know you have that service on premise. Even if
they do know, having proper protections in place should prevent direct access to
those services.&lt;/p&gt;
&lt;p&gt;&lt;img alt="On premise services" src="https://blog.siphos.be/images/202109/cloud-scale-on-premise.png"&gt;&lt;/p&gt;
&lt;p&gt;Some situations do require services to expose themselves to the internet. This
exposure increases the &lt;em&gt;attack surface&lt;/em&gt; for the service significantly.
However, these services are still part of a rather isolated deployment that I
call an &lt;strong&gt;isolation domain&lt;/strong&gt;: a logical aggregation of services that share
one or more integrations and interactions, broadening the scope of
potential vulnerabilities and misconfigurations.&lt;/p&gt;
&lt;p&gt;Separate isolation domains imply that vulnerabilities or misconfigurations
that rely on information from the domain cannot spread. This is not the same as
separate deployments or environments, as those often do share certain
integrations. For instance, all NoSQL databases within a company might use that
company's identity provider for federated authentication. But NoSQL databases
exposed to the internet from two completely different companies are often in
separate isolation domains.&lt;/p&gt;
&lt;p&gt;The Cosmos DB vulnerability exploited the fact that all Cosmos DB deployments
are part of the same isolation domain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perimeter and isolation domain challenges for public cloud&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Public cloud platform services, like Cosmos DB, are often lacking these two
attributes: they have different perimeter protections in place, and share the
same isolation domain.&lt;/p&gt;
&lt;p&gt;I do not want to imply that public cloud providers do not provide perimeter
protections against their services. They most definitely do, but the scope of
the perimeter is different from what a company would apply. Whereas a company
gains some measurable security by hiding services or ensuring those services are
not reachable from unauthorized contexts, public cloud platform services need to
be easily accessible for the public cloud to become successful. Security
paradigms like &lt;a href="https://www.nist.gov/publications/zero-trust-architecture"&gt;Zero
Trust&lt;/a&gt; are needed to
raise the security posture of these services. Companies that are building
solutions within the public cloud will find that this requires a different
mindset, and that these environments are not comparable with the traditional
on-premise designs.&lt;/p&gt;
&lt;p&gt;For the Cosmos DB vulnerability, the FAQ mentions that instances that are not
internet facing are still somewhat impacted (as the credentials could have been
leaked) but accessing the database (by using the credentials) will not be
possible without additional vulnerabilities or misconfigurations being
addressed. This is comparable to an administrator password leakage for your
properly isolated on-premise database: while your database might not be
immediately accessible by attackers, you're still going to change the password
as soon as possible to prevent it from being used in later attacks.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Public cloud platform services" src="https://blog.siphos.be/images/202109/cloud-scale-public-cloud.png"&gt;&lt;/p&gt;
&lt;p&gt;The isolation domain is a bigger hurdle to take though, as this is almost always
by design. Platform services always share interactions or integrations across
all the customers of the public cloud. Even though you have your own logical
deployment (or even ask for your own physical deployment), the main interface to
access your service is shared. The service you use to authenticate users or
systems is shared (even when it will eventually use federated authentication to
your own identity provider, the initial service is still the same).&lt;/p&gt;
&lt;p&gt;This shared isolation domain makes each public cloud service a fantastic target
for attackers (and luckily also security researchers). Exploits might not just
reveal data or insights from one customer, but from thousands of customers all
over the world. And the bigger the cloud provider, the bigger the impact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shared control planes also imply sharing the isolation domain&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This problem of using a shared isolation domain is not restricted to public
cloud platform services only. Even on premise deployments that use a public
control plane are taking part in the same isolation domain as all other
customers of the same service.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Control plane also implies sharing isolation domains" src="https://blog.siphos.be/images/202109/cloud-scale-control-plane.png"&gt;&lt;/p&gt;
&lt;p&gt;Suppose you set up a big data platform on premise, but use your vendor's SaaS
service as a control plane to manage this big data platform. This SaaS service
is also used by the other customers of that vendor, so your deployment is part
of the same isolation domain.&lt;/p&gt;
&lt;p&gt;While such setups have benefits (such as using the same control plane for
multiple deployments across different environments and even hosting setups, and
not having to manage and maintain the control services yourself) they do
increase the risk exposure in a not dissimilar fashion from the pure public
cloud services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to tackle these concerns&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Knowing about these increased risks (reachability/exposure, and the shared
isolation domain) is the foremost important part that this article wants to
address. Once these risks are considered, companies can start taking
precautions. I've mentioned the zero trust model as a way to address the
reachability/exposure risk. To address the shared isolation domain, reducing the
impact of a successful exploit can be done through proper architecture and
design that uses the "it is not if, but when" principle for cyberattacks.&lt;/p&gt;
&lt;p&gt;For instance, the data within the databases can use application-level encryption
(meaning the encryption is not done by or through the database, but by the
front-end application that interacts with the database) to reduce the impact of
data leakage through such vulnerabilities. Proper data governance processes
should also be in place to remove any data that is no longer needed on that
database. Active security validations on log data should exist to detect
deviating access patterns, and access controls should be in place to prevent
unauthorized access even from succesfully authenticated users or systems.&lt;/p&gt;
&lt;p&gt;In the Cosmos DB case, the vulnerability was possible through a selectable
feature: deployments that do not have the Jupyter Notebook feature active would
not leak the credentials. Hence, proper configuration management of services and
disabling features that are not going to be used is paramount for cloud
services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If architects are sufficiently aware of the added risks of public cloud
services, they can properly balance these risks against the benefits of the
public cloud, and make appropriate adjustments to the architecture and design of
the solutions. The main challenge here is to make sure this awareness is raised,
and that this awareness is not only reaching the architects, but also the
engineers and other stakeholders. If not, architects risk that they will be seen
as "innovation inhibitors" if they would recommend changes and improvements to
tackle these risks.&lt;/p&gt;
&lt;p&gt;Feedback? Comments? Don't hesitate to &lt;a href="mailto:sven.vermeulen@siphos.be"&gt;drop me an
email&lt;/a&gt;, or join the &lt;a href="https://twitter.com/infrainsight/status/1442867880639401989"&gt;discussion on
Twitter&lt;/a&gt;.&lt;/p&gt;</content><category term="Architecture"></category><category term="cloud"></category><category term="vulnerability"></category></entry><entry><title>Disaster recovery in the public cloud</title><link href="https://blog.siphos.be/2021/07/disaster-recovery-in-the-public-cloud/" rel="alternate"></link><published>2021-07-30T20:00:00+02:00</published><updated>2021-07-30T20:00:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-07-30:/2021/07/disaster-recovery-in-the-public-cloud/</id><summary type="html">&lt;p&gt;The public cloud is a different beast than an on-premise environment, and that
also reflects itself on how we (should) look at the processes that are
actively steering infrastructure designs and architecture. One of these
is the business continuity, severe incident handling, and the
hopefully-never-to-occur disaster recovery. When building up procedures
for handling disasters (&lt;a href="https://en.wikipedia.org/wiki/Disaster_recovery"&gt;DRP = Disaster Recovery Procedure or Disaster 
Recover Planning&lt;/a&gt;),
it is important to keep in mind what these are about.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;The public cloud is a different beast than an on-premise environment, and that
also reflects itself on how we (should) look at the processes that are
actively steering infrastructure designs and architecture. One of these
is the business continuity, severe incident handling, and the
hopefully-never-to-occur disaster recovery. When building up procedures
for handling disasters (&lt;a href="https://en.wikipedia.org/wiki/Disaster_recovery"&gt;DRP = Disaster Recovery Procedure or Disaster 
Recover Planning&lt;/a&gt;),
it is important to keep in mind what these are about.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;What is a disaster&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Disasters are major incidents that have wide-ranging consequences to the
regular operations of the business. What entails a disaster can be different
between organizations, although they are commonly tied to the size of the
infrastructure and the organizational and infrastructural maturity. I'll get
back to the size dependency later when covering public cloud.&lt;/p&gt;
&lt;p&gt;A small organization that only has a few systems can declare a
disaster when all those systems are unreachable because their network
provider's line is interrupted. A larger organization probably has
redundancy of the network in place to mitigate that threat. And even
without the redundancy, organizations might just not depend that much
on those services.&lt;/p&gt;
&lt;p&gt;The larger the environment becomes though, the more the business depends
on the well-being of the services. And while I can only hope that high
availability, resiliency and appropriate redundancy are taken into account
as well, there are always threats that could jeopardize the availability
of services.&lt;/p&gt;
&lt;p&gt;When the problem at hand is specific to one or a manageable set of services,
then taking appropriate action to remediate that threat is generally not a
disaster. It can be a severe incident, but in general it is taken up
by the organization as an incident with a sufficiently small yet
efficient and well organized coordination: the teams involved are 
low in numbers, and the coordination can be done accurately.&lt;/p&gt;
&lt;p&gt;However, when the problem is significant or has a very wide scope, then
depending on the standard incident coordination will be insufficient. You
need to coordinate across too many teams, make sure communication is done
correctly, business is continuously involved/consulted, and most of all - 
you want to make sure that the organization doesn't independently try
to resolve issues when they don't have a full view on the situation
themselves.&lt;/p&gt;
&lt;p&gt;The latter is a major reason in my opinion why a DRP is so important
to have (the plan/procedure, not an actual disaster). If there is no
proper, well-aligned plan of action, teams will try to get in touch
with other teams, polluting communication and only getting incomplete
information. They might take action that other teams should know about
(but won't) or are heavily impacted by (e.g. because they are at that
time trying to do activities themselves). It can make the situation
much worse.&lt;/p&gt;
&lt;p&gt;Because we have to make a distinction between incident management
and disaster management, an organization has to formally declare
a problem as a disaster, and communicate that singular fact ("we
are now in disaster mode") so that all teams know how to respond: 
according to the Disaster Recovery Plan (DRP).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disasters are not just 'force majeure'&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Disasters aren't extraordinary events or circumstances beyond the
control of the organization. Depending on the business needs, you
might very well take precautionary actions against situations you've
never encountered before and will never encounter. We've recently had
a disastrous weather in Belgium (and other countries in Western Europe)
with floods happening in large areas. But that doesn't mean that
for an organization a flood event will trigger a disaster declaration
within a company (the disastrous weather was a disaster from a
human side, with several dozen deaths and millions of damage, so it
feels somewhat incorrect to consider the threat from a theoretical
standpoint here).&lt;/p&gt;
&lt;p&gt;If you're located in a flood-sensitive environment, you can still take
precautionary actions and assess what to do in case of a flood event. 
Depending on the actions taken, a flood event (threat) will not manifest
into availability concerns, data and infrastructure destruction, people
unavailability, etc. It is only when the threat itself turns into an
unforeseen (or non-remediated) situation that we speak of a disaster.&lt;/p&gt;
&lt;p&gt;This is why disasters depend on organizations, and how risk averse
the organization (and business) is. Some businesses might not want to
take precautionary actions against situations that in the past only
occur once every 100 years, especially if the investment they would
have to do is too significant compared to the losses they might have.&lt;/p&gt;
&lt;p&gt;Common disaster threats (sometimes also called catastrophic events)
that I'm used to evaluate from an infrastructure point of view, with a
company that has four strategic data centers, multiple headquarter
locations and a high risk averse setting (considering the financial
market it plays in) are cyberattacks, local but significant infrastructure
disruptions (data center failures or destruction), people-oriented
threats (targetting key personnel), critical provider outages,
disgruntled employees, and so forth. Searching for risk matrices
online can give you some interesting pointers, such as the European
Commission's &lt;a href="https://ec.europa.eu/echo/sites/default/files/swd_2017_176_overview_of_risks_2.pdf"&gt;Overview of Natural and Man-made Disaster Risks the
European Union may
face&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Public cloud related events&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In case of public cloud, the catastrophic events that might occur are
different, and it would be wrong to just consider the same events and
with the same action plan. A prime example, and the one I really want
people to focus on, is regional outages.&lt;/p&gt;
&lt;p&gt;If your current company considers region-wide failures (for
instance because you have two data centers but within the same
region) more from a reactive point of view rather than preventive
(e.g. the DRP in case of region-wide failures is to approach
the reconstruction within the region whenever possible, rather
than fail over to a different region), it might feel the same about
public cloud region failures.&lt;/p&gt;
&lt;p&gt;That would be wrong though. Whereas it is likely that a region-wide
failure for a company is not going to happen in its lifetime, a public
cloud provider is so much more massive in size, that the likelihood
of region-wide failures is higher. If you do a quick search for
region-wide failures in AWS or Azure, you'll find plenty of examples.
And while the failures themselves might be considered 'incidents' from
the public cloud provider point of view, they might be disasters for
the companies/customers that rely on them.&lt;/p&gt;
&lt;p&gt;For me, tackling disaster recovery when dealing with public cloud strongly
focuses on region failures and (coordinated) recovery from region failures.
Beyond region failures, I also strongly recommend to look into the dependencies
that the public cloud consumption has with services outside of the public cloud.
Some of these dependencies might also play a role in certain catastrophic
events. Say that you depend on Azure AD for your authentication and
authorization, and Microsoft is suddenly facing not just a world-wide
Azure AD outage, but also has to explain to you that they cannot restore its
data.&lt;/p&gt;
&lt;p&gt;Preparing for disasters is about preparing for multiple possible catastrophic
events, and in case of public cloud, you're required to think at massive scales.
And that includes designing for region-wide failures as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Impact of public cloud disasters to the organization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Generally, if your organization has a decent maturity in dealing with disaster
recovery planning, they will be using Service Level Agreements with the
business to help decide what to do in case of disasters. Important
non-functionals that are included here are RTO (Recovery Time Objective), RPO
(Recovery Point Objective), and MTD (Maximum Tolerable Downtime). There are
others possibly listed in the SLA as well, but let me focus on these three.
If you want to learn more about contigency planning in general, I recommend
to go through the &lt;a href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-34r1.pdf"&gt;NIST Special Publication 800-34 Rev.1, "Contingency Planning
Guide for Federal Informatino
Systems"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With the RTO, we represent the time it is allowed to take to recover a service
to the point that it functions again. This might include with reduced capacity
or performance degradation. The RTO can be expressed in hours, days, weeks
or other arbitrary value. It is a disaster-oriented value, not availability!
As long as no disaster is declared, the RTO is not considered.&lt;/p&gt;
&lt;p&gt;The RPO identifies how much data loss is acceptable by the business in case of
a disaster. Again, this is disaster-oriented: the business can very well take
extra-ordinary steps to ensure full transactional consistency outside of 
disaster situations, yet allow for a "previous day" RPO in case of a disaster.&lt;/p&gt;
&lt;p&gt;The MTD is most often declared not on a single service, but at business service
level, and explains how long unavailability of that service is tolerated before
it seriously impacts the survivability of the business. It is related to the
RTO, as most services will have an RTO that is more strict/lower value than the
overall MTD, whereas the MTD is near non-negotiable.&lt;/p&gt;
&lt;p&gt;Now, what does public cloud disasters have to do with this? Well, in theory
nothing, as this model and process of capturing business requirements is quite
sensible and maps out perfectly as well. However (and here's the culprit),
an organization that sets up new services on a frequent basis might get
accustomed to certain values, and these values might not be as easy to approach
in a public cloud environment. Furthermore, the organization might not be
accustomed to different disaster scenario's for the SLA: having different sets
of RTO/RPO depending on the category of disaster.&lt;/p&gt;
&lt;p&gt;Let's get back to the region-wide disasters. A company might have decided not
to have region-wide proactive measures in place, and fixate their SLA
non-functionals on local disasters: a data center failure is considered a threat
that still requires proactive measures, whereas regional failures are treated
differently.  The organization decides to only have one SLA set defined, and
includes RTO and RPO values based on the current, local threat matrix. They
might decide that a majority of applications or services has a RPO of "last
transaction", meaning the data has to be fully restored at the latest situation
in case of a disaster.&lt;/p&gt;
&lt;p&gt;This generally implies synchronous replication as an infrastructural
solution. If the organization is used to having this method available (for
instance through SAN replication, cluster technologies, database recovery,
etc.) then they won't sweat at all if the next dozen services all require
the same RPO.&lt;/p&gt;
&lt;p&gt;But now comes the public cloud, and a strong point of attention is region-wide
failures. Doing synchronous replication across regions is not a proper tactic
(as it implies significant performance degradation) and especially not sensible
to do at the same scale as with local replication (e.g. between availability
zones in the same region). Now you have to tell your business that this RPO
value is not easily attainable in the public cloud. The public cloud, which
solves all the wonders in the world. The public cloud, which has more maturity
on operations than your own company. Yet you can't deliver the same SLA?&lt;/p&gt;
&lt;p&gt;Apples and pears. The disasters are different, so your offering might be
different. Of course, you should explain that your 'on premise' disaster
scenarios do not include region-wide failures, and that if you include
the same scenarios for 'on premise' that that RPO value would not be
attainable on premise either.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The public cloud provides many capabilities, and has to deal with a
significantly larger environment than companies are used to. This also means
that disasters that are considered 'extremely unlikely' are now 'likely' (given
the massive scale of the public cloud), and that the threats you have to
consider while dealing with disaster recovery have to be re-visited for public
cloud enabled scenarios.&lt;/p&gt;
&lt;p&gt;My recommendation is to tackle the disaster-oriented non-functional requirements
by categorizing the disasters and having different requirements based on the
disaster at hand. Mature your cloud endeavours so that regional outages
are not a problem anymore (moving them away from the 'disaster' board), and 
properly map all dependencies you have through the public cloud exercises so
that you can build up a good view on what possible threats exist that would
require a well-coordinated approach to tackle the event.&lt;/p&gt;</content><category term="Architecture"></category><category term="architecture"></category><category term="cloud"></category><category term="DRP"></category></entry><entry><title>Not sure if TOSCA will grow further</title><link href="https://blog.siphos.be/2021/06/not-sure-if-TOSCA-will-grow-further/" rel="alternate"></link><published>2021-06-30T14:30:00+02:00</published><updated>2021-06-30T14:30:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-06-30:/2021/06/not-sure-if-TOSCA-will-grow-further/</id><summary type="html">&lt;p&gt;TOSCA is an OASIS open standard, and is an abbreviation for &lt;em&gt;Topology and
Orchestration Specification for Cloud Applications&lt;/em&gt;. It provides a
domain-specific language to describe how an application should be deployed
in the cloud (the topology), which and how many resources it needs, as well
as tasks to run when certain events occur (the orchestration). When I
initially came across this standard, I was (and still am) interested
in how far this goes. The promise of declaring an application (and even
bundling the necessary application artefacts) within a single asset and
then using this asset to deploy on whatever cloud is very appealing to
an architect. Especially in organizations that have a multi-cloud
strategy.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;TOSCA is an OASIS open standard, and is an abbreviation for &lt;em&gt;Topology and
Orchestration Specification for Cloud Applications&lt;/em&gt;. It provides a
domain-specific language to describe how an application should be deployed
in the cloud (the topology), which and how many resources it needs, as well
as tasks to run when certain events occur (the orchestration). When I
initially came across this standard, I was (and still am) interested
in how far this goes. The promise of declaring an application (and even
bundling the necessary application artefacts) within a single asset and
then using this asset to deploy on whatever cloud is very appealing to
an architect. Especially in organizations that have a multi-cloud
strategy.&lt;/p&gt;


&lt;p&gt;But while I do see some adoption of TOSCA, I get the feeling that it is
struggling with its position against the various infrastructure-as-code
(IaC) frameworks that are out there. While many of these frameworks do
not inherently support the abstraction that TOSCA has, it is not all that
hard to apply similar principles and use those frameworks to facilitate
multi-cloud deployments.&lt;/p&gt;
&lt;p&gt;Before considering the infrastructural value of TOSCA further, let's
see what TOSCA is about first.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simplifying and abstracting cloud deployments&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TOSCA offers a model where you can declare how an application should be
hosted in the cloud, or in a cloud-native environment (like a Kubernetes
cluster). For instance, you might want to describe a certain document
management system, which has a web application front-end deployed on 
a farm of web application servers with a load balancer in front of it,
a backend processing system, a database system and a document storage
system. With TOSCA, you can define these structural elements with their
resource requirements.&lt;/p&gt;
&lt;p&gt;For instance, for the database system, we could declare that it has to
be a PostgreSQL database system with a certain administration password,
and within the database system we define two databases with their
own user roles:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;topology_template:
  ...
  node_templates:
    db_server:
      type: tosca.nodes.Compute
      ...
    postgresql:
      type: tosca.nodes.DBMS.PostgreSQL
      properties:
        root_password: &amp;quot;...&amp;quot;
      requirements:
        host: db_server
    db_filemeta:
      type: tosca.nodes.Database.PostgreSQL
      properties:
        name: db_filemeta
        user: fmusr
        password: &amp;quot;...&amp;quot;
      artifacts:
        db_content:
          file: files/file_server_metadata.txt
          type: tosca.artifacts.File
      requirements:
        - host: postgresql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The parameters can, and should be further parameterized. TOSCA supports
declaring inputs that are provided upon deployment so you can safely
publicize the TOSCA structure without putting passwords in there
for instance. Furthermore, TOSCA allows you to add scripts to execute
when a resource is created, which is a common requirement for database
systems.&lt;/p&gt;
&lt;p&gt;But that's not all. Within TOSCA, you then further define the relationship
between the different systems (nodes), including connectivity requirements.
Connections can then be further aligned with virtual networks to model
the network design of the application.&lt;/p&gt;
&lt;p&gt;One of the major benefits of TOSCA is that it also provides abstraction on
the requirements. While the above example explicitly pushes for a PostgreSQL
database hosted on a specific compute server, we could also declare that we
need a database management system, or for the network part we need firewall
capabilities. The TOSCA interpreter, when mapping the model to the target
cloud environment, can then either suggest or pick the technology service
itself. The TOSCA model can then have different actions depending on the
selected technology. For the database for instance, it would have different
deployment scripts.&lt;/p&gt;
&lt;p&gt;The last major benefit that I would like to point out are the workflow
and policy capabilities of TOSCA. You can declare how for instance a 
backup process should look like, or how to cleanly stop and start the
application. You can even model how a rolling upgrade of the application
or database could be handled.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is not just theoretical&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Standards can often be purely theoretical, with one or a few reference
implementations out there. That is not the case with TOSCA. While reading
up on TOSCA, it became clear that it has a strong focus on Network
Functions Virtualization (NFV), a term used to denote the shift
from appliance-driven networking capabilities towards an environment
that has a multitude of solutions running in virtual environments, and
where the infrastructure adopts to this virtualized situation with
(for network) virtual routers, firewalls, etc. Another standards body,
namely the European Telecommunications Standards Institute (ETSI), seems
to be the driving force behind the NFV architecture.&lt;/p&gt;
&lt;p&gt;TOSCA has a simple profile for NFV, which aligns with ETSI's NFV and 
ensures that TOSCA parsers that support this profile can easily be used
to set up and manage solutions in virtualized environments (and thus
also cloud environments). The amount of online information about TOSCA
with respect to the NFV side is large, although still in my opinion
strongly vendor-oriented (products that support TOSCA) and standards-oriented
(talks about how well it fits). On TOSCA's &lt;a href="https://www.oasis-open.org/tosca-implementation-stories/"&gt;implementation stories&lt;/a&gt;
page, two of the three non-vendor stories are within the telco industry.&lt;/p&gt;
&lt;p&gt;There are a few vendors that heavily promote
TOSCA: &lt;a href="https://cloudify.co/"&gt;Cloudify&lt;/a&gt; and &lt;a href="https://designer.otc-service.com"&gt;Ubicity&lt;/a&gt;
offer multi-cloud orchestrators that are TOSCA-based. Many vendors, 
including the incumbent network technology vendors like Cisco and Nokia,
embrace TOSCA NFV. But most information from practical TOSCA usage out
there is in open source solutions. The list of &lt;a href="https://github.com/oasis-open/tosca-community-contributions/wiki/Known-TOSCA-Implementations"&gt;known TOSCA implementations&lt;/a&gt;
mentions plenty of open source products. One of the solutions that I
am considering of playing around with is &lt;a href="https://turandot.puccini.cloud/"&gt;turandot&lt;/a&gt;,
which uses TOSCA to compose and orchestrate Kubernetes workloads.&lt;/p&gt;
&lt;p&gt;As an infrastructure architect, TOSCA could be a nice way of putting
initial designs into practice: after designing solutions in a language
like ArchiMate, which is in general not 'executable', the next step could
be to move the deployment specifications into TOSCA and have the next
phases of the project use and enhance the TOSCA definition. But that
easily brings me to what I consider to be shortcomings of the current
situation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inhibitors for growth potential&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are a number of issues I have with the current state of TOSCA.&lt;/p&gt;
&lt;p&gt;TOSCA's ecosystem &lt;em&gt;seems&lt;/em&gt; to be lacking sufficient visualization support.
I did come across &lt;a href="https://projects.eclipse.org/projects/soa.winery"&gt;Winery&lt;/a&gt;
but that seems to be it. I would really like to see a solution that reads
TOSCA and generates an architectural overview. For instance, for the
example I started this blog with, something like the following:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Visualization of a deployment" src="https://blog.siphos.be/images/202106/tosca-archimate.png"&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, my impression is that TOSCA is strongly and mostly Infrastructure
as a Service (IaaS) oriented. The company I currently work for strongly
focuses on platform services, managed cloud services rather than the
more traditional infrastructure services where we would still have to do
the blunt of the management ourselves. Can TOSCA still play a role
in solutions that are fully using platform services? Perhaps the answer
here is "no", as those managed services are often very cloud-vendor specific,
but that isn't always the case, and can often also be tackled using the
abstraction and implementation specifics that TOSCA supports.&lt;/p&gt;
&lt;p&gt;I also have to rely too much on impressions. While the TOSCA ecosystem
has plenty of open source solutions out there, I find it hard to get
tangible examples: TOSCA definitions of larger-scale definitions that
not only show an initial setup, but are actively maintained to show
maintenance evolution of the solution. If TOSCA is so great for vendors
to have a cloud-independent approach, why do I find it hard to find
vendors that expose TOSCA files? If the adoption of TOSCA stops
at the standards bodies and too few vendors, then it is not likely
to grow much further.&lt;/p&gt;
&lt;p&gt;TOSCA orchestration engines often are in direct competition with
general IaC orchestration like Terraform. Cloudify has a post that
&lt;a href="https://cloudify.co/blog/terraform-vs-cloudify/"&gt;compares Terraform with their solution&lt;/a&gt;
but doesn't look into how Terraform is generally used in CI/CD
processes that join Terraform with the other services that create a
decent end-to-end orchestration for cloud deployments. For Kubernetes,
it competes with Helm and the likes - not fully, as TOSCA has other 
benefits of course, but if you compare how quickly Helm is taking
the lead in Kubernetes you can understand the struggle that TOSCA in
my opinion has.&lt;/p&gt;
&lt;p&gt;Another inhibitor is TOSCA's name. If you search for information on
TOSCA, you need to exclude &lt;a href="https://www.tricentis.com/resources/tricentis-tosca-overview/"&gt;Tricentis'&lt;/a&gt;
continuous testing platform, the &lt;a href="https://en.wikipedia.org/wiki/Tosca"&gt;1900's Opera&lt;/a&gt;,
and several other projects, films, and other entities that use the same
name. You'll need to explicitly mention OASIS and/or cloud as well if
you want to find decent articles about TOSCA, knowing well that there
can be pages out there that are missed because of it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While I appreciate the value TOSCA brings, I feel that it might not grow
to its fullest potential. I hope to be wrong of course, and I would
like to see big vendors publish their reference architecture TOSCA material
so that large-scale solutions are shown to be manageable using TOSCA and
that solution architects do not need to reinvent the wheel over and
over again, as well as link architecture with the more operations
side of things.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To learn more about TOSCA, there are a few resources that I would recommend
here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=tosca"&gt;OASIS TOSCA Technical Committee&lt;/a&gt;
  has a number of resources linked. The &lt;a href="https://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.3/os/TOSCA-Simple-Profile-YAML-v1.3-os.pdf"&gt;TOSCA Simple Profile in YAML Version 1.3&lt;/a&gt;
  PDF is a good read which gradually explains the structure of a TOSCA YAML
  file with plenty of examples.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.etsi.org/technologies/nfv"&gt;Network Functions Virtualisation (NFV)&lt;/a&gt;
  is the ETSI site on NFV. Given the focus on NFV that I find around when
  looking at TOSCA (and is even referenced on this page) understanding what
  NFV is about clarifies a bit more how valuable TOSCA is/can be in this
  environment.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=NHYRESmE6uA"&gt;OCB: AMA on TOSCA the Topology and Orchestration Specification for Cloud Applications - Tal Liron&lt;/a&gt;
  is an hour-long briefing that covers TOSCA not only in theory but also applies
  it in practice, and covers some of the new features that are coming up.&lt;/li&gt;
&lt;/ul&gt;</content><category term="Architecture"></category><category term="architecture"></category><category term="cloud"></category><category term="TOSCA"></category><category term="OASIS"></category><category term="topology"></category><category term="orchestration"></category><category term="infrastructure"></category><category term="IaC"></category><category term="NFV"></category></entry><entry><title>Integrating or customizing SaaS within your own cloud environment</title><link href="https://blog.siphos.be/2021/06/integrating-or-customizing-SaaS-within-your-own-cloud-environment/" rel="alternate"></link><published>2021-06-23T15:10:00+02:00</published><updated>2021-06-23T15:10:00+02:00</updated><author><name>Sven Vermeulen</name></author><id>tag:blog.siphos.be,2021-06-23:/2021/06/integrating-or-customizing-SaaS-within-your-own-cloud-environment/</id><summary type="html">&lt;p&gt;Software as a Service (SaaS) solutions are often a quick way to get new
capabilities into an organization’s portfolio. Smaller SaaS solutions are
simple, web-based solutions which barely integrate with the organization’s
other solutions, besides the identity and access management (which is often
handled by federated authentication).&lt;/p&gt;
&lt;p&gt;More complex or intermediate solutions require more integration focus, and
a whole new market of Integration Platform as a Service (iPaaS) solutions
came up to facilitate cross-cloud integrations. But even without the iPaaS
offerings, integrations are often a mandatory part to leverage the benefits
of the newly activated SaaS solution.&lt;/p&gt;
&lt;p&gt;In this post I want to bring some thoughts on the integrations that might be
needed to support customizing a SaaS solution.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Software as a Service (SaaS) solutions are often a quick way to get new
capabilities into an organization’s portfolio. Smaller SaaS solutions are
simple, web-based solutions which barely integrate with the organization’s
other solutions, besides the identity and access management (which is often
handled by federated authentication).&lt;/p&gt;
&lt;p&gt;More complex or intermediate solutions require more integration focus, and
a whole new market of Integration Platform as a Service (iPaaS) solutions
came up to facilitate cross-cloud integrations. But even without the iPaaS
offerings, integrations are often a mandatory part to leverage the benefits
of the newly activated SaaS solution.&lt;/p&gt;
&lt;p&gt;In this post I want to bring some thoughts on the integrations that might be
needed to support customizing a SaaS solution.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Integrations versus customizations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are plenty of ways to integrate solutions in a larger ecosystem. Most
integrations focus on data integration (file transfers mostly) and service
integration (using APIs or Enterprise Service Bus solutions), although many
other creative methods are used to facilitate the integration of a SaaS
within the organization’s portfolio.&lt;/p&gt;
&lt;p&gt;This creativity, in my opinion, often transforms into customization of a SaaS
solution rather than an integration approach. SaaS services are being extended
with new, customized functionality, but in a way that we’re no longer thinking
about integrating this customization with the SaaS, but injecting the SaaS
with closely tied services. And SaaS providers are often happy to support
this, as it binds the customer to their solution.&lt;/p&gt;
&lt;p&gt;Now, customizations are not integrations, and integrations are not
customizations. If you customize a SaaS offering, then you still need an
integration between the custom development and the SaaS offering. Sometimes
this integration is as simple as uploading the customization into the SaaS
and the SaaS does the rest. Or the customization is a completely separate
application service, which integrates over managed APIs with the SaaS. Or you
use an intermediate solution that bridges the two solutions.&lt;/p&gt;
&lt;p&gt;While many integrations are possible, I feel that there are a few integration
approaches that are in most cases just wrong. One of these is linking the
SaaS within your own private solution (network or cloud).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don’t just extend a SaaS environment into your own&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I don’t believe that it is wise to just extend a SaaS environment into your
own, even when the SaaS provider enables this. Services like VPC peering,
which can be used to link your VPC with the SaaS provider’s VPC, are easy
ways to do so, but applying it without adjusting the architecture for it
makes your long-term maintainability and security more challenging. How
do you ensure that the SaaS does not abuse this link? How do you ensure
that you don’t accidentally leak information to the SaaS? How do you ensure
high availability and resiliency is retained?&lt;/p&gt;
&lt;p&gt;In traditional architectures, we would have these provider’s locations
considered as a separate network, and introduce the appropriate controls
(like those offered by application firewalls, reverse proxies, etc.) in
between the business application and the third party. This would often be
facilitated by the network operations teams, and governed through more
centralized environments.&lt;/p&gt;
&lt;p&gt;In cloud environments, architectures can be completely different, and
individual applications might pick integration architectures that are more
fruitful for them, without considering the larger environment. If the DevOps
teams that manage the solution architecture are mature, then they too will
consider the various non-functionals that play a role with such integrations.
But if the experience is lacking, setting up direct extensions towards the
SaaS might seem to be a quick and valid solution.&lt;/p&gt;
&lt;p&gt;Some areas that I would focus on when such integrations are requested, are
(in no particular order):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Impact of the integration to the deployment architecture of the solution,
  considering the availability zones and region concepts used within the
  solution&lt;/li&gt;
&lt;li&gt;Authentication of the integration at various levels (not just
  authentication based on the identity being used)&lt;/li&gt;
&lt;li&gt;Isolation of the integration, ensuring that no other parties are impacted
  by the integration&lt;/li&gt;
&lt;li&gt;Filtering capabilities on network and application level&lt;/li&gt;
&lt;li&gt;Logging and metrics to get visibility on the integration, its usage, the
  volumes sent over, etc.&lt;/li&gt;
&lt;li&gt;Resilience in case of temporary failures (be it through buffering
  mechanisms, or asynchronous integrations)&lt;/li&gt;
&lt;li&gt;Registration of the integration in the enterprise architecture, so that
  assessments, vendor relationship, and other processes are aware of the
  integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When properly tackled, then services like AWS PrivateLink of course do
have a role to play. But it isn’t to just link one solution with another
and be done with it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Granting SaaS providers limited access to your resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Another approach that I see happening is to grant a SaaS provider
administrative access to your own resources. Just like with extending SaaS
environments, I feel that this is not something to apply by default and has
to be carefully assessed. For some SaaS solutions, this is part of their
selling proposal, and is something you know up front. But not all SaaS
solutions are equally obvious in this requirement.&lt;/p&gt;
&lt;p&gt;Some organizations might not have their cloud architecture, account structure
and the like designed to enable SaaS providers to get administrative access
to (some) resources. If the current architectures focus on highly integrated
accounts and solutions, then granting a SaaS administrative access might
jeopardize the security and stability of your overall architecture.&lt;/p&gt;
&lt;p&gt;Furthermore, granting a third party access to your resources also has
implications on accountability. If a SaaS has access to storage within your
account, it could accidentally manipulate data it shouldn’t have access to,
upload another customer’s data on your storage (or vice-versa), or due to a
cyber incident upload toxic data to your account. The provider might also
inadvertently access the data in an economically unfriendly way.&lt;/p&gt;
&lt;p&gt;Using such access patterns should be carefully designed. While you can
often not implement specific IT or security measures on the solution design,
it might be possible to use separate accounts for instance, focusing on
the integration between your ‘core’ solutions and this intermediate one
to ensure a secure and resilient setup, while optimizing cost management
for this intermediate account. You can even consider putting such accounts
under a different tree in the organization structure and apply restrictive
policies such as through AWS’ Service Control Policies (SCP).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Creating solutions that link with third parties requires thought and
design. Cloud providers make it a lot easier to change and apply connections
and integrations, but that does not make the architectural work that
precedes it less obvious - on the contrary.&lt;/p&gt;
&lt;p&gt;Customizations with SaaS providers still need to be carefully assessed
and integrated, with attention on the non-functionals such as resilience,
availability, security and the like.&lt;/p&gt;
&lt;p&gt;If the SaaS provider needs access to your own resources, carefully assess
how fine-grained this can be implemented and how the accountability is
assigned. See if an intermediate account can be used where both you and
the SaaS provider have administrative access to, while keeping the rest
of the organization’s data and solutions elsewhere.&lt;/p&gt;</content><category term="Architecture"></category><category term="architecture"></category><category term="cloud"></category><category term="SaaS"></category><category term="integration"></category><category term="customization"></category></entry></feed>